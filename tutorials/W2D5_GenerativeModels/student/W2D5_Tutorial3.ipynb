{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuromatch Academy: Week 2, Day 5, Tutorial 3\n",
    "\n",
    "# VAEs and GANs : Conditional GANs\n",
    "\n",
    "__Content creators:__ Seungwook Han, Kai Xu, Akash Srivastava\n",
    "\n",
    "__Content reviewers:__ Name Surname, Name Surname. \n",
    "\n",
    "__Content editors:__ Name Surname, Name Surname.\n",
    "\n",
    "__Production editors:__ Name Surname, Name Surname.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorial Objectives\n",
    "\n",
    "The goal of this notebook is to understand conditional GANs.\n",
    "\n",
    "By the end of this tutorial you will be able to:\n",
    "- Understand the differences in conditional GANs\n",
    "- Generate high-dimensional natural images from a BigGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "outputId": "a250de6c-3dc7-4f85-cbe0-42af3e0842c7"
   },
   "outputs": [],
   "source": [
    "#@markdown Tutorial slides\n",
    "# you should link the slides for all tutorial videos here (we will store pdfs on osf)\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"https://docs.google.com/presentation/d/1eP79mRMzD2Q7Utol3kZ5hooYIXRTQMMb\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "740247d8-0424-4611-abf1-fded336b2c70"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "\n",
    "# Import only the libraries/objects that you use in this tutorial.\n",
    "\n",
    "# If any external library has to be installed, !pip install library --quiet\n",
    "# follow this order: numpy>matplotlib.\n",
    "# import widgets in hidden Figure settings cell\n",
    "\n",
    "# Install Huggingface BigGAN library\n",
    "!pip install pytorch-pretrained-biggan --quiet\n",
    "!pip install Pillow libsixel-python --quiet\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Plotting functions\n",
    "\n",
    "# You may have functions that plot results that aren't\n",
    "# particularly interesting. You can add these here to hide them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "\n",
    "# If any helper functions you want to hide for clarity (that has been seen before\n",
    "# or is simple/uniformative), add here\n",
    "# If helper code depends on libraries that aren't used elsewhere,\n",
    "# import those libaries here, rather than in the main import cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Figure settings\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import ipywidgets as widgets       # interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 1: Generating with a conditional GAN (BigGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "outputId": "6327285d-aca8-4452-c8a0-51983e8d0992"
   },
   "outputs": [],
   "source": [
    "#@title Video 1: Conditional Generative Models\n",
    "# Insert the ID of the corresponding youtube video\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"lV6zH2xDZck\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load a pre-trained conditional GAN, BigGAN, which is the state-of-the-art model in conditional high-dimensional natural image generation, and generate samples from it. Since it is a class conditional model, we will be able to use the class label to generate images from the respective classes of objects.\n",
    "\n",
    "Read here for more details on BigGAN: https://arxiv.org/pdf/1809.11096.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load respective BigGAN model for the specified resolution (biggan-deep-128, biggan-deep-256, biggan-deep-512)\n",
    "def load_biggan(model_res):\n",
    "  return BigGAN.from_pretrained('biggan-deep-{}'.format(model_res))\n",
    "\n",
    "\n",
    "# Create class and noise vectors for sampling from BigGAN\n",
    "def create_class_noise_vectors(class_str, trunc, num_samples):\n",
    "  class_vector = one_hot_from_names([class_str]*num_samples, batch_size=num_samples)\n",
    "  noise_vector = truncated_noise_sample(truncation=trunc, batch_size=num_samples)\n",
    "\n",
    "  return class_vector, noise_vector\n",
    "\n",
    "\n",
    "# Generate samples from BigGAN\n",
    "def generate_biggan_samples(model, class_vector, noise_vector, truncation=0.4, device='cpu'):\n",
    "  # Convert to tensor\n",
    "  noise_vector = torch.from_numpy(noise_vector)\n",
    "  class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "  # Move to GPU\n",
    "  noise_vector = noise_vector.to(device)\n",
    "  class_vector = class_vector.to(device)\n",
    "  model.to(device)\n",
    "\n",
    "  # Generate an image\n",
    "  with torch.no_grad():\n",
    "      output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "  # Back to CPU\n",
    "  output = output.to('cpu')\n",
    "\n",
    "  # The output layer of BigGAN has a tanh layer, resulting the range of [-1, 1] for the output image\n",
    "  # Therefore, we normalize the images properly to [0, 1] range.\n",
    "  # Clipping is only in case of numerical instability problems\n",
    "\n",
    "  output = torch.clip(((output.detach().clone() + 1) / 2.0), 0, 1)\n",
    "  output = output\n",
    "\n",
    "  # Make grid and show generated samples\n",
    "  output_grid = torchvision.utils.make_grid(output, nrow=min(4, output.shape[0]), padding=5)\n",
    "  plt.imshow(output_grid.permute(1,2,0))\n",
    "\n",
    "  return output_grid\n",
    "\n",
    "def generate(b):\n",
    "  # Create BigGAN model\n",
    "  model = load_biggan(MODEL_RESOLUTION)\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "  # Use specified parameters (resolution, class, number of samples, etc) to generate from BigGAN\n",
    "  class_vector, noise_vector = create_class_noise_vectors(CLASS, TRUNCATION, NUM_SAMPLES)\n",
    "  samples_grid = generate_biggan_samples(model, class_vector, noise_vector, TRUNCATION, device)\n",
    "  torchvision.utils.save_image(samples_grid, 'samples.png')\n",
    "  ### If CUDA out of memory issue, lower NUM_SAMPLES (number of samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1:  Define configurations\n",
    "\n",
    "We will now define the configurations (resolution of model, number of samples, class to sample from, truncation level) under which we will sample from BigGAN. \n",
    "\n",
    "***Question***: What is the truncation trick employed by BigGAN? How does sample variety and fidelity change by varying the truncation level? (Hint: play with the truncation slider and try sampling at different levels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "\n",
    "### RUN THIS BLOCK EVERY TIME YOU CHANGE THE PARAMETERS FOR GENERATION\n",
    "\n",
    "# Resolution at which to generate\n",
    "MODEL_RESOLUTION = \"256\" #@param [128, 256, 512]\n",
    "\n",
    "# Number of images to generate\n",
    "NUM_SAMPLES = 1 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "\n",
    "# Class of images to generate\n",
    "CLASS = 'German shepherd' #@param ['tench', 'magpie', 'jellyfish', 'German shepherd', 'bee', 'acoustic guitar', 'coffee mug', 'minibus', 'monitor']\n",
    "\n",
    "# Truncation level of the normal distribution we sample z from\n",
    "TRUNCATION = 0.4 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "b127355c2f114bd593db2aa2d436407a",
      "9df3c82f4f7643d1a5ca001884dddb22",
      "69f200751dc3423cad3612dac23caff9",
      "437599356016424fbecab08c66e6e35c",
      "1ceac124fc8a48bc916db2e30c335e52"
     ]
    },
    "outputId": "07565a55-b62a-4fc6-cffe-fc1dc2f20a01"
   },
   "outputs": [],
   "source": [
    "# Create generate button, given parameters specified above\n",
    "button = widgets.Button(description=\"GENERATE!\",\n",
    "                        layout=widgets.Layout(width='30%', height='80px'),\n",
    "                        button_style='danger')\n",
    "output = widgets.Output()\n",
    "display(button, output)\n",
    "button.on_click(generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this section, we have learned: \n",
    "- How conditional GANs differ from unconditional models\n",
    "- How to use a pre-trained BigGAN model to generate high-dimensional photo-realistic images and its tricks to modulate diversity and image fidelity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJV37zVl3U75"
   },
   "source": [
    "# Food for thought\n",
    "\n",
    "1. How does BigGAN differ from previous state-of-the-art generative models for high-dimensional natural images? In other words, how does BigGAN solve high-dimensional image generation? (Hint: look into model architecture and training configurations) (BigGAN paper: https://arxiv.org/pdf/1809.11096.pdf) \n",
    "2. Continuing from Question 1, what are the drawbacks of introducing such techniques into training large models for high-dimensional, diverse datasets?\n",
    "3. Play with other pre-trained generative models like StyleGAN here -- where code for sampling and interpolation in the latent space is available: https://github.com/NVlabs/stylegan"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D5_Tutorial3",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
