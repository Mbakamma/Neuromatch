{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D5_GenerativeModels/W2D5_Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuromatch Academy: Week 2, Day 5, Tutorial 3\n",
    "\n",
    "# VAEs and GANs : Conditional GANs and Implications of GAN Technology\n",
    "\n",
    "__Content creators:__ Kai Xu, Seungwook Han, Akash Srivastava\n",
    "\n",
    "__Content reviewers:__ Polina Turishcheva, Melvin Selim Atay, Hadi Vafaei, Deepak Raya\n",
    "\n",
    "__Content editors:__ Spiros Chavlis\n",
    "\n",
    "__Production editors:__ Arush Tagade, Spiros Chavlis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorial Objectives\n",
    "\n",
    "The goal of this notebook is to understand conditional GANs. Then you will have the opportunity to experience first-hand how effective GANs are at modeling the data distribution and to question what the consequences of this technology may be.\n",
    "\n",
    "By the end of this tutorial you will be able to:\n",
    "- Understand the differences in conditional GANs.\n",
    "- Generate high-dimensional natural images from a BigGAN.\n",
    "- Understand the efficacy of GANs in modeling the data distribution (e.g., faces).\n",
    "- Understand the energy inefficiency / environmental impact of training these large generative models.\n",
    "- Understand the implications of this technology (ethics, environment, *etc*.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "outputId": "c4641ab1-e61b-4eaf-c251-f0e29b51c59b"
   },
   "outputs": [],
   "source": [
    "#@markdown Tutorial slides (pt. 1)\n",
    "# you should link the slides for all tutorial videos here (we will store pdfs on osf)\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"https://docs.google.com/presentation/d/1eP79mRMzD2Q7Utol3kZ5hooYIXRTQMMb\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "64de50f2-7c91-4f71-d606-a24803843e8e"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Install Huggingface BigGAN library\n",
    "!pip install pytorch-pretrained-biggan --quiet\n",
    "!pip install Pillow libsixel-python --quiet\n",
    "\n",
    "# Import libraries\n",
    "import nltk\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_pretrained_biggan import BigGAN\n",
    "from pytorch_pretrained_biggan import one_hot_from_names\n",
    "from pytorch_pretrained_biggan import truncated_noise_sample\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Figure settings\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import ipywidgets as widgets       # interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e7839c61-e301-4ada-cafd-cbbf57974d94"
   },
   "outputs": [],
   "source": [
    "# @title Set seed for reproducibility in Pytorch\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "def set_seed(seed):\n",
    "  \"\"\"\n",
    "  Set random seed for reproducibility\n",
    "\n",
    "  Args:\n",
    "    seed: integer\n",
    "      A positive integer to ensure reproducibility\n",
    "  \"\"\"\n",
    "  random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "  print(f'Seed {seed} has been set.')\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "set_seed(522)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 1: Generating with a conditional GAN (BigGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "outputId": "eab9cd0b-e16c-4bcc-c1a4-9e90e255cacb"
   },
   "outputs": [],
   "source": [
    "#@title Video 1: Conditional Generative Models\n",
    "# Insert the ID of the corresponding youtube video\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"lV6zH2xDZck\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load a pre-trained conditional GAN, BigGAN, which is the state-of-the-art model in conditional high-dimensional natural image generation, and generate samples from it. Since it is a class conditional model, we will be able to use the class label to generate images from the respective classes of objects.\n",
    "\n",
    "Read here for more details on BigGAN: https://arxiv.org/pdf/1809.11096.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load respective BigGAN model for the specified resolution (biggan-deep-128, biggan-deep-256, biggan-deep-512)\n",
    "def load_biggan(model_res):\n",
    "  return BigGAN.from_pretrained('biggan-deep-{}'.format(model_res))\n",
    "\n",
    "\n",
    "# Create class and noise vectors for sampling from BigGAN\n",
    "def create_class_noise_vectors(class_str, trunc, num_samples):\n",
    "  class_vector = one_hot_from_names([class_str]*num_samples, batch_size=num_samples)\n",
    "  noise_vector = truncated_noise_sample(truncation=trunc, batch_size=num_samples)\n",
    "\n",
    "  return class_vector, noise_vector\n",
    "\n",
    "\n",
    "# Generate samples from BigGAN\n",
    "def generate_biggan_samples(model, class_vector, noise_vector, truncation=0.4,\n",
    "                            device=device):\n",
    "  # Convert to tensor\n",
    "  noise_vector = torch.from_numpy(noise_vector)\n",
    "  class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "  # Move to GPU\n",
    "  noise_vector = noise_vector.to(device)\n",
    "  class_vector = class_vector.to(device)\n",
    "  model.to(device)\n",
    "\n",
    "  # Generate an image\n",
    "  with torch.no_grad():\n",
    "      output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "  # Back to CPU\n",
    "  output = output.to('cpu')\n",
    "\n",
    "  # The output layer of BigGAN has a tanh layer, resulting the range of [-1, 1] for the output image\n",
    "  # Therefore, we normalize the images properly to [0, 1] range.\n",
    "  # Clipping is only in case of numerical instability problems\n",
    "\n",
    "  output = torch.clip(((output.detach().clone() + 1) / 2.0), 0, 1)\n",
    "  output = output\n",
    "\n",
    "  # Make grid and show generated samples\n",
    "  output_grid = torchvision.utils.make_grid(output, nrow=min(4, output.shape[0]), padding=5)\n",
    "  plt.imshow(output_grid.permute(1,2,0))\n",
    "\n",
    "  return output_grid\n",
    "\n",
    "\n",
    "def generate(b):\n",
    "  # Create BigGAN model\n",
    "  model = load_biggan(MODEL_RESOLUTION)\n",
    "\n",
    "  # Use specified parameters (resolution, class, number of samples, etc) to generate from BigGAN\n",
    "  class_vector, noise_vector = create_class_noise_vectors(CLASS, TRUNCATION, NUM_SAMPLES)\n",
    "  samples_grid = generate_biggan_samples(model, class_vector, noise_vector, TRUNCATION, device)\n",
    "  torchvision.utils.save_image(samples_grid, 'samples.png')\n",
    "  ### If CUDA out of memory issue, lower NUM_SAMPLES (number of samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1:  Define configurations\n",
    "\n",
    "We will now define the configurations (resolution of model, number of samples, class to sample from, truncation level) under which we will sample from BigGAN. \n",
    "\n",
    "***Question***: What is the truncation trick employed by BigGAN? How does sample variety and fidelity change by varying the truncation level? (Hint: play with the truncation slider and try sampling at different levels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "\n",
    "### RUN THIS BLOCK EVERY TIME YOU CHANGE THE PARAMETERS FOR GENERATION\n",
    "\n",
    "# Resolution at which to generate\n",
    "MODEL_RESOLUTION = \"256\" #@param [128, 256, 512]\n",
    "\n",
    "# Number of images to generate\n",
    "NUM_SAMPLES = 1 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "\n",
    "# Class of images to generate\n",
    "CLASS = 'German shepherd' #@param ['tench', 'magpie', 'jellyfish', 'German shepherd', 'bee', 'acoustic guitar', 'coffee mug', 'minibus', 'monitor']\n",
    "\n",
    "# Truncation level of the normal distribution we sample z from\n",
    "TRUNCATION = 0.4 #@param {type:\"slider\", min:0.1, max:1, step:0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "34c0f51a7f0b41028fccb76a501bf601",
      "7965841f1e3949bd8ac65e70bd481f69",
      "58695a0fba1c41e9a41abe0f400ab945",
      "6453691af39e428dac5bb11f071eea25",
      "84dd5502c6344cc8b59f526135ba15c5"
     ]
    },
    "outputId": "a878133f-5167-4692-c0b7-d6170c4f0ea7"
   },
   "outputs": [],
   "source": [
    "# Create generate button, given parameters specified above\n",
    "button = widgets.Button(description=\"GENERATE!\",\n",
    "                        layout=widgets.Layout(width='30%', height='80px'),\n",
    "                        button_style='danger')\n",
    "output = widgets.Output()\n",
    "display(button, output)\n",
    "button.on_click(generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food for thought\n",
    "\n",
    "1. How does BigGAN differ from previous state-of-the-art generative models for high-dimensional natural images? In other words, how does BigGAN solve high-dimensional image generation? (Hint: look into model architecture and training configurations) (BigGAN paper: https://arxiv.org/pdf/1809.11096.pdf) \n",
    "2. Continuing from Question 1, what are the drawbacks of introducing such techniques into training large models for high-dimensional, diverse datasets?\n",
    "3. Play with other pre-trained generative models like StyleGAN here -- where code for sampling and interpolation in the latent space is available: https://github.com/NVlabs/stylegan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Ethical issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "outputId": "d947ef6b-12d2-483e-eaee-97b210f2cfc3"
   },
   "outputs": [],
   "source": [
    "#@markdown Tutorial slides (pt. 2)\n",
    "# you should link the slides for all tutorial videos here (we will store pdfs on osf)\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"https://docs.google.com/presentation/d/1-omVjYriCQumx1q_dtAGw-gWmnx7uPz5\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "outputId": "6c46ae1b-0de5-467b-b260-9519e3042103"
   },
   "outputs": [],
   "source": [
    "#@title Video 2: Ethical Issues\n",
    "# Insert the ID of the corresponding youtube video\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"ZtWFeUZgfVk\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1: Faces Quiz \n",
    "\n",
    "Now is your turn to test your abilities on recognizing a real vs. a fake image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "outputId": "02d6bd64-ca12-4ff1-ac20-bbffabd840c3"
   },
   "outputs": [],
   "source": [
    "#@markdown Real or Fake?\n",
    "from IPython import display\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='https://docs.google.com/forms/d/e/1FAIpQLSeGjn2S2bn6Q1qWjVgDS5LG7G1GsQQh2Q0T9dEUO1z5_W0yYg/viewform?usp=sf_link', width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2: Energy Efficiency Quiz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "outputId": "36495b1c-a451-4837-a5aa-9785475dd347"
   },
   "outputs": [],
   "source": [
    "#@markdown Make a guess\n",
    "IFrame(src='https://docs.google.com/forms/d/e/1FAIpQLSe8suNt4ZmadSr_6IWq6s_nUYxC1VCpjR2cBBmQ7cR_5znCZw/viewform?usp=sf_link', width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "outputId": "3ead1656-169c-4480-8e82-842c36379fe1"
   },
   "outputs": [],
   "source": [
    "#@markdown Tutorial slides (pt. 3)\n",
    "# you should link the slides for all tutorial videos here (we will store pdfs on osf)\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"https://docs.google.com/presentation/d/1s8jHcZUudPp0h1yZLHRI9Rk8hz3zuoUS\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "outputId": "18be00f6-0e41-4c59-fe31-b481dd2e9469"
   },
   "outputs": [],
   "source": [
    "#@title Video 3: Recap and advanced topics\n",
    "# Insert the ID of the corresponding youtube video\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"7nUjFG3N04I\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! You have finished the second week of NMA-DL course!!!\n",
    "\n",
    "In the first section of this tutorial, we have learned: \n",
    "- How conditional GANs differ from unconditional models\n",
    "- How to use a pre-trained BigGAN model to generate high-dimensional photo-realistic images and its tricks to modulate diversity and image fidelity\n",
    "\n",
    "In the second section, we learned about the broader ethical implications of GAN technology on society through deepfakes and their tremendous energy inefficiency.\n",
    "\n",
    "On the brighter side, as we learned throughout the week, GANs are very effective in modeling the data distribution and have many practical applications.\n",
    "\n",
    "For example, as personalized healthcare and applications of AI in healthcare rise, the need to remove any Personally Identifiable Information (PII) becomes more important. As shown in this paper (https://link.springer.com/chapter/10.1007/978-3-030-45385-5_36), GANs can be leveraged to anonymize healthcare data.\n",
    "\n",
    "As a food for thought, what are some other practical applications of GANs that you can think of? Discuss with your pod your ideas."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D5_Tutorial3",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
