{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W2D3_Tutorial1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/update_nlp/tutorials/W2D5_IntroNLP/W2D5_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BkC-_xt3Lb-p"
      },
      "source": [
        "# Tutorial 1: Introduction to processing time series\n",
        "\n",
        "**Week 2, Day 5: Intro to NLP**\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__ Lyle Ungar, Kelson Shilling-Scrivo, Alish Dipani\n",
        "\n",
        "__Content reviewers:__  \n",
        "\n",
        "__Content editors:__ Kelson Shilling-Scrivo\n",
        "\n",
        "__Production editors:__ Spiros Chavlis\n",
        "\n",
        "<br>\n",
        "\n",
        "_Based on Content from: Anushree Hede, Pooja Consul, Ann-Katrin Reuel_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "sr6V5fhpLb-r"
      },
      "source": [
        "**Our 2022 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
        "\n",
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "UuYSbyF4Lb-s"
      },
      "source": [
        "----\n",
        "# Tutorial objectives\n",
        "\n",
        "Before we begin with exploring how RNNs excel at modelling sequences, we will explore some of the other ways we can model sequences, encode text, and make meaningful measurements using such encodings and embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "luLZZrqCLb-s"
      },
      "outputs": [],
      "source": [
        "# @title Tutorial slides\n",
        "\n",
        "from IPython.display import IFrame\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/n263c/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gStNLrIaLb-t"
      },
      "source": [
        "These are the slides for the videos in this tutorial. If you want to locally download the slides, click [here](https://osf.io/n263c/download)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BEQEjLpqLb-u"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "72hzrrD_Lb-v"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "\n",
        "# @markdown There may be *errors* and/or *warnings* reported during the installation. However, they are to be ignored.\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html --quiet\n",
        "!pip install --upgrade gensim --quiet\n",
        "!pip install unidecode --quiet\n",
        "!pip install nltk --quiet\n",
        "!pip install python-Levenshtein --quiet\n",
        "!pip install git+https://github.com/facebookresearch/fastText.git --quiet\n",
        "\n",
        "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
        "from evaltools.airtable import AirtableForm\n",
        "\n",
        "# Generate airtable form\n",
        "atform = AirtableForm('appn7VdPRseSoMXEG','W2D5_T1','https://portal.neuromatchacademy.org/api/redirect/to/9c55f6cb-cdf9-4429-ac1c-ec44fe64c303')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "oiH6sVJ4Lb-v"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "import nltk\n",
        "import torch\n",
        "import random\n",
        "import string\n",
        "import fasttext\n",
        "import unidecode\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchtext.legacy import data, datasets\n",
        "from torchtext.vocab import Vectors, FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "lpM1M33LLb-x"
      },
      "outputs": [],
      "source": [
        "# @title Figure Settings\n",
        "import ipywidgets as widgets\n",
        "%matplotlib inline \n",
        "fig_w, fig_h = (8, 6)\n",
        "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "SMALL_SIZE = 12\n",
        "\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/\"\n",
        "              \"course-content/master/nma.mplstyle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "jbi9jEcNLb-z"
      },
      "outputs": [],
      "source": [
        "# @title  Load Dataset from `nltk`\n",
        "# No critical warnings, so we suppress it\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "kEhMHFmlLb-0"
      },
      "outputs": [],
      "source": [
        "# @title Helper functions\n",
        "import requests\n",
        "\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "  URL = \"https://docs.google.com/uc?export=download\"\n",
        "  session = requests.Session()\n",
        "  response = session.get(URL, params={'id': id }, stream=True)\n",
        "  token = get_confirm_token(response)\n",
        "\n",
        "  if token:\n",
        "    params = {'id': id, 'confirm': token}\n",
        "    response = session.get(URL, params=params, stream=True)\n",
        "\n",
        "  save_response_content(response, destination)    \n",
        "\n",
        "\n",
        "def get_confirm_token(response):\n",
        "  for key, value in response.cookies.items():\n",
        "    if key.startswith('download_warning'):\n",
        "      return value\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "  CHUNK_SIZE = 32768\n",
        "  with open(destination, \"wb\") as f:\n",
        "    for chunk in response.iter_content(CHUNK_SIZE):\n",
        "      if chunk:  # filter out keep-alive new chunks\n",
        "        f.write(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "uwAjjNWDLb-1"
      },
      "outputs": [],
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# For DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness.\n",
        "  NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "iB0TX2LKLb-1"
      },
      "outputs": [],
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "\n",
        "# Inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "o3d-hJWWLb-2"
      },
      "outputs": [],
      "source": [
        "DEVICE = set_device()\n",
        "SEED = 2021\n",
        "set_seed(seed=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Section 1: Intro: What time series are there?\n",
        "\n",
        "*Time estimate: 20 mins*"
      ],
      "metadata": {
        "id": "wNBvtT9dNpE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Video 1: Time Series and NLP\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1jg411774B\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"W4RTRXt7pO0\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Video 1: Time Series and NLP')\n",
        "\n",
        "display(out)"
      ],
      "metadata": {
        "id": "h5PeQ6AUVFdj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Video 2: What is NLP?\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1jg411774B\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"Q-PGZyaBQVk\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Video 2: What is NLP')\n",
        "\n",
        "display(out)"
      ],
      "metadata": {
        "id": "uaBFLiFJEcCh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Section 2: Embeddings\n",
        "\n",
        "*Time estimate: 50 mins*"
      ],
      "metadata": {
        "id": "6SbsljEgOPqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Video 3: Embeddings Rule!\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1jg411774B\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"7ijjjFpcOwI\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Video 3: Embeddings Rule!')\n",
        "\n",
        "display(out)"
      ],
      "metadata": {
        "id": "oNLp-RQfVN7p",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6gHudTqTuyd"
      },
      "source": [
        "## Section 2.1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDk5_9UobCfo"
      },
      "source": [
        "[Word2vec](https://rare-technologies.com/word2vec-tutorial/) is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, with each unique word in the corpus being assigned a corresponding vector in the space. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hYXzuYe54uP"
      },
      "source": [
        "### Creating Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn_MEZO6fLaa"
      },
      "source": [
        "We will create embeddings for a subset of categories in [Brown corpus](https://www1.essex.ac.uk/linguistics/external/clmt/w3c/corpus_ling/content/corpora/list/private/brown/brown.html).  In order to achieve this task we will use [gensim](https://radimrehurek.com/gensim/) library to create word2vec embeddings. Gensim’s word2vec expects a sequence of sentences as its input. Each sentence is a list of words.\n",
        "Calling Word2Vec(sentences, iter=1) will run two passes over the sentences iterator (or, in general iter+1 passes). The first pass collects words and their frequencies to build an internal dictionary tree structure. The second and subsequent passes train the neural model. \n",
        "Word2vec accepts several parameters that affect both training speed and quality.\n",
        "\n",
        "One of them is for pruning the internal dictionary. Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. In addition, there’s not enough data to make any meaningful training on those words, so it’s best to ignore them:\n",
        "\n",
        "`model = Word2Vec(sentences, min_count=10)  # default value is 5`\n",
        "\n",
        "\n",
        "A reasonable value for min_count is between 0-100, depending on the size of your dataset.\n",
        "\n",
        "Another parameter is the size of the NN layers, which correspond to the “degrees” of freedom the training algorithm has:\n",
        "\n",
        "`model = Word2Vec(sentences, size=200)  # default value is 100`\n",
        "\n",
        "\n",
        "Bigger size values require more training data, but can lead to better (more accurate) models. Reasonable values are in the tens to hundreds.\n",
        "\n",
        "The last of the major parameters (full list [here](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec)) is for training parallelization, to speed up training:\n",
        "\n",
        "`model = Word2Vec(sentences, workers=4) # default = 1 worker = no parallelization`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UhrgWC9yNw-"
      },
      "source": [
        "# Categories used for the Brown corpus\n",
        "category = ['editorial', 'fiction', 'government', 'mystery', 'news', 'religion',\n",
        "            'reviews', 'romance', 'science_fiction']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYG6dRgl4znS",
        "cellView": "form"
      },
      "source": [
        "# @markdown Helper functions\n",
        "\n",
        "def create_word2vec_model(category='news', size=50, sg=1, min_count=5):\n",
        "  sentences = brown.sents(categories=category) \n",
        "  model = Word2Vec(sentences, vector_size=size,\n",
        "                   sg=sg, min_count=min_count)\n",
        "  return model\n",
        "\n",
        "def model_dictionary(model):\n",
        "  print(w2vmodel.wv)\n",
        "  words = list(w2vmodel.wv)\n",
        "  return words \n",
        "\n",
        "\n",
        "def get_embedding(word, model):\n",
        "  if word in w2vmodel.wv:\n",
        "    return model.wv[word]\n",
        "  else:\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5xulV57Nw2o"
      },
      "source": [
        "The cell will take 30-45 seconds to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0LQa50W1d3v"
      },
      "source": [
        "# Create a word2vec model based on categories from Brown corpus\n",
        "w2vmodel = create_word2vec_model(category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7WY_g_P3wXY"
      },
      "source": [
        "You can get the embedding vector for a word in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Va12snm4Itt"
      },
      "source": [
        "# get word list from Brown corpus\n",
        "brown_wordlist = list(brown.words(categories=category))\n",
        "# generate a random word\n",
        "random_word = random.sample(brown_wordlist, 1)[0]\n",
        "# get embedding of the random word\n",
        "random_word_embedding = get_embedding(random_word, w2vmodel)\n",
        "print(f'Embedding of \"{random_word}\" is {random_word_embedding}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YITWgmtw59s9"
      },
      "source": [
        "### Visualizing Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTrSH9LKP5hM"
      },
      "source": [
        "We can now obtain the word embeddings for any word in the dictionary using word2vec. Let's visualize these embeddings to get an inuition of what these embeddings mean. The word embeddings obtained from word2vec model are in high dimensional space. We will use PCA to pick the 2 features that capture the most variance in the embeddings in order to represent them in a 2D space.\n",
        "\n",
        "\n",
        "For each word in `keys`, we pick the top 10 similar words (using cosine similarity) and plot them.  \n",
        "\n",
        " What should be the arrangement of similar words?\n",
        " What should be arrangement of the key clusters with respect to each other?\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIxN4T_xRLEC"
      },
      "source": [
        "keys = ['voters', 'magic', 'love', 'God', 'evidence', 'administration', 'governments']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1QP-C3WJYLl",
        "cellView": "form"
      },
      "source": [
        "# @markdown ### Helper functions\n",
        "\n",
        "# @markdown **Note:** We import [sklearn.manifold.TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "def get_cluster_embeddings(keys):\n",
        "  embedding_clusters = []\n",
        "  word_clusters = []\n",
        "\n",
        "  # find closest words and add them to cluster\n",
        "  for word in keys:\n",
        "    embeddings = []\n",
        "    words = []\n",
        "    if not word in w2vmodel.wv:\n",
        "      print(f'The word {word} is not in the dictionary')\n",
        "      continue\n",
        "\n",
        "    for similar_word, _ in w2vmodel.wv.most_similar(word, topn=10):\n",
        "      words.append(similar_word)\n",
        "      embeddings.append(w2vmodel.wv[similar_word])\n",
        "    embedding_clusters.append(embeddings)\n",
        "    word_clusters.append(words)\n",
        "\n",
        "  # get embeddings for the words in clusers\n",
        "  embedding_clusters = np.array(embedding_clusters)\n",
        "  n, m, k = embedding_clusters.shape\n",
        "  tsne_model_en_2d = TSNE(perplexity=10, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
        "  embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
        "  return embeddings_en_2d, word_clusters\n",
        "\n",
        "\n",
        "def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, opacity, filename=None):\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
        "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
        "      x = embeddings[:, 0]\n",
        "      y = embeddings[:, 1]\n",
        "      plt.scatter(x, y, color=color, alpha=opacity, label=label)\n",
        "      for i, word in enumerate(words):\n",
        "          plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),\n",
        "                       textcoords='offset points',\n",
        "                       ha='right', va='bottom', size=10)\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    if filename:\n",
        "      plt.savefig(filename, format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJvOa5X1SeXv"
      },
      "source": [
        "# Get closest words to the keys and get clusters of these words\n",
        "embeddings_en_2d, word_clusters = get_cluster_embeddings(keys)\n",
        "# tSNE plot of similar words to keys\n",
        "tsne_plot_similar_words(title='Similar words from Brown Corpus',\n",
        "                        labels=keys,\n",
        "                        embedding_clusters=embeddings_en_2d,\n",
        "                        word_clusters=word_clusters,\n",
        "                        opacity=0.7,\n",
        "                        filename='similar_words.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Think! 2.1\n",
        "\n",
        "1. What does having higher similarity between two word embeddings mean?\n",
        "2. Why are cluster centers close to some keys but farther from others?"
      ],
      "metadata": {
        "id": "rMPnlNVBLGgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q1' , text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ],
      "metadata": {
        "id": "VsYODJ38OUMG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2.2: Embedding exploration"
      ],
      "metadata": {
        "id": "qodTcwOQacJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Video 4: NLP tokenization\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1jg411774B\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"GLreyXm4rg8\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "#atform.add_event('Video 4: NLP Tokenization')\n",
        "\n",
        "display(out)"
      ],
      "metadata": {
        "id": "dCxsCwgXK6ZV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Video 5: Distributional Similarity\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1jg411774B\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"0vTuEIAnrII\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Video 5: Distributional Similarity')\n",
        "\n",
        "display(out)"
      ],
      "metadata": {
        "id": "_R5SBWU3K6uU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkU-9UT1c-4G"
      },
      "source": [
        "\n",
        "Words or subword units such as morphemes are the basic units that we use to express meaning  in language. The technique of mapping words to vectors of real numbers is known as word embedding. \n",
        "\n",
        "In this section, we will be using pretrained fastText embeddings, a context-oblivious embedding similar to word2vec. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7FT7dkdP5t"
      },
      "source": [
        "### Embedding Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWctWkpUA7rX"
      },
      "source": [
        "Let's use the [FastText](https://fasttext.cc/) library to manipulate the embeddings. \n",
        "First, find the embedding for the word \"King\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8jn3QasSGfg",
        "cellView": "form"
      },
      "source": [
        "# @markdown ### Download FastText English Embeddings of dimension 100\n",
        "# @markdown This will take 1-2 minutes to run\n",
        "\n",
        "import os, zipfile, requests, io\n",
        "\n",
        "url = \"https://osf.io/2frqg/download\"\n",
        "fname = \"cc.en.100.bin.gz\"\n",
        "\n",
        "r = requests.get(url, stream=True)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVXvcxJ5-vMI"
      },
      "source": [
        "# Load 100 dimension FastText Vectors using FastText library\n",
        "ft_en_vectors = fasttext.load_model('cc.en.100.bin')\n",
        "print(f\"Length of the embedding is: {len(ft_en_vectors.get_word_vector('king'))}\")\n",
        "print(f\"\\nEmbedding for the word King is:\\n {ft_en_vectors.get_word_vector('king')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuzeZR7pFT9E"
      },
      "source": [
        "Cosine similarity is used for similarities between words. Similarity is a scalar between 0 and 1. Higher scalar value corresponds to higher similarity.\n",
        "\n",
        "Now find the 10 most similar words to \"king\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaRMMjIoGDsr"
      },
      "source": [
        "ft_en_vectors.get_nearest_neighbors(\"king\", 10)  # Most similar by key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n35pqYiobxaJ"
      },
      "source": [
        "### Word Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xugCyA0uNK4Y"
      },
      "source": [
        "More on similarity between words. Let's check how similar different pairs of word are.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-G9Iy6RAJ_Q"
      },
      "source": [
        "def cosine_similarity(vec_a, vec_b):\n",
        "  \"\"\"Compute cosine similarity between vec_a and vec_b\"\"\"\n",
        "  return np.dot(vec_a, vec_b) / (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n",
        "\n",
        "\n",
        "def getSimilarity(word1, word2):\n",
        "  v1 = ft_en_vectors.get_word_vector(word1)\n",
        "  v2 = ft_en_vectors.get_word_vector(word2)\n",
        "  return cosine_similarity(v1, v2)\n",
        "\n",
        "\n",
        "print(f\"Similarity between the words King and Queen: {getSimilarity('king', 'queen')}\")\n",
        "print(f\"Similarity between the words King and Knight: {getSimilarity('king', 'knight')}\")\n",
        "print(f\"Similarity between the words King and Rock: {getSimilarity('king', 'rock')}\")\n",
        "print(f\"Similarity between the words King and Twenty: {getSimilarity('king', 'twenty')}\")\n",
        "\n",
        "print(f\"\\nSimilarity between the words Dog and Cat: {getSimilarity('dog', 'cat')}\")\n",
        "print(f\"Similarity between the words Ascending and Descending: {getSimilarity('ascending', 'descending')}\")\n",
        "print(f\"Similarity between the words Victory and Defeat: {getSimilarity('victory', 'defeat')}\")\n",
        "print(f\"Similarity between the words Less and More: {getSimilarity('less', 'more')}\")\n",
        "print(f\"Similarity between the words True and False: {getSimilarity('true', 'false')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interactive Demo 2.2.1\n",
        "\n",
        "# @markdown Check similarity between words\n",
        "\n",
        "word1 = 'King'  # @param \\ {type:\"string\"}\n",
        "word2 = 'Frog'  # @param \\ {type:\"string\"}\n",
        "word_similarity = getSimilarity(word1, word2)\n",
        "print(f'Similarity between {word1} and {word2}: {word_similarity}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_GitEjg9RHTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN4gXHA4HljR"
      },
      "source": [
        "Using embeddings, we can find the words that appear in similar contexts. But, what happens if the word has several different meanings? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1F4QN8GR70q"
      },
      "source": [
        "### Homonym Similarity\n",
        "\n",
        "Homonyms are words which have same spelling or pronunciation but different meanings depending on the context. Let's explore how these words are embedded and their similarity in different contexts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz20ZseyOO0m"
      },
      "source": [
        "#######################     Words with multiple meanings     ##########################\n",
        "print(f\"Similarity between the words Cricket and Insect: {getSimilarity('cricket', 'insect')}\")\n",
        "print(f\"Similarity between the words Cricket and Sport: {getSimilarity('cricket', 'sport')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interactive Demo 2.2.2\n",
        "\n",
        "# @markdown Explore homonyms \\\\\n",
        "\n",
        "# @markdown examples - minute (time/small), pie (graph/food)\n",
        "\n",
        "word = 'minute'  # @param \\ {type:\"string\"}\n",
        "context_word_1 = 'time'  # @param \\ {type:\"string\"}\n",
        "context_word_2 = 'small'  # @param \\ {type:\"string\"}\n",
        "word_similarity_1 = getSimilarity(word, context_word_1)\n",
        "word_similarity_2 = getSimilarity(word, context_word_2)\n",
        "print(f'Similarity between {word} and {context_word_1}: {word_similarity_1}')\n",
        "print(f'Similarity between {word} and {context_word_2}: {word_similarity_2}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fZVo8PNzR5qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlKxoozWg2uJ"
      },
      "source": [
        "### Word Analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXkZ-fyKiy5c"
      },
      "source": [
        "Embeddings can be used to find word analogies.\n",
        "Let's try it:\n",
        "1.   Man : Woman  ::  King : _____\n",
        "2.  Germany: Berlin :: France : _____\n",
        "3.  Leaf : Tree  ::  Petal : _____\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHKt2IZ0GpPB"
      },
      "source": [
        "## Use get_analogies() funnction. \n",
        "# The words have to be in the order Positive, negative,  Positve\n",
        "\n",
        "# Man : Woman  ::  King : _____\n",
        "# Positive=(woman, king), Negative=(man)\n",
        "print(ft_en_vectors.get_analogies(\"woman\", \"man\", \"king\", 1)) \n",
        "\n",
        "# Germany: Berlin :: France : ______\n",
        "# Positive=(berlin, frannce), Negative=(germany)\n",
        "print(ft_en_vectors.get_analogies(\"berlin\", \"germany\", \"france\", 1))\n",
        "\n",
        "# Leaf : Tree  ::  Petal : _____\n",
        "# Positive=(tree, petal), Negative=(leaf)\n",
        "print(ft_en_vectors.get_analogies(\"tree\", \"leaf\", \"petal\", 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eZ6ZdHQkop-"
      },
      "source": [
        "But, does it always work?\n",
        "\n",
        "\n",
        "1.   Poverty : Wealth  :: Sickness : _____\n",
        "2.   train : board :: horse : _____"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5asyCbMHaQE"
      },
      "source": [
        "# Poverty : Wealth  :: Sickness : _____\n",
        "print(ft_en_vectors.get_analogies(\"wealth\", \"poverty\", \"sickness\", 1))\n",
        "\n",
        "# train : board :: horse : _____\n",
        "print(ft_en_vectors.get_analogies(\"board\", \"train\", \"horse\", 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcYd3O5gn79L"
      },
      "source": [
        "## Section 2.3: Neural Net with word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBoJG26LRKHU",
        "cellView": "form"
      },
      "source": [
        "# @title Video 6: Using Embeddings\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"9ujUgNoPeF0\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Video 6: Using Embeddings')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjjFcmNlpBfd"
      },
      "source": [
        "Training context-oblivious word embeddings is relatively cheap, but most people still use pre-trained word embeddings. After we cover context sensitive word embeddings we'll see how to \"fine tune\" embeddings (adjust them to the task at hand).\n",
        "\n",
        "Let's use the pretrained FastText embeddings to train a neural network on the IMDB dataset. \n",
        "\n",
        "The data consists of reviews and sentiments attached to it. It is a binary classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQsw9lNj3PmE"
      },
      "source": [
        "###  Coding Exercise 1: Simple feed forward net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ez7ZiWXcMeC"
      },
      "source": [
        "Define a vanilla neural network with linear layers. Then average the word embeddings to get an embedding for the entire review.\n",
        "The neural net will have one hidden layer of size 128."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHRWikI4PqJ2"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  \"\"\" A vanilla neural network. \"\"\"\n",
        "  def __init__(self, batch_size, output_size, hidden_size, vocab_size,\n",
        "               embedding_length, word_embeddings):\n",
        "    \"\"\"\n",
        "    Constructs a vanilla Neural Network Instance.\n",
        "\n",
        "    Args:\n",
        "      batch_size: Integer\n",
        "        Specifies probability of dropout hyperparameter\n",
        "      output_size: Integer\n",
        "        Specifies the size of output vector\n",
        "      hidden_size: Integer\n",
        "        Specifies the size of hidden layer\n",
        "      vocab_size: Integer\n",
        "        Specifies the size of the vocabulary\n",
        "        i.e. the number of tokens in the vocabulary\n",
        "      embedding_length: Integer\n",
        "        Specifies the size of the embedding vector\n",
        "      word_embeddings\n",
        "        Specifies the weights to create embeddings from\n",
        "        voabulary.\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(NeuralNet, self).__init__()\n",
        "\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_length = embedding_length\n",
        "\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
        "    self.word_embeddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
        "    self.fc1 = nn.Linear(embedding_length, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\"\n",
        "    Compute the final labels by taking tokens as input.\n",
        "\n",
        "    Args:\n",
        "      inputs: Tensor\n",
        "        Tensor of tokens in the text\n",
        "\n",
        "    Returns:\n",
        "      out: Tensor\n",
        "        Final prediction Tensor\n",
        "    \"\"\"\n",
        "    input = self.word_embeddings(inputs)  # convert text to embeddings\n",
        "    #################################################\n",
        "    # Implement a vanilla neural network\n",
        "    raise NotImplementedError(\"Neural Net `forward`\")\n",
        "    #################################################\n",
        "    # Average the word embedddings in a sentence\n",
        "    # Use torch.nn.functional.avg_pool2d to compute the averages\n",
        "    pooled = F.avg_pool2d(..., (input.shape[1], 1)).squeeze(1)\n",
        "    # Pass the embeddings through the neural net\n",
        "    # Use ReLU as the non-linearity\n",
        "    x = ...\n",
        "    x = ...\n",
        "    x = ...\n",
        "    output = F.log_softmax(x, dim=1)    \n",
        "    return output\n",
        "\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 1: Neural Net for text classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_remove solution\n",
        "class NeuralNet(nn.Module):\n",
        "  \"\"\" A vanilla neural network. \"\"\"\n",
        "  def __init__(self, batch_size, output_size, hidden_size, vocab_size,\n",
        "               embedding_length, word_embeddings):\n",
        "    \"\"\"\n",
        "    Constructs a vanilla Neural Network Instance.\n",
        "\n",
        "    Args:\n",
        "      batch_size: Integer\n",
        "        Specifies probability of dropout hyperparameter\n",
        "      output_size: Integer\n",
        "        Specifies the size of output vector\n",
        "      hidden_size: Integer\n",
        "        Specifies the size of hidden layer\n",
        "      vocab_size: Integer\n",
        "        Specifies the size of the vocabulary\n",
        "        i.e. the number of tokens in the vocabulary\n",
        "      embedding_length: Integer\n",
        "        Specifies the size of the embedding vector\n",
        "      word_embeddings\n",
        "        Specifies the weights to create embeddings from\n",
        "        voabulary.\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(NeuralNet, self).__init__()\n",
        "\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_length = embedding_length\n",
        "\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
        "    self.word_embeddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
        "    self.fc1 = nn.Linear(embedding_length, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\"\n",
        "    Compute the final labels by taking tokens as input.\n",
        "\n",
        "    Args:\n",
        "      inputs: Tensor\n",
        "        Tensor of tokens in the text\n",
        "\n",
        "    Returns:\n",
        "      out: Tensor\n",
        "        Final prediction Tensor\n",
        "    \"\"\"\n",
        "    input = self.word_embeddings(inputs)  # convert text to embeddings\n",
        "    # Average the word embedddings in a sentence\n",
        "    # Use torch.nn.functional.avg_pool2d to compute the averages\n",
        "    pooled = F.avg_pool2d(input, (input.shape[1], 1)).squeeze(1)\n",
        "    # Pass the embeddings through the neural net\n",
        "    # Use ReLU as the non-linearity\n",
        "    x = self.fc1(pooled)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    output = F.log_softmax(x, dim=1)    \n",
        "    return output\n",
        "\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 1: Neural Net for text classification')"
      ],
      "metadata": {
        "id": "rNV0tNjzrv1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLuocVQuRObk",
        "cellView": "form"
      },
      "source": [
        "# @markdown ### Helper functions\n",
        "\n",
        "# @markdown - `train(model, device, train_iter, valid_iter, epochs, learning_rate)`\n",
        "\n",
        "# @markdown - `test(model,  device, test_iter)`\n",
        "\n",
        "# @markdown - `load_dataset(emb_vectors, seed, sentence_length=50)`\n",
        "\n",
        "# @markdown - `plot_train_val(x, train, val, train_label, val_label, title)`\n",
        "\n",
        "\n",
        "# Plotting\n",
        "def plot_train_val(x, train, val, train_label, val_label, title):\n",
        "  plt.plot(x, train, label=train_label)\n",
        "  plt.plot(x, val, label=val_label)\n",
        "  plt.legend()\n",
        "  plt.xlabel('epoch')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Dataset\n",
        "def tokenize(sentences):\n",
        "  # Tokenize the sentence\n",
        "  # from nltk.tokenize library use word_tokenize\n",
        "  token = word_tokenize(sentences)\n",
        "  return token\n",
        "\n",
        "\n",
        "def load_dataset(emb_vectors, seed, sentence_length=50):\n",
        "  TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=sentence_length)\n",
        "  LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "  train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "  TEXT.build_vocab(train_data, vectors=emb_vectors)\n",
        "  LABEL.build_vocab(train_data)\n",
        "\n",
        "  train_data, valid_data = train_data.split(split_ratio=0.7, random_state = random.seed(seed))\n",
        "  train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=32, sort_key=lambda x: len(x.text), repeat=False, shuffle=True)\n",
        "  vocab_size = len(TEXT.vocab)\n",
        "\n",
        "  return TEXT, vocab_size, train_iter, valid_iter, test_iter\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(model, device, train_iter, valid_iter, epochs, learning_rate):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  \n",
        "  train_loss, validation_loss = [], []\n",
        "  train_acc, validation_acc = [], []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # train\n",
        "    model.train()\n",
        "    running_loss = 0.\n",
        "    correct, total = 0, 0 \n",
        "    steps = 0\n",
        "\n",
        "    for idx, batch in enumerate(train_iter):\n",
        "      text = batch.text[0]\n",
        "      target = batch.label\n",
        "      target = torch.autograd.Variable(target).long()\n",
        "      text, target = text.to(device), target.to(device)\n",
        "\n",
        "      # add micro for coding training loop\n",
        "      optimizer.zero_grad()\n",
        "      output = model(text)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      steps += 1\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # get accuracy \n",
        "      _, predicted = torch.max(output, 1)\n",
        "      total += target.size(0)\n",
        "      correct += (predicted == target).sum().item()\n",
        "    train_loss.append(running_loss/len(train_iter))\n",
        "    train_acc.append(correct/total)\n",
        "\n",
        "    print(f'Epoch: {epoch + 1},  Training Loss: {running_loss/len(train_iter):.4f}, Training Accuracy: {100*correct/total: .2f}%')\n",
        "\n",
        "    # evaluate on validation data\n",
        "    model.eval()\n",
        "    running_loss = 0.\n",
        "    correct, total = 0, 0 \n",
        "\n",
        "    with torch.no_grad():\n",
        "      for idx, batch in enumerate(valid_iter):\n",
        "        text = batch.text[0]\n",
        "        target = batch.label\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        text, target = text.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(text)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # get accuracy \n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "    validation_loss.append(running_loss/len(valid_iter))\n",
        "    validation_acc.append(correct/total)\n",
        "\n",
        "    print (f'Validation Loss: {running_loss/len(valid_iter):.4f}, Validation Accuracy: {100*correct/total: .2f}% \\n')\n",
        "\n",
        "  return train_loss, train_acc, validation_loss, validation_acc\n",
        "\n",
        "\n",
        "# Testing\n",
        "def test(model,  device, test_iter):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for idx, batch in enumerate(test_iter):\n",
        "      text = batch.text[0]\n",
        "      target = batch.label\n",
        "      target = torch.autograd.Variable(target).long()\n",
        "      text, target = text.to(device), target.to(device)\n",
        "\n",
        "      outputs = model(text)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += target.size(0)\n",
        "      correct += (predicted == target).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F89jVCxRhlRC",
        "cellView": "form"
      },
      "source": [
        "# @markdown ### Download embeddings and load the dataset\n",
        "\n",
        "# @markdown This will load 300 dim FastText embeddings.\n",
        "\n",
        "# @markdown It will take around 3-4 minutes.\n",
        "\n",
        "embedding_fasttext = FastText('simple')\n",
        "TEXT, vocab_size, train_iter, valid_iter, test_iter = load_dataset(embedding_fasttext, SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ulnNHujG47"
      },
      "source": [
        "learning_rate = 0.0003\n",
        "batch_size = 32\n",
        "output_size = 2\n",
        "hidden_size = 128\n",
        "embedding_length = 300\n",
        "epochs = 15\n",
        "word_embeddings = TEXT.vocab.vectors\n",
        "vocab_size = len(TEXT.vocab)\n",
        "\n",
        "nn_model = NeuralNet(batch_size, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
        "nn_model.to(DEVICE)\n",
        "nn_start_time = time.time()\n",
        "nn_train_loss, nn_train_acc, nn_validation_loss, nn_validation_acc = train(nn_model, DEVICE, train_iter, valid_iter, epochs, learning_rate)\n",
        "print()\n",
        "print(f\"--- Time taken to train = {time.time() - nn_start_time} seconds ---\")\n",
        "test_accuracy = test(nn_model, DEVICE, test_iter)\n",
        "print()\n",
        "print(f'Test Accuracy: {test_accuracy}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXnfP308m6_Z"
      },
      "source": [
        "plot_train_val(np.arange(0, epochs), nn_train_acc, nn_validation_acc,\n",
        "                'training_accuracy', 'validation_accuracy',\n",
        "                'Neural Net on IMDB text classification')\n",
        "plot_train_val(np.arange(0, epochs), nn_train_loss, nn_validation_loss,\n",
        "                'training_loss', 'validation_loss',\n",
        "               'Neural Net on IMDB text classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Summary"
      ],
      "metadata": {
        "id": "0jWFnGkpk-VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Video 7: Time Series\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"JAjuG0o4_Xc\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Video 7: Time Series')\n",
        "\n",
        "display(out)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r-pwcU4pk1rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we introduced how to process time series by taking language as an example. To process time series, they can be converted into embeddings.  \n",
        "  \n",
        "For text, we can first tokenize the words and then create either context-oblivious embeddings or context-dependent embeddings.  \n",
        "  \n",
        "Finally, we saw how these words embeddings can be processed for applications such as text classification."
      ],
      "metadata": {
        "id": "8nzcYK3nP1BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Airtable Submission Link\n",
        "from IPython import display as IPydisplay\n",
        "IPydisplay.HTML(\n",
        "   f\"\"\"\n",
        " <div>\n",
        "   <a href= \"{atform.url()}\" target=\"_blank\">\n",
        "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1\"\n",
        " alt=\"button link to Airtable\" style=\"width:410px\"></a>\n",
        "   </div>\"\"\" )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rslTaKL-P-hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmHQUcI42Ozk"
      },
      "source": [
        "---\n",
        "# Bonus 1 : Multilingual Embeddings\n",
        "\n",
        "Traditionally, word embeddings have been lnaguage-specific, with embeddings for each language trained separately and existing in entirely different vector spaces. But, what if we wanted to compare words in one language to another language? Say, we want to create a text classifier with a corpus consisting of English and Spanish words. \n",
        "\n",
        "We use the multilingual word embeddings provided in fastText. More information can be found [here](https://engineering.fb.com/2018/01/24/ml-applications/under-the-hood-multilingual-embeddings/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training multilingual embeddings\n",
        "\n",
        "We first train separate embeddings for each language using fastText and a combination of data from Facebook and Wikipedia. Then, we find a dictionary of common words between the two languages. The dictionaries are automatically induced from parallel data - datasets that consist of a pair of sentences in two different languages that have the same meaning. \n",
        "\n",
        "Then, we find a matrix that projects the embeddings into a common space between the given languages. The matrix is designed to minimize the distance between a word $x_i$ and its projection $y_i$. If our dictionary consists of pairs $(x_i, y_i)$, our projector $M$ would be: \n",
        "\n",
        "\\begin{equation}\n",
        "M = \\underset{W}{\\operatorname{argmax}} \\sum_i ||x_i - Wy_i||^2\n",
        "\\end{equation}\n",
        "\n",
        "Also, the projector matrix $W$ is constrained to e orthogonal so that original distances between word embedding vectors are preserved. Multilingual models are trained by using our multilingual word embeddings as the base representations in DeepText and “freezing” them, or leaving them unchanged during the training process. \n",
        "\n",
        "After going through this, try to replicate the above exercises but in different languages!"
      ],
      "metadata": {
        "id": "9IxemazpqdL3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkZDDZryGzJy",
        "cellView": "form"
      },
      "source": [
        "# @markdown ### Download FastText French Embeddings of dimension 100\n",
        "\n",
        "# @markdown **Note:** This cell might take 10-15 minutes to run\n",
        "\n",
        "import os, zipfile, requests, io\n",
        "\n",
        "url = \"https://osf.io/6tqvp/download\"\n",
        "fname = \"cc.fr.100.bin.gz\"\n",
        "\n",
        "r = requests.get(url, stream=True)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB-HOFL3hqkI"
      },
      "source": [
        "# Load 100 dimension FastText Vectors using FastText library\n",
        "french = fasttext.load_model('cc.fr.100.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niCYe2QllHM2"
      },
      "source": [
        "First, we take a look at the cosine similarity between different languages without projecting them into the same vector space. As you can see, the same words seem to be close to $0$ cosine similarity in different languages - so neither similar nor dissimilar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwI-61zSyF6X"
      },
      "source": [
        "hello = ft_en_vectors.get_word_vector('hello')\n",
        "hi = ft_en_vectors.get_word_vector('hi')\n",
        "bonjour = french.get_word_vector('bonjour')\n",
        "\n",
        "print(f\"Cosine Similarity between HI and HELLO: {cosine_similarity(hello, hi)}\")\n",
        "print(f\"Cosine Similarity between BONJOUR and HELLO: {cosine_similarity(hello, bonjour)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnLV8NzfJvUp"
      },
      "source": [
        "cat = ft_en_vectors.get_word_vector('cat')\n",
        "chatte = french.get_word_vector('chatte')\n",
        "chat = french.get_word_vector('chat')\n",
        "\n",
        "print(f\"Cosine Similarity between cat and chatte: {cosine_similarity(cat, chatte)}\")\n",
        "print(f\"Cosine Similarity between cat and chat: {cosine_similarity(cat, chat)}\")\n",
        "print(f\"Cosine Similarity between chatte and chat: {cosine_similarity(chatte, chat)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-4Ywer6lu8l"
      },
      "source": [
        "First, let's define a list of words that are in common between English and French. We'll be using this to make our training matrices. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoyzY7x-NQn_"
      },
      "source": [
        "en_words = set(ft_en_vectors.words)\n",
        "fr_words = set(french.words)\n",
        "overlap = list(en_words & fr_words)\n",
        "bilingual_dictionary = [(entry, entry) for entry in overlap]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTUS9JB_l5Jd"
      },
      "source": [
        "We define a few functions to make our lives a bit easier: `make_training_matrices` takes in the source words, target language words, and the set of common words. It then creates a matrix of all the word embeddings of all common words between the languages (in each language). These are our training matrices. \n",
        "\n",
        "The function `learn_transformation` then takes in these matrices, normalizes them, and then performs SVD, which aligns the source language to the target and returns a transformation matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdF7jqWgNZ3V"
      },
      "source": [
        "def make_training_matrices(source_dictionary, target_dictionary,\n",
        "                           bilingual_dictionary):\n",
        "  source_matrix = []\n",
        "  target_matrix = []\n",
        "  for (source, target) in tqdm(bilingual_dictionary):\n",
        "    # if source in source_dictionary.words and target in target_dictionary.words:\n",
        "    source_matrix.append(source_dictionary.get_word_vector(source))\n",
        "    target_matrix.append(target_dictionary.get_word_vector(target))\n",
        "  # return training matrices\n",
        "  return np.array(source_matrix), np.array(target_matrix)\n",
        "\n",
        "\n",
        "# from https://stackoverflow.com/questions/21030391/how-to-normalize-array-numpy\n",
        "def normalized(a, axis=-1, order=2):\n",
        "  \"\"\"Utility function to normalize the rows of a numpy array.\"\"\"\n",
        "  l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
        "  l2[l2==0] = 1\n",
        "  return a / np.expand_dims(l2, axis)\n",
        "\n",
        "\n",
        "def learn_transformation(source_matrix, target_matrix, normalize_vectors=True):\n",
        "  \"\"\"\n",
        "  Source and target matrices are numpy arrays, shape\n",
        "  (dictionary_length, embedding_dimension). These contain paired\n",
        "  word vectors from the bilingual dictionary.\n",
        "  \"\"\"\n",
        "  # optionally normalize the training vectors\n",
        "  if normalize_vectors:\n",
        "    source_matrix = normalized(source_matrix)\n",
        "    target_matrix = normalized(target_matrix)\n",
        "  # perform the SVD\n",
        "  product = np.matmul(source_matrix.transpose(), target_matrix)\n",
        "  U, s, V = np.linalg.svd(product)\n",
        "  # return orthogonal transformation which aligns source language to the target\n",
        "  return np.matmul(U, V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBoo9SaQmlxD"
      },
      "source": [
        "Now, we just have to put it all together! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH6IdDLPQdLJ"
      },
      "source": [
        "source_training_matrix, target_training_matrix = make_training_matrices(ft_en_vectors, french, bilingual_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eU7R44XQtto"
      },
      "source": [
        "transform = learn_transformation(source_training_matrix, target_training_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baD77aOVmqVX"
      },
      "source": [
        "Let's run the same examples as above, but this time, whenever we use French words, matrix multiply the embedding by the transpose of the transform matrix. That works a lot better! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7a3L-VOR6ht"
      },
      "source": [
        "hello = ft_en_vectors.get_word_vector('hello')\n",
        "hi = ft_en_vectors.get_word_vector('hi')\n",
        "bonjour = np.matmul(french.get_word_vector('bonjour'), transform.T)\n",
        "\n",
        "print(f\"Cosine Similarity between HI and HELLO: {cosine_similarity(hello, hi)}\")\n",
        "print(f\"Cosine Similarity between BONJOUR and HELLO: {cosine_similarity(hello, bonjour)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-o5a_DQS6b7"
      },
      "source": [
        "cat = ft_en_vectors.get_word_vector('cat')\n",
        "chatte = np.matmul(french.get_word_vector('chatte'), transform.T)\n",
        "chat = np.matmul(french.get_word_vector('chat'), transform.T)\n",
        "\n",
        "print(f\"Cosine Similarity between cat and chatte: {cosine_similarity(cat, chatte)}\")\n",
        "print(f\"Cosine Similarity between cat and chat: {cosine_similarity(cat, chat)}\")\n",
        "print(f\"Cosine Similarity between chatte and chat: {cosine_similarity(chatte, chat)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRYVFi7-m797"
      },
      "source": [
        "Now, try a couple of your own examples. Try some of the examples you looked at in $2.1$, but with English and French. Does it work as expected? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXBTQe_8nMfI"
      },
      "source": [
        "# USE THIS SPACE TO TRY YOUR OWN EXAMPLES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uexRXZpkxBI",
        "cellView": "form"
      },
      "source": [
        "# @markdown Clean Up of Previous Files (MUST RUN)\n",
        "!rm *.zip\n",
        "!rm *.gz\n",
        "!rm *.bin\n",
        "!rm *.bin"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}