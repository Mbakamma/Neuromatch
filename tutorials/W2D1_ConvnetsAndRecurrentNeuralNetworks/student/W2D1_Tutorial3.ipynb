{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Neuromatch Academy: Week 2, Day 1, Tutorial 3\n",
    "# Day 1: Parameter Sharing (CNNs and RNNs)\n",
    "\n",
    "__Content creators:__ Alona Fyshe, Dawn McKnight, Richard Gerum, Cassidy Pirlot, Rohan Saha, Liam Peet-Pare, Saeed Najafi \n",
    "\n",
    "__Content reviewers:__ Saeed Salehi, Lily Cheng, Yu-Fang Yang, Polina Turishcheva\n",
    "\n",
    "__Production editors:__ Anmol Gupta, Spiros Chavlis \n",
    "\n",
    "__Based on material from:__ Konrad Kording, Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "At the end of this tutorial, we will be able to:\n",
    "- Understand the structure of a Recurrent Neural Network (RNN)\n",
    "- Build a simple RNN model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "outputId": "d4a7edad-5ab0-42c9-e4bf-5d9cef139b14"
   },
   "outputs": [],
   "source": [
    "#@markdown Tutorial slides\n",
    "# you should link the slides for all tutorial videos here (we will store pdfs on osf)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe src=\"https://docs.google.com/presentation/d/1jrKnXGoCXovB5pMGtnsF0ICxr1Cu_vDk/edit#slide=id.p1\" frameborder=\"100\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Dependencies\n",
    "!pip install livelossplot --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "597744a3-9d2d-43df-e5b5-581302c1971b"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device, torch.get_num_threads()\n",
    "\n",
    "!mkdir images\n",
    "!wget \"https://raw.githubusercontent.com/dem1995/generally_available_files/main/chicago_skyline_shrunk_v2.bmp\"\n",
    "!mv *.bmp images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "fig_w, fig_h = (8, 6)\n",
    "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
    "\n",
    "plt.rcParams[\"mpl_toolkits.legacy_colorbar\"] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/\"\n",
    "              \"course-content/master/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "50e04e2e-1be8-4b86-c0d7-edf0bc6c238d"
   },
   "outputs": [],
   "source": [
    "# @title Set seed for reproducibility\n",
    "seed = 2021\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "print ('Seed has been set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "outputId": "3d18076f-e82c-4a46-cd50-61946dc973bf"
   },
   "outputs": [],
   "source": [
    "#@title Video 1: Intro to RNNs\n",
    "# Insert the ID of the corresponding youtube video\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"0Majex-aF0E\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs are compact models that operate over timeseries, and have the ability to remember past input. They also save parameters by using the same weights at every time step.  If you've heard of Transformers, those models dont' have this kind of temporal weight sharing, and so they are *much* larger.\n",
    "\n",
    "The code below is adapted from https://github.com/spro/char-rnn.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3b9e167d-8016-4d47-95be-e0f4bf3b00ce"
   },
   "outputs": [],
   "source": [
    "#@title RNN framework (run me)\n",
    "\n",
    "!pip install unidecode\n",
    "\n",
    "!wget --output-document=/content/sample_data/twain.txt https://github.com/amfyshe/amfyshe.github.io/blob/master/twain.txt\n",
    "\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"rnn\":\n",
    "            self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Helpers (run me)\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# Reading and un-unicode-encoding data\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def read_file(filename):\n",
    "    file = unidecode.unidecode(open(filename).read())\n",
    "    return file, len(file)\n",
    "\n",
    "# Turning a string into a tensor\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor\n",
    "\n",
    "# Readable time elapsed\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
    "\n",
    "    if cuda:\n",
    "        hidden = hidden.cuda()\n",
    "        prime_input = prime_input.cuda()\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p], hidden)\n",
    "\n",
    "    inp = prime_input[:,-1]\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "\n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
    "        if cuda:\n",
    "            inp = inp.cuda()\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "505980594e8146b1a47156dc3fecf4f7",
      "a9b1b9f0ecab4d96bc595797f27bdf50",
      "bd9bd764635e4e7fb100acd4c8cb4545",
      "6e88fd361fde4e888ce82cc9fa190ff8",
      "2a6db00a2a3a45b4afcbb12deb208f86",
      "7db1592264bf47a293f60940b699501f",
      "a27d3c1e3fca487ab621762e3ab350eb",
      "1f1f27f216f84612aa9d9915db39c4fa"
     ]
    },
    "outputId": "d57662b4-7b80-4dec-e16c-3fa170a00974"
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "!ls\n",
    "!pwd\n",
    "\n",
    "batch_size = 50\n",
    "chunk_len = 200\n",
    "model = \"rnn\" # other options: lstm, gru\n",
    "\n",
    "#hyperparams\n",
    "n_layers = 2\n",
    "hidden_size = 200\n",
    "n_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "print_every = 25\n",
    "\n",
    "def train(inp, target):\n",
    "  hidden = decoder.init_hidden(batch_size)\n",
    "  decoder.zero_grad()\n",
    "  loss = 0\n",
    "\n",
    "  for c in range(chunk_len):\n",
    "    output, hidden = decoder(inp[:,c], hidden)\n",
    "    loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "\n",
    "  loss.backward()\n",
    "  decoder_optimizer.step()\n",
    "  return loss.item() / chunk_len\n",
    "\n",
    "file, file_len = read_file('/content/sample_data/twain.txt')\n",
    "\n",
    "def random_training_set(chunk_len, batch_size):\n",
    "  inp = torch.LongTensor(batch_size, chunk_len)\n",
    "  target = torch.LongTensor(batch_size, chunk_len)\n",
    "  for bi in range(batch_size):\n",
    "    start_index = random.randint(0, file_len - chunk_len - 1)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    chunk = file[start_index:end_index]\n",
    "    inp[bi] = char_tensor(chunk[:-1])\n",
    "    target[bi] = char_tensor(chunk[1:])\n",
    "  inp = Variable(inp)\n",
    "  target = Variable(target)\n",
    "  return inp, target\n",
    "\n",
    "decoder = CharRNN(\n",
    "    n_characters,\n",
    "    hidden_size,\n",
    "    n_characters,\n",
    "    model=model,\n",
    "    n_layers=n_layers,\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adagrad(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in tqdm(range(1, n_epochs + 1), position=0, leave=True):\n",
    "  loss = train(*random_training_set(chunk_len, batch_size))\n",
    "  loss_avg += loss\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "    print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch,\\\n",
    "                                   epoch / n_epochs * 100, loss))\n",
    "    print(generate(decoder, 'Wh', 100), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Section 2: Power consumption in Deep Learning\n",
    "\n",
    "Training NN models can be incredibly costly, both in actual money but also in power consumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "outputId": "f339b6a0-9c4f-483c-8cc4-ada7c19ba252"
   },
   "outputs": [],
   "source": [
    "#@title Video 2: Carbon Footprint of AI\n",
    "# Insert the ID of the corresponding youtube video\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"2upwdK3bcXU\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a few moments to chat with your pod about the following points:\n",
    "* Which societal costs of training do you find most compelling?\n",
    "* When is training an AI model worth the cost?  Who should make that decision?\n",
    "* Should there be additional taxes on energy costs for compute centers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Wrap up\n",
    "\n",
    "What a day!  We've learned a lot!  The basics of CNNs and RNNs, and how changes to architecture that allow models to parameter share can greatly reduce the size of the model.  We learned about convoliution and pooling, as well as the basic idea behind RNNs.  To wrap up we thought about the impact of training large NN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "outputId": "423ff25c-fc87-482d-e47c-1dc7a291cbfb"
   },
   "outputs": [],
   "source": [
    "#@title Video 3: Wrap-up\n",
    "# Insert the ID of the corresponding youtube video\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"Ikb4hwR4pU0\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "84Dq9a0HCXcw"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "W2D1_Tutorial3",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
