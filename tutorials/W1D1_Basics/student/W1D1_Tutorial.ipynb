{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Neuromatch Academy: Week 1, Day 1, Tutorial 1\n",
    "# Pytorch\n",
    "\n",
    "__Content creators:__ Shubh Pachchigar, Vladimir Haltakov, Matthew Sargent\n",
    "\n",
    "\n",
    "\n",
    "__Content reviewers:__ Kelson Shilling-Scrivo, Deepak Raya\n",
    "\n",
    "__Content editors:__ Anoop Kulkarni\n",
    "\n",
    "__Production editors:__ Name Surname, Name Surname.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Tutorial Objectives\n",
    "\n",
    "Then have a few specific objectives for this tutorial:\n",
    "* Learn about PyTorch and tensors\n",
    "* Tensor Manipulations \n",
    "* Data Loading\n",
    "* GPUs and Cuda Tensors\n",
    "* Train NaiveNet\n",
    "* Get to know your pod\n",
    "* Start thinking about the course as a whole\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout your Neuromatch tutorials, most (probably all!) notebooks contain setup cells. These cells will import the required Python packages (e.g. PyTorch, numpy); set global or environment variables, and load in helper functions for things like plotting.\n",
    "\n",
    "Be sure to run all of the cells in the setup section. Feel free to expand them and have a look at what you are loading in, but you should be able to fulfill the learning objectives of every tutorial without having to look at these cells.\n",
    "\n",
    "If you start building your own projects built on this code base we highly recommend looking at them in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Helper Functions\n",
    "def checkExercise1(A: torch.Tensor, B: torch.Tensor ,C:torch.Tensor, D:torch.Tensor):\n",
    "  errors = []\n",
    "  #TODO better errors\n",
    "  if not torch.equal(A,torch.ones(20,21)):\n",
    "    errors.append(\"A is not a 20 by 21 tensor of ones \")\n",
    "  if not np.array_equal( B.numpy(),np.vander([1,2,3], 4)):\n",
    "    errors.append(\"B is not a tensor containing the elements of Z \")\n",
    "  if C.shape != (20,21):\n",
    "    errors.append(\"C is not the correct shape \")\n",
    "  if not torch.equal(D,torch.arange(4,41,step=2)):\n",
    "    errors.append(\"D does not contain the correct elements\")\n",
    "\n",
    "  if errors == []:\n",
    "    print(\"All correct!\")\n",
    "\n",
    "  else:\n",
    "    print(errors)\n",
    "\n",
    "def timeFun(f, iterations):\n",
    "  iterations = iterations\n",
    "  t_total = 0\n",
    "  for _ in range(iterations):\n",
    "    start = time.time()\n",
    "    f()\n",
    "    end = time.time()\n",
    "    t_total += end - start\n",
    "  print(f\"time taken for {iterations} iterations of {f.__name__}: {t_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3BHHd19Gk9j"
   },
   "source": [
    "# Section 1: Welcome to Neuromatch Deep learning course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "73544b1e-c781-4e2e-f4f7-8a6e33df0894"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 1.1: Welcome and History\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"ca21SNqt78I\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This will be an intensive 3 week adventure. We will all learn Deep Learning. In a group. Groups need standards. Read our \n",
    "[code of conduct](https://docs.google.com/document/d/1eHKIkaNbAlbx_92tLQelXnicKXEcvFzlyzzeWjEtifM/edit?usp=sharing).\n",
    "\n",
    "Code of conduct\n",
    "\n",
    "TODO: ADD EXERCISE: DESCRIBE WHAT YOU HOPE TO GET OUT OF THIS COURSE IN ABOUT 100 WORDS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "0c5d7b3d-c493-4e27-dda1-2e5f92648c82"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 1.2: Syllabus\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"cDvAqG_hAvQ\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meet our lecturers:\n",
    "\n",
    "Week 1: the building blocks\n",
    "*   [Konrad Kording](https://kordinglab.com)\n",
    "*   [Andrew Saxe](https://www.saxelab.org/)\n",
    "*   [Surya Ganguli](https://ganguli-gang.stanford.edu/)\n",
    "*   [Ioannis Mitliagkas](http://mitliagkas.github.io/)\n",
    "*   [Lyle Ungar](https://www.cis.upenn.edu/~ungar/)\n",
    "\n",
    "Week 2: making things work\n",
    "* [Alona Fyshe](https://webdocs.cs.ualberta.ca/~alona/)\n",
    "* [Alexander Ecker](https://eckerlab.org/)\n",
    "* [James Evans](https://sociology.uchicago.edu/directory/james-evans)\n",
    "* [He He](https://hhexiy.github.io/)\n",
    "* [Vikash Gilja](https://tnel.ucsd.edu/bio) and [Akash Srivastava](https://akashgit.github.io/)\n",
    "\n",
    "Week 3: more magic\n",
    "* [Tim Lillicrap](https://contrastiveconvergence.net/~timothylillicrap/index.php) and [Blake Richards](https://www.mcgill.ca/neuro/blake-richards-phd)\n",
    "* [Jane Wang](http://www.janexwang.com/)\n",
    "* [Tim Lillicrap](https://contrastiveconvergence.net/~timothylillicrap/index.php) and [Blake Richards](https://www.mcgill.ca/neuro/blake-richards-phd)\n",
    "* [Josh Vogelstein](https://jovo.me/) and [Vincenzo Lamonaco](https://www.vincenzolomonaco.com/)\n",
    "\n",
    "Now, go to the visualization of ICLR papers. Read a few abstracts. Look at the various clusters. Where do you see yourself in this map?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: The Basics of PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "PyTorch is a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  A replacement for NumPy to use the power of GPUs\n",
    "-  A deep learning platform that provides significant flexibility\n",
    "   and speed\n",
    "\n",
    "At its core, PyTorch provides a few key features:\n",
    "\n",
    "- A multidimensional [Tensor](https://pytorch.org/docs/stable/tensors.html) object, similar to [NumPy Array](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) but with GPU acceleration.\n",
    "- An optimized **autograd** engine for automatically computing derivatives.\n",
    "- A clean, modular API for building and deploying **deep learning models**.\n",
    "\n",
    "You can find more information about PyTorch in the appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Section 2.1: Creating Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "dfec5d53-9894-4867-ed4c-bd854e36c670"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 2.1: Making Tensors\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"jGKd_4tPGrw\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways of creating tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct tensors directly:**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1395eccd-0b05-40ab-950d-25ecef38acc6"
   },
   "outputs": [],
   "source": [
    "# we can construct a tensor directly from some common python iterables,\n",
    "# such as list and tuple nested iterables can also be handled as long as the\n",
    "# dimensions make sense\n",
    "\n",
    "# tensor from a list\n",
    "a = torch.tensor([0,1,2])\n",
    "\n",
    "#tensor from a tuple of tuples\n",
    "b = ((1.0, 1.1), (1.2,1.3))\n",
    "b = torch.tensor(b)\n",
    "\n",
    "# tensor from a numpy array\n",
    "c = np.ones([2,3])\n",
    "c = torch.tensor(c)\n",
    "print(\"Tensor a:\", a)\n",
    "print(\"Tensor b:\", b)\n",
    "print(\"Tensor c:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some common tensor constructors:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9575eeed-86e4-4157-dbc3-0f7a106bd3e0"
   },
   "outputs": [],
   "source": [
    "# the numerical arguments we pass to these constructors\n",
    "# determine the shape of the output tensor\n",
    "\n",
    "x = torch.ones(5, 3)\n",
    "y = torch.zeros(2)\n",
    "z = torch.empty(1,1,5)\n",
    "print(\"Tensor x:\" ,x)\n",
    "print(\"Tensor y:\" ,y)\n",
    "print(\"Tensor z:\" ,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that ```.empty()``` does not return zeros, but seemingly random small numbers. Unlike ```.zeros()```, which initialises the elements of the tensor with zeros, ```.empty()``` just allocates the memory. It is hence faster if you are looking to just create a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating random tensors and tensors like other tensors:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4e705d4b-690d-4acb-d277-116c72e3ab60"
   },
   "outputs": [],
   "source": [
    "# there are also constructors for random numbers\n",
    "\n",
    "# uniform distribution\n",
    "a = torch.rand(1,3)\n",
    "\n",
    "# normal distribution\n",
    "b = torch.randn(3,4)\n",
    "\n",
    "# there are also constructors that allow us to construct\n",
    "# a tensor according to the above constructors, but with\n",
    "# dimensions equal to another tensor\n",
    "\n",
    "c = torch.zeros_like(a)\n",
    "d = torch.rand_like(c)\n",
    "\n",
    "print(\"Tensor a: \", a)\n",
    "print(\"Tensor b: \", b)\n",
    "print(\"Tensor c: \", c)\n",
    "print(\"Tensor d: \", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numpy-like number ranges:**\n",
    "---\n",
    "The ```.arange()``` and ```.linspace()``` behave how you would expect them to if you are familar with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dcaab011-3ced-4dde-9594-f855705bbbf8"
   },
   "outputs": [],
   "source": [
    "a = torch.arange(0,10,step=1)\n",
    "b = np.arange(0,10,step=1)\n",
    "\n",
    "c = torch.linspace(0,5,steps=11)\n",
    "d = np.linspace(0,5,num=11)\n",
    "\n",
    "print(\"Tensor a: \", a)\n",
    "print(\"Numpy array b: \", b)\n",
    "print(\"Tensor c: \", c)\n",
    "print(\"Numpy array d: \", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 1: Creating Tensors\n",
    "\n",
    "Below you will find some incomplete code. Fill in the missing code to construct the specified tensors.\n",
    "\n",
    "We want the tensors: \n",
    "\n",
    "$A:$ 20 by 21 tensor consisting of ones\n",
    "\n",
    "$B:$ a tensor with elements equal to the elements of numpy array $Z$\n",
    "\n",
    "$C:$ a tensor with the same number of elements as $A$ but with values $\n",
    "\\sim U(0,1)$\n",
    "\n",
    "$D:$ a 1D tensor containing the even numbers between 4 and 40 inclusive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_creation(Z):\n",
    "  \"\"\"A function that creates various tensors.\n",
    "\n",
    "  Args:\n",
    "    Z (numpy.ndarray): An array of shape\n",
    "\n",
    "  Returns:\n",
    "    A : 20 by 21 tensor consisting of ones\n",
    "    B : a tensor with elements equal to the elements of numpy array  Z\n",
    "    C : a tensor with the same number of elements as A but with values ∼U(0,1)\n",
    "    D : a 1D tensor containing the even numbers between 4 and 40 inclusive.\n",
    "  \"\"\"\n",
    "  #################################################\n",
    "  ## TODO for students: fill in the missing code\n",
    "  ## from the first expression\n",
    "  raise NotImplementedError(\"Student exercise: say what they should have done\")\n",
    "  #################################################\n",
    "  A = ...\n",
    "  B = ...\n",
    "  C = ...\n",
    "  D = ...\n",
    "\n",
    "  return A, B, C, D\n",
    "\n",
    "# numpy array to copy later\n",
    "Z = np.vander([1,2,3], 4)\n",
    "\n",
    "# Uncomment below to check your function!\n",
    "# A, B, C, D = tensor_creation(Z)\n",
    "# checkExercise1(A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4e4de3f1-92f9-4388-b2ac-ecc02a97a578"
   },
   "outputs": [],
   "source": [
    "# to remove solution\n",
    "\n",
    "def tensor_creation(Z):\n",
    "  \"\"\"A function that creates various tensors.\n",
    "\n",
    "  Args:\n",
    "    Z (numpy.ndarray): An array of shape\n",
    "\n",
    "  Returns:\n",
    "    A : 20 by 21 tensor consisting of ones\n",
    "    B : a tensor with elements equal to the elements of numpy array  Z\n",
    "    C : a tensor with the same number of elements as A but with values ∼U(0,1)\n",
    "    D : a 1D tensor containing the even numbers between 4 and 40 inclusive.\n",
    "  \"\"\"\n",
    "  A = torch.ones(20,21)\n",
    "  B = torch.tensor(Z)\n",
    "  C = torch.rand_like(A)\n",
    "  D = torch.arange(4,41,step=2)\n",
    "\n",
    "  return A, B, C, D\n",
    "\n",
    "# numpy array to copy later\n",
    "Z = np.vander([1,2,3], 4)\n",
    "\n",
    "# Uncomment below to check your function!\n",
    "A, B, C, D = tensor_creation(Z)\n",
    "checkExercise1(A, B, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2: Operations in PyTorch\n",
    "\n",
    "**Tensor-Tensor operations**\n",
    "\n",
    "We can perform operations on tensors using methods under ```torch.``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "c481dfd7-386c-41ff-8dc7-dc3c0e28e5d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 2.2: Tensor Operators\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"R1R8VoYXBVA\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor-Tensor operations**\n",
    "\n",
    "We can perform operations on tensors using methods under ```torch.``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "49c8daf9-3590-4e5a-ce05-e1730504e582"
   },
   "outputs": [],
   "source": [
    "a = torch.ones(5, 3)\n",
    "b = torch.rand(5, 3)\n",
    "c = torch.empty(5, 3)\n",
    "d = torch.empty(5, 3)\n",
    "\n",
    "torch.add(a, b, out=c)\n",
    "torch.multiply(a,b, out=d)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in PyTorch most common Python operators are overridden.\n",
    "The common standard arithmetic operators (+, -, *, /, and **) have all been lifted to elementwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3f9f3f2d-4dfd-4c71-c2e4-921a376e8657"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x**y  # The ** operator is exponentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors also have a number of common arithmetic operations built in. A full list of **all** methods can be found  in the appendix (there are a lot!) \n",
    "\n",
    "All of these operations should have similar syntax to their numpy equivalents.(Feel free to skip if you already know this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7e5e9759-0ad8-47fc-9b5b-0900a260bb99"
   },
   "outputs": [],
   "source": [
    "x = torch.rand(3,3)\n",
    "print(x)\n",
    "print(\"\\n\")\n",
    " # sum() - note the axis is the axis you move across when summing\n",
    "print(\"Sum of every element of x: \", x.sum())\n",
    "print(\"Sum of the columns of x: \", x.sum(axis=0))\n",
    "print(\"Sum of the rows of x: \", x.sum(axis=1))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean value of all elements of x \", x.mean())\n",
    "print(\"Mean values of the columns of x \", x.mean(axis=0))\n",
    "print(\"Mean values of the rows of x \", x.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Operations**\n",
    "\n",
    "The ```@``` symbol is overridden to represent matrix multiplication. You can also use ```torch.matmul()``` to multiply tensors. For dot multiplication, you can use ```.torch.dot()```, or manipulate the axes of your tensors and do matrix multiplication (we will cover that in the next section). \n",
    "\n",
    "Transposes of 2D tensors are obtained using ```torch.t()``` or ```Tensor.t```. Note the lack of brackets for ```Tensor.t``` - it is an attribute, not a method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 : Simple tensor operations\n",
    "\n",
    "Below are two expressions involving operations on matrices. \n",
    "\n",
    "$$ \\textbf{A} = \n",
    "\\begin{bmatrix}2 &4 \\\\5 & 7 \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix} 1 &1 \\\\2 & 3\n",
    "\\end{bmatrix} \n",
    " + \n",
    "\\begin{bmatrix}10 & 10  \\\\ 12 & 1 \n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "and\n",
    "\n",
    "\n",
    "$$ b = \n",
    "\\begin{bmatrix} 3 \\\\ 5 \\\\ 7\n",
    "\\end{bmatrix} \\cdot \n",
    "\\begin{bmatrix} 2 \\\\ 4 \\\\ 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The code block below that computes these expressions using PyTorch is incomplete - fill in the missing lines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing expression 1:\n",
    "\n",
    "# init our tensors\n",
    "a1 = torch.tensor([[2, 4], [5, 7]])\n",
    "\n",
    "def simple_operations(a1):\n",
    "################################################\n",
    "## TODO for students: create the a2 and a3 matrices\n",
    "## from the first expression\n",
    "  raise NotImplementedError(\"Student exercise: fill in the missing code to complete the operation\")\n",
    "  a2 = ...\n",
    "  a3 = ...\n",
    "\n",
    "  answer = ...\n",
    "  return answer\n",
    "\n",
    "## TODO for students: complete the function above and assign\n",
    "## the result to a tensor named A\n",
    "\n",
    "#A = simple_operations(a1)\n",
    "\n",
    "#print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d79e8ca7-733c-4fb7-bd0e-00ae943872a3"
   },
   "outputs": [],
   "source": [
    "# to remove solution\n",
    "\n",
    "# Computing expression 1:\n",
    "\n",
    "# init our tensors\n",
    "a1 = torch.tensor([[2, 4], [5, 7]])\n",
    "\n",
    "def simple_operations(a1):\n",
    "################################################\n",
    "## TODO for students: create the a2 and a3 matrices\n",
    "## from the first expression\n",
    "  a2 = torch.tensor([[1,1], [2,3]])\n",
    "  a3 = torch.tensor([[10,10],[12,1]])\n",
    "\n",
    "  return a1@a2+a3\n",
    "\n",
    "## TODO for students: compute the expression above and assign\n",
    "## the result to a tensor named A\n",
    "\n",
    "A = simple_operations(a1)\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing expression 2:\n",
    "\n",
    "def dot_product():\n",
    "###############################################\n",
    "## TODO for students: create the b1 and b2 matrices\n",
    "## from the second expression\n",
    "  raise NotImplementedError(\"Student exercise: fill in the missing code to complete the operation\")\n",
    "  b1 = ...\n",
    "  b2 = ...\n",
    "  product = ...\n",
    "  return product\n",
    "\n",
    "## TODO for students: compute the expression above and assign\n",
    "## the result to a tensor named b\n",
    "\n",
    "#b = dot_product()\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8775fa02-9ba1-46ab-e89b-7d320b2549aa"
   },
   "outputs": [],
   "source": [
    "# to remove solution\n",
    "\n",
    "# Computing expression 2:\n",
    "\n",
    "def dot_product():\n",
    "###############################################\n",
    "## TODO for students: create the b1 and b2 matrices\n",
    "## from the second expression\n",
    "\n",
    "  b1 = torch.tensor([3,5,7])\n",
    "  b2 = torch.tensor([2,4,8])\n",
    "  product = torch.dot(b1,b2)\n",
    "  return product\n",
    "\n",
    "## TODO for students: compute the expression above and assign\n",
    "## the result to a tensor named b\n",
    "\n",
    "b = dot_product()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3 Manipulating Tensors in Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "df0a3689-5680-48c1-aed3-7ea0931eb74d"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 2.3: Tensor Indexing\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"0d0KSJ3lJbg\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indexing**\n",
    "\n",
    "Just as in numpy, elements in a tensor can be accessed by index. As in any numpy array, the first element has index 0 and ranges are specified to include the first but before the last element. We can access elements according to their relative position to the end of the list by using negative indices.\n",
    "\n",
    "For example, [-1] selects the last element; [1:3] selects the second and the third elements, and [:-2] will select all elements excluding the last and second-to-last elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d90e4e88-e982-465d-c3ee-bbb422624335"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(0, 10)\n",
    "print(x)\n",
    "print(x[-1])\n",
    "print(x[1:3])\n",
    "print(x[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have multidimensional tensors, indexing rules work the same way as numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7740a8f5-69e6-43dd-c7a1-5cbe8a583106"
   },
   "outputs": [],
   "source": [
    "# make a 5D tensor\n",
    "x = torch.rand(1,2,3,4,5)\n",
    "\n",
    "print(\" shape of x[0]:\", x[0].shape)\n",
    "print(\" shape of x[0][0]:\", x[0][0].shape)\n",
    "print(\" shape of x[0][0][0]:\", x[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten and reshape**\n",
    "\n",
    "There are various methods for reshaping tensors. It is common to have to express 2D data in 1D format. Similarly, it is also common to have to reshape a 1D tensor into a 2D tensor. We can achieve this with the ```.flatten()``` and ```.reshape()``` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a40e4151-9576-4a57-cbf7-0ac3b4c54608"
   },
   "outputs": [],
   "source": [
    "z = torch.arange(12).reshape(6,2)\n",
    "print(\"Original z: \\n \", z)\n",
    "\n",
    "# 2D -> 1D\n",
    "z = z.flatten()\n",
    "print(\"Flattened z: \\n \", z)\n",
    "\n",
    "# and back to 2D\n",
    "z = z.reshape(3, 4)\n",
    "print(\"Reshaped (3x4) z: \\n\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also see the ```.view()``` methods used a lot to reshape tensors. There is a subtle difference between ```.view()``` and ```.reshape()```, though for now we will just use ```.reshape()```. The documentation can be found in the appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Squeezing tensors**\n",
    "\n",
    "When processing batches of data, you will quite often be left with singleton dimensions. e.g. [1,10] or [256, 1, 3]. This dimension can quite easilly mess up your matrix operations if you don't plan on it being there...\n",
    "\n",
    "In order to compress tensors along their singleton dimensions we can use the ```.squeeze()``` method. We can use the ```.unsqueeze()``` method to do the opposite. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8b94b708-4750-43dd-a843-e883b0817a50"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(1,10)\n",
    "# printing the zeroth element of the tensor will not give us the first number!\n",
    "\n",
    "print(x.shape)\n",
    "print(\"x[0]: \",x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Because of that pesky singleton dimension, x[0] gave us the first row instead!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4148a076-d233-48fe-a78d-e262b2d0db0a"
   },
   "outputs": [],
   "source": [
    "# lets get rid of that singleton dimension and see what happens now\n",
    "x = x.squeeze(0)\n",
    "print(x.shape)\n",
    "print(\"x[0]: \", x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "03c1b7f9-2dfe-4043-eedc-a0cf67bfddfc"
   },
   "outputs": [],
   "source": [
    "# adding singleton dimensions works a similar way, and is often used when tensors\n",
    "# being added need same number of dimensions\n",
    "\n",
    "y = torch.randn(5,5)\n",
    "print(\"shape of y: \", y.shape)\n",
    "\n",
    "# lets insert a singleton dimension\n",
    "y = y.unsqueeze(1)\n",
    "print(\"shape of y: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Permutation**\n",
    "Sometimes our dimensions will be in the wrong order! For example, we may be dealing with RGB images with dim [3x48x64], but our pipeline expects the colour dimension to be the last dimension i.e. [48x64x3]. To get around this we can use ```.permute()```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5563f6e2-2e19-4768-961a-7ee523ebb255"
   },
   "outputs": [],
   "source": [
    "# `x` has dimensions [color,image_height,image_width]\n",
    "x = torch.rand(3,48,64)\n",
    "\n",
    "# we want to permute our tensor to be [ image_height , image_width , color ]\n",
    "x = x.permute(1,2,0)\n",
    "# permute(1,2,0) means:\n",
    "# the 0th dim of my new tensor = the 1st dim of my old tensor\n",
    "# the 1st dim of my new tensor = the 2nd\n",
    "# the 2nd dim of my new tensor = the 0th\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we concatenate two matrices along rows (axis 0, the first element of the shape) vs. columns (axis 1, the second element of the shape). We can see that the first output tensor’s axis-0 length ( 6 ) is the sum of the two input tensors’ axis-0 lengths ( 3+3 ); while the second output tensor’s axis-1 length ( 8 ) is the sum of the two input tensors’ axis-1 lengths ( 4+4 )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6bc91e43-5fb7-4e89-8a95-3c23d517bccc"
   },
   "outputs": [],
   "source": [
    "# Create two tensors of the same shape\n",
    "x = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "\n",
    "#concatenate them along rows\n",
    "cat_rows = torch.cat((x, y), dim=0 )\n",
    "\n",
    "# concatenate along columns\n",
    "cat_cols = torch.cat((x, y), dim=1 )\n",
    "\n",
    "# printing outputs\n",
    "print('Concatenated by rows: shape{} \\n {}'.format(list(cat_rows.shape),cat_rows))\n",
    "print('\\n Concatenated by colums: shape{}  \\n {}'.format(list(cat_cols.shape),cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion to Other Python Objects**\n",
    "\n",
    "Converting to a NumPy tensor, or vice versa, is easy. The converted result does not share memory. This minor inconvenience is actually quite important: when you perform operations on the CPU or on GPUs, you do not want to halt computation, waiting to see whether the NumPy package of Python might want to be doing something else with the same chunk of memory.\n",
    "\n",
    "When converting to a numpy array, the information being tracked by the tensor will be lost i.e. the computational graph. This will be covered in detail when you are introduced to autograd tomorrow! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cc63c778-8281-49e0-dda3-f1b25e3ace95"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(5)\n",
    "print(f\"x: {x}  |  x type:  {x.type()}\")\n",
    "\n",
    "y = x.numpy()\n",
    "print(f\"y: {y}  |  y type:  {type(y)}\")\n",
    "\n",
    "z = torch.tensor(y)\n",
    "print(f\"z: {z}  |  z type:  {z.type()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a size-1 tensor to a Python scalar, we can invoke the item function or Python’s built-in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0831ac35-07e8-4873-ab0d-096502f27923"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Manipulating Tensors\n",
    "Using a combination of the methods discussed above, complete the functions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function A** \n",
    "\n",
    "This function takes in two 2D tensors $A$ and $B$ and returns the column sum of A multiplied by the sum of all the elmements of $B$ i.e. a scalar. e.g:\n",
    "\n",
    " $ A = \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1 \n",
    "\\end{bmatrix}$  $ B = \\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "1 & 2 & 3 \n",
    "\\end{bmatrix}$\n",
    "$ Out = 12 *  \\begin{bmatrix}\n",
    "2 & 2\\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "24 & 24\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "**Function B** \n",
    "\n",
    "This function takes in a square matrix $C$ and returns a 2D tensor consisting of a flattened $C$ with the index of each element appended to this tensor in the row dimension. e.g:\n",
    "\n",
    " $ C = \\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "-1 & 10 \n",
    "\\end{bmatrix}$\n",
    " $ Out = \\begin{bmatrix}\n",
    "0 & 2 \\\\\n",
    "1 & 3 \\\\\n",
    "2 & -1 \\\\\n",
    "3 & 10\n",
    "\\end{bmatrix}$\n",
    "\n",
    "**Hint:** pay close attention to singleton dimensions\n",
    "\n",
    "**Function C (maybe cut this depending on time constraints)**\n",
    "\n",
    "This function takes in two 2D tensors $D$ and $E$. If the dimensions allow it, this function returns the elementwise sum of $E$ reshaped into the dimensions of $D$, and $D$; else this function returns a 1D tensor that is the concatenation of the two tensors. e.g.\n",
    "\n",
    " $ D = \\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "-1 & 3 \n",
    "\\end{bmatrix}$\n",
    " $ E = \\begin{bmatrix}\n",
    "2 & 3 & 0 & 2 \\\\\n",
    "\\end{bmatrix}$\n",
    " $ Out = \\begin{bmatrix}\n",
    "3 & 2 \\\\\n",
    "-1 & 5 \n",
    "\\end{bmatrix}$\n",
    "\n",
    " $ D = \\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "-1 & 3 \n",
    "\\end{bmatrix}$\n",
    " $ E = \\begin{bmatrix}\n",
    "2 & 3 & 0  \\\\\n",
    "\\end{bmatrix}$\n",
    " $ Out = \\begin{bmatrix}\n",
    "1 & -1 & -1 & 3  & 2 & 3 & 0  \n",
    "\\end{bmatrix}$\n",
    "\n",
    "**Hint:** ```torch.numel()``` is an easy way of finding the number of elements in a tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## TODO for students: complete these functions\n",
    "\n",
    "def functionA(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n",
    "  ## TODO for students\n",
    "  raise NotImplementedError(\"Student exercise: complete function A\")\n",
    "  output = torch.zeros(2)\n",
    "  return output\n",
    "\n",
    "def functionB(C: torch.Tensor) -> torch.Tensor:\n",
    "  raise NotImplementedError(\"Student exercise: complete function B\")\n",
    "\n",
    "  # TODO flatten the tensor  C\n",
    "  C = ...\n",
    "\n",
    "  # TODO create the idx tensor to be concatenated to C\n",
    "  idx_tensor = ...\n",
    "\n",
    "  # TODO concatenate the two tensors\n",
    "  output = ...\n",
    "\n",
    "  output = torch.zeros(1)\n",
    "  return output\n",
    "\n",
    "def functionC(D: torch.Tensor, E: torch.Tensor) -> torch.Tensor:\n",
    "  raise NotImplementedError(\"Student exercise: complete function C\")\n",
    "  # TODO check we can reshape E into the shape of D\n",
    "  if ... :\n",
    "    # TODO reshape E into the shape of D\n",
    "    E = ...\n",
    "\n",
    "    # TODO sum the two tensors\n",
    "    output = ...\n",
    "\n",
    "  else:\n",
    "    # TODO flatten both tensors\n",
    "    D = ...\n",
    "    E = ...\n",
    "\n",
    "    # TODO concatenate the two tensors in the correct dimension\n",
    "    output = ...\n",
    "\n",
    "  return output\n",
    "\n",
    "##TODO: Implement the functions above and then uncomment the following lines to test your code\n",
    "#print(functionA(torch.tensor([[1,1], [1,1]]), torch.tensor([ [1,2,3],[1,2,3] ]) ))\n",
    "#print(functionB(torch.tensor([ [2,3],[-1,10] ])))\n",
    "#print(functionC(torch.tensor([[1, -1],[-1,3]]), torch.tensor([[2,3,0,2]])))\n",
    "#print(functionC(torch.tensor([[1, -1],[-1,3]]), torch.tensor([[2,3,0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9ef88eeb-72c4-4c30-c4b6-ffdfd2e6207e"
   },
   "outputs": [],
   "source": [
    "# to remove solution\n",
    "\n",
    "def functionA(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n",
    "  ## TODO for students\n",
    "  output = A.sum(axis = 0) * B.sum()\n",
    "  return output\n",
    "\n",
    "def functionB(C: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "\n",
    "  # TODO flatten the tensor  C\n",
    "  C = C.flatten()\n",
    "\n",
    "  # TODO create the idx tensor to be concatenated to C\n",
    "\n",
    "  # here we're going to do flatten and unsqueeze, but reshape can also be used\n",
    "  idx_tensor = torch.arange(0, len(C))\n",
    "\n",
    "  # TODO concatenate the two tensors\n",
    "  output = torch.cat([idx_tensor.unsqueeze(0), C.unsqueeze(0)], axis = 1)\n",
    "\n",
    "  return output\n",
    "\n",
    "def functionC(D: torch.Tensor, E: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "  # TODO check we can reshape E into the shape of D\n",
    "  if torch.numel(D) == torch.numel(E) :\n",
    "    # TODO reshape E into the shape of D\n",
    "    E = E.reshape(D.shape)\n",
    "\n",
    "    # TODO sum the two tensors\n",
    "    output = D + E\n",
    "\n",
    "  else:\n",
    "    # TODO flatten both tensors\n",
    "    # this time we'll use reshape to keep the singleton dimension\n",
    "    D = D.reshape(1,-1)\n",
    "    E = E.reshape(1,-1)\n",
    "\n",
    "    # TODO concatenate the two tensors in the correct dimension\n",
    "    output = torch.cat([D,E], axis = 1)\n",
    "\n",
    "  return output\n",
    "\n",
    "print(functionA(torch.tensor([[1,1], [1,1]]), torch.tensor([ [1,2,3],[1,2,3] ]) ))\n",
    "print(functionB(torch.tensor([ [2,3],[-1,10] ])))\n",
    "print(functionC(torch.tensor([[1, -1],[-1,3]]), torch.tensor([[2,3,0,2]])))\n",
    "print(functionC(torch.tensor([[1, -1],[-1,3]]), torch.tensor([[2,3,0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.4: GPUs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "eb01d837-e093-404f-9e66-7c39e9c5f96b"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 2.4: GPU vs CPU\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"9Mc9GFUtILY\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "By default, when we create a tensor it will *not* live on the GPU! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9b528b0d-8d2a-40fb-db5b-ca8e1d06043f"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(10)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Colab notebooks by default will note have access to a GPU. In order to start using GPUs we need to request one. We can do this by going to the runtime tab at the top of the page. \n",
    "\n",
    "By following Runtime -> Change runtime type and selecting \"GPU\" from the Hardware Accelerator dropdown list, we can start playing with sending tensors to GPUs.\n",
    "\n",
    "Once you have done this your runtime will restart and you will need to rerun the first setup cell to reimport PyTorch. Then proceed to the next cell.\n",
    "\n",
    "(For more information on the GPU usage policy you can view in the appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have a GPU**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below should return True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "37d4df71-c1cf-4f91-ec8e-385560b6beb0"
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA is an API developed by Nvidia for interfacing with GPUs. PyTorch provides us with a layer of abstraction, and allows us to launch CUDA kernels using pure Python. *NOTE I am assuming that GPU stuff might be covered in more detail on another day but there could be a bit more detail here*\n",
    "\n",
    "In short, we get the power of parallising our tensor computations on GPUs, whilst only writing (relatively) simple Python!\n",
    "\n",
    "Let's make some CUDA tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3bceaa3d-a67f-4ff9-df17-f99d4442445b"
   },
   "outputs": [],
   "source": [
    "# common device agnostic way of writing code that can run on cpu OR gpu\n",
    "# that we provide for you in each of the tutorials\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# we can specify a device when we first create our tensor\n",
    "x = torch.randn(2,2, device=device)\n",
    "print(x.dtype)\n",
    "print(x.device)\n",
    "\n",
    "# we can also use the .to() method to change the device a tensor lives on\n",
    "y = torch.randn(2,2)\n",
    "print(f\"y before calling to() |  device: {y.device} | dtype: {y.type()}\")\n",
    "\n",
    "y = y.to(device)\n",
    "print(f\"y after calling to() |  device: {y.device} | dtype: {y.type()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Operations between cpu tensors and cuda tensors**\n",
    "\n",
    "Note that the type of the tensor changed after calling ```.to()```. What happens if we try and perform operations on tensors on devices?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0,1,2], device=\"cuda\")\n",
    "y = torch.tensor([3,4,5], device=\"cpu\")\n",
    "\n",
    "#Uncomment the following line and run this cell\n",
    "#z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot combine cuda tensors and cpu tensors in this fashion. If we want to compute an operation that combines tensors on different devices, we need to move them first! We can use the ```.to()``` method as before, or the ```.cpu()``` and ```.cuda()``` methods.\n",
    "\n",
    "Genrally in this course all Deep learning is done on the GPU and any computation is done on the CPU, so sometimes we have to pass things back and forth so you'll see us call\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e2ea68a0-9c2b-4e7a-c151-b0301103a5b0"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([0,1,2], device=\"cuda\")\n",
    "y = torch.tensor([3,4,5], device=\"cpu\")\n",
    "z = torch.tensor([6,7,8], device=\"cuda\")\n",
    "\n",
    "# moving to cpu\n",
    "x = x.cpu()\n",
    "print(x + y)\n",
    "\n",
    "# moving to gpu\n",
    "y = y.cuda()\n",
    "print(y + z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Exercise 4: Just how much faster are GPUs?\n",
    "\n",
    "Below is a simple function. Complete the second function, such that it is performs the same operations as the first function, but entirely on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleFun():\n",
    "  x = torch.rand(10000,10000)\n",
    "  y = torch.rand_like(x)\n",
    "  z = 2*torch.ones(10000,10000)\n",
    "\n",
    "  x = x * y\n",
    "  x = x @ z\n",
    "\n",
    "\n",
    "def simpleFunGPU():\n",
    "  ###############################################\n",
    "  ## TODO for students: recreate the above function, but\n",
    "  ## ensure all computation happens  on the GPU\n",
    "\n",
    "  x = ...\n",
    "  y = ...\n",
    "  z = ...\n",
    "\n",
    "  x = ...\n",
    "  y = ...\n",
    "  raise NotImplementedError(\"Student exercise: fill in the missing code to create the tensors\")\n",
    "\n",
    "##TODO: Implement the function above and uncomment the following lines to test your code\n",
    "#timeFun(simpleFun, iterations = 1 )\n",
    "#timeFun(simpleFunGPU, iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "611785b6-ee8e-423a-a566-e48ffe791999"
   },
   "outputs": [],
   "source": [
    "#to remove solution\n",
    "def simpleFun():\n",
    "  x = torch.rand(10000,10000)\n",
    "  y = torch.rand_like(x)\n",
    "  z = 2*torch.ones(10000,10000)\n",
    "\n",
    "  x = x * y\n",
    "  x = x @ z\n",
    "\n",
    "\n",
    "def simpleFunGPU():\n",
    "  x = torch.rand(10000,10000).to(\"cuda\")\n",
    "  y = torch.rand_like(x).to(\"cuda\")\n",
    "  z = 2*torch.ones(10000,10000).to(\"cuda\")\n",
    "\n",
    "  x = x * y\n",
    "  x = x @ z\n",
    "\n",
    "timeFun(simpleFun, iterations = 1)\n",
    "timeFun(simpleFunGPU, iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.5: Datasets and Dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "b554ddf5-cb16-4cab-f37c-49f232481bed"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 2.5: Getting Data\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"LSkjPM1gFu0\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training neural network models you will be working with large amounts of data. Fortunately, PyTorch offers some great tools that help you organize and manipulate your data samples.\n",
    "\n",
    "**Datasets**\n",
    "\n",
    "The `torchvision` package gives you easy access to many of the publicly available datasets. Let's load the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset, which contains color images of 10 different classes, like vehicles and animals.\n",
    "\n",
    "Creating an object of type `datasets.CIFAR10` will automatically download and load all images from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d110d97e-4135-4d25-b3b9-eb7ddff60b84"
   },
   "outputs": [],
   "source": [
    "# Download and load the images from the CIFAR10 dataset\n",
    "cifar10_data = datasets.CIFAR10(\n",
    "    root=\"data\",            # path where the images will be stored\n",
    "    download=True,          # all images should be downloaded\n",
    "    transform=ToTensor()    # transform the images to tensors\n",
    ")\n",
    "\n",
    "# Print the number of samples in the loaded dataset\n",
    "print('Number of samples:', len(cifar10_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 50000 samples loaded. Now let's take a look at one of them in detail. Each sample consists of an image and its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6e919240-2ab2-4491-d688-6a3b435049a7"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Predefined label names\n",
    "cifar10_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Choose a random sample\n",
    "image, label = cifar10_data[random.randint(0, len(cifar10_data))]\n",
    "print('Label:', cifar10_labels[label])\n",
    "print('Image size:', image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color images are modeled as 3 dimensional tensors. The first dimension corresponds to the channels of the image (in this case we have RGB images). The second dimensions is the height of the image and the third is the width. We can denote this image format as C × H × W.\n",
    "\n",
    "### Exercise 5: Display an image from the dataset\n",
    "\n",
    "Let's try to display the image using `matplotlib`. The code below will not work, because `imshow` expects to have the image in a different format - H × W × C.\n",
    "\n",
    "You need to reorder the dimensions of the tensor using the `permute` method of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the following line to see the error that arises from the current image format\n",
    "# plt.imshow(image)\n",
    "\n",
    "# TODO: Comment the above line and fix this code by reordering the tensor dimensions\n",
    "# plt.imshow(image.permute(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "text",
    "outputId": "ee53bc66-0867-455d-d38a-97fe77c70626"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D1_Basics/solutions/W1D1_Tutorial_Solution_8adb99e9.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=251 height=249 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D1_Basics/static/W1D1_Tutorial_Solution_8adb99e9_1.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "69aa4911-9967-4806-c640-60eb604d509e"
   },
   "outputs": [],
   "source": [
    "#@title Video 2.6: Train and Test\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"JokSIuPs-ys\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Test Datasets**\n",
    "\n",
    "When loading a dataset, you can specify if you want to load the training or the test samples using the `train` argument. We can load the training and test datasets separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9fab3caf-fc84-4e61-ab10-d742c363e7ae"
   },
   "outputs": [],
   "source": [
    "# Load the training samples\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# Load the test samples\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "1927a660-b665-472f-c541-37e398c9468b"
   },
   "outputs": [],
   "source": [
    "#@title Video 2.7: Data Augmentation - Transformations\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"sjegA9OBUPw\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloader**\n",
    "\n",
    "Another important concept is the `Dataloader`. It is a wrapper around the `Dataset` that splits it into minibatches (important for training the neural network) and makes the data iterable. The `shuffle` argument is used to shuffle the order of the samples across the minibatches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders with\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query the next batch from the data loader and inspect it. We can now see that we have a 4D tensor. This is because we have a 64 images in the batch and each image has 3 dimensions: channels, height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "outputId": "73ea2f89-3ab7-4e1e-a158-09c8b1e299c9"
   },
   "outputs": [],
   "source": [
    "# Load the next batch\n",
    "batch_images, batch_labels = next(iter(train_dataloader))\n",
    "print('Batch size:', batch_images.shape)\n",
    "\n",
    "# Display the first image from the batch\n",
    "plt.imshow(batch_images[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformations**\n",
    "\n",
    "Another useful feature when loading a dataset is applying transformations on the data - color conversions, normalization, cropping, rotation etc. There are many predefined transformations in the `torchvision.transforms` package and you can also combine them using the `Compose` transform.\n",
    "\n",
    "### Exercise 6: Load the CIFAR10 dataset as grayscale images\n",
    "\n",
    "The goal of this excercise is to load the images from the CIFAR10 dataset as grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Grayscale\n",
    "\n",
    "# TODO Load the CIFAR10 data using a transform that converts the images to grayscale tensors\n",
    "# data = datasets.CIFAR10( ...\n",
    "\n",
    "# TODO After implementing the above code, uncomment the following lines to test your code\n",
    "# Display a random grayscale image\n",
    "# image, label = data[random.randint(0, len(data))]\n",
    "# plt.imshow(image.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "text",
    "outputId": "45c8cc8f-85ac-4f4e-e942-7492afaacb28"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D1_Basics/solutions/W1D1_Tutorial_Solution_1d2870c1.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=251 height=249 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D1_Basics/static/W1D1_Tutorial_Solution_1d2870c1_2.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Section 3:  Neural Networks\n",
    "\n",
    "Now it's time for you to create your first neural network using PyTorch. This section will walk you through the process of:\n",
    "- Creating a simple neural network model\n",
    "- Training the network\n",
    "- Visualizing the results of the network\n",
    "- Tweeking the network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "918ad92c-3fd3-4279-99e0-ee4d12664b95"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 3.1: CSV Files\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"JrC_UAJWYKU\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.1: Data Loading\n",
    "\n",
    "First we need some sample data to train our network on. You can use the function below to generate an example dataset consisting of 2D points along two interleaving half circles. The data will be stored in a file called `sample_data.csv`. You can inspect the file directly in Colab by going to Files on the left side and opening the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Generate sample data\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataset of 256 points with a little noise\n",
    "X, y = sklearn.datasets.make_moons(256, noise=0.1)\n",
    "\n",
    "# Store the data as a Pandas data frame and save it to a CSV file\n",
    "df = pd.DataFrame(dict(x0=X[:,0], x1=X[:,1], y=y))\n",
    "df.to_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the data from the CSV file using the Pandas library. Pandas provides many functions for reading files in varios formats. When loading data from a CSV file, we can reference the columns directly by their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "outputId": "1ed6f3f2-47bb-48a9-a2dd-20b86f5ca7ff"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file in a Pandas DataFrame\n",
    "data = pd.read_csv(\"sample_data.csv\")\n",
    "\n",
    "# Create a 2D numpy array from the x0 and x1 columns\n",
    "X_orig = data[[\"x0\", \"x1\"]].to_numpy()\n",
    "\n",
    "# Create a 1D numpy array from the y column\n",
    "y_orig = data[\"y\"].to_numpy()\n",
    "\n",
    "# Print the sizes of the generated 2D points X and the corresponding labels Y\n",
    "print(\"Size X:\", X_orig.shape)\n",
    "print(\"Size y:\", y_orig.shape)\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.scatter(X_orig[:,0], X_orig[:,1], s=40, c=y_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data for PyTorch**\n",
    "\n",
    "Now let's prepare the data in a format suitable for PyTorch - convert everything into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9d075713-d833-4124-9f3f-92ad884f4ff5"
   },
   "outputs": [],
   "source": [
    "# Convert the 2D points to a float tensor\n",
    "X = torch.from_numpy(X_orig).type(torch.FloatTensor)\n",
    "# Upload the tensor to the device\n",
    "X = X.to(device)\n",
    "\n",
    "print(\"Size X:\", X.shape)\n",
    "\n",
    "# Convert the labels to a long interger tensor\n",
    "y = torch.from_numpy(y_orig).type(torch.LongTensor)\n",
    "# Upload the tensor to the device\n",
    "y = y.to(device)\n",
    "\n",
    "print(\"Size y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "f3f49352-add0-49a6-9372-e93187f599d6"
   },
   "outputs": [],
   "source": [
    "#@title Video 3.2: Generating the Neural Network\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"PwSzRohUvck\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Section 3.2: Create a Simple Neural Network\n",
    "\n",
    "For this example we want to have a simple neural network consisting of 3 layers:\n",
    "- 1 input layer of size 2 (our points have 2 coordinates)\n",
    "- 1 hidden layer of size 16 (you can play with different numbers here)\n",
    "- 1 output layer of size 2 (we want the have the scores for the two classes)\n",
    "\n",
    "**Programing the Network**\n",
    "\n",
    "PyTorch provides a base class for all neural network modules called [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). You need to inherit from `nn.Module` and implement some important methods:\n",
    "\n",
    "#### `__init__`\n",
    "\n",
    "In the `__init__` method you need to define the structure of your network. Here you will specify what layers will the network consist of, what activation functions will be used etc.\n",
    "\n",
    "#### `forward`\n",
    "\n",
    "All neural network modules need to implement the `forward` method. It specifies the computations the network needs to do when data is passed through it.\n",
    "\n",
    "#### `predict`\n",
    "\n",
    "This is not an obligatory method of a neural network module, but it is a good practice if you want to interpret the result of the network as a probability distribution.\n",
    "\n",
    "#### `train`\n",
    "\n",
    "This is also not an obligatory method, but it is a good practice to have. The method will be used to train the network parameters and will be implemented later in the notebook.\n",
    "\n",
    "\n",
    "> Note that you can use the `__call__` method of a module directly and it will invoke the `forward` method: `net()` does the same as `net.forward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Inherit from nn.Module - the base class for neural network modules provided by Pytorch\n",
    "class NaiveNet(nn.Module):\n",
    "\n",
    "  # Define the structure of your network\n",
    "  def __init__(self):\n",
    "    super(NaiveNet, self).__init__()\n",
    "\n",
    "    # The network is defined as a sequence of operations\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Linear(2, 16), # Transformation from the input to the hidden layer\n",
    "        nn.ReLU(),        # Activation function (ReLU)\n",
    "        nn.Linear(16, 2), # Transformation from the hidden to the output layer\n",
    "    )\n",
    "\n",
    "  # Specify the computations performed on the data\n",
    "  def forward(self, x):\n",
    "    # Pass the data through the layers\n",
    "    return self.layers(x)\n",
    "\n",
    "  # Convert the output of the network to a probability distribution\n",
    "  def predict(self, x):\n",
    "    # Pass the data through the networks\n",
    "    output = self.forward(x)\n",
    "\n",
    "    # Choose the label with the highest score\n",
    "    return torch.argmax(output, 1)\n",
    "\n",
    "  # Train the neural network (will be implemented later)\n",
    "  def train(seld, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that your network works**\n",
    "\n",
    "Create an instance of your model and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "977a40fe-1f71-4d71-be4f-00edfcec232d"
   },
   "outputs": [],
   "source": [
    "# Create new NaiveNet and transfer it to the device\n",
    "model = NaiveNet().to(device)\n",
    "\n",
    "# Print the structure of the network\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Classify some samples\n",
    "\n",
    "Now let's pass some of the points of our dataset through the network and see if it works. You should not expect the network to actually classify the points correctly, because it has not been trained yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_samples = ...\n",
    "#print(\"Sample input:\", X_samples)\n",
    "\n",
    "# Do a forward pass of the network\n",
    "#output = ...\n",
    "#print(\"Network output:\", output)\n",
    "\n",
    "# Predict the label of each point\n",
    "# y_predicted = ...\n",
    "# print(\"Predicted labels:\", y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "text",
    "outputId": "757555dc-bf63-4b85-c5ff-be07e46fbcba"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D1_Basics/solutions/W1D1_Tutorial_Solution_f4cd20c3.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.3: Train Your Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "bf07e794-13a2-4c87-fd0a-9d6e782584a6"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Video 3.3: Train the Network\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"4MIqnE4XPaA\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train your network on your dataset. We will not go into details of the training process for now - this will be covered in the next days. The goal for now is to see your network in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Helper function to plot the decision boundary\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    # Transfer the data to the CPU\n",
    "    X = X.cpu().numpy()\n",
    "    y = y.cpu().numpy()\n",
    "\n",
    "    # Check if the frames folder exists and create it if needed\n",
    "    frames_path = Path(\"frames\")\n",
    "    if not frames_path.exists():\n",
    "      frames_path.mkdir()\n",
    "\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Predict the function value for the whole gid\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_points = torch.from_numpy(grid_points).type(torch.FloatTensor)\n",
    "    Z = model.predict(grid_points.to(device)).cpu().numpy()\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "outputId": "56788257-d389-405c-9656-f13a9eed35dd"
   },
   "outputs": [],
   "source": [
    "# Implement the train function\n",
    "def train(self, X, y):\n",
    "  # The Cross Entropy Loss is suitable for classification problems\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # Create an optimizer (Stochastic Gradient Descent) that will be used to train the network\n",
    "  learning_rate = 1e-2\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Number of epochs\n",
    "  epochs = 15000\n",
    "\n",
    "  # List of losses for visualization\n",
    "  losses = []\n",
    "\n",
    "  for i in range(epochs):\n",
    "    # Pass the data through the network and compute the loss\n",
    "    y_logits = model(X)\n",
    "    loss = loss_function(y_logits, y)\n",
    "\n",
    "    # Clear the previous gradients and compute the new ones\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Adapt the weights of the network\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store the loss\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Print the results at every 1000th epoch\n",
    "    if i % 1000 == 0:\n",
    "      print(f\"Epoch {i} loss is {loss.item()}\")\n",
    "\n",
    "      plot_decision_boundary(model, X, y)\n",
    "      plt.savefig('frames/{:05d}.png'.format(i))\n",
    "\n",
    "  return losses\n",
    "\n",
    "# Replace the train function in the NaiveNet class\n",
    "NaiveNet.train = train\n",
    "\n",
    "# Create a new network instance a train it\n",
    "model = NaiveNet().to(device)\n",
    "losses = model.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the loss during training**\n",
    "\n",
    "Plot the loss during the training to see how it reduces and converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "outputId": "e2dacd60-199e-4b18-cebe-c682271aa194"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, len(losses), len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Visualize the training process\n",
    "import imageio\n",
    "images = []\n",
    "\n",
    "for i in range(10):\n",
    "    filename = \"frames/0\"+str(i)+\"000.png\"\n",
    "    images.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave('frames/movie.gif', images)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython import display\n",
    "from pathlib import Path\n",
    "\n",
    "gifPath = Path(\"frames/movie.gif\")\n",
    "with open(gifPath,'rb') as f:\n",
    "    display.Image(data=f.read(), format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "9b964d12-def8-4979-fbd0-727bea3d872f"
   },
   "outputs": [],
   "source": [
    "#@title Video 3.4: Play with it\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"_GGkapdOdSY\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Tweak your Network\n",
    "\n",
    "You can now play around with the network a little bit to get a feeling of what different parameters are doing. Here are some ideas what you could try:\n",
    "- Increase or decrease the number of epochs for training\n",
    "- Increase or decrease the size of the hidden layer\n",
    "- Add one additional hidden layer\n",
    "\n",
    "Can you get the network to better fit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "cad8854b-691b-4282-a7bf-d6b5f9cc2364"
   },
   "outputs": [],
   "source": [
    "#@title Video 3.5: XOR Widget\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"cnu7pyRx_u0\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Solving XOR\n",
    "\n",
    "Here we use an open source and famous visualization widget developed by Tensorflow team available [here](https://github.com/tensorflow/playground).\n",
    "* Play with the widget and observe that you can not solve the continuous XOR dataset\n",
    "* Now add one hidden layer with three units, play with the widget, and set weights by hand to solve this dataset perfectly.\n",
    "\n",
    "For the second part, you should set the weights by clicking on the connections and either type the value or use the up and down keys to change it by one increment. You could also do the same for the biases by clicking on the tiny square to each neuron's bottom left.\n",
    "Even though there are infinitely many solutions, a neat solution when $f(x)$ is ReLU is: \n",
    "\n",
    "$$y = f(x_1)+f(x_2)-f((x_1+x_2))$$\n",
    "\n",
    "Try to set the weights and biases to implement this function after you played enough :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "outputId": "6b0b00fa-9a11-4f5f-a502-bf51081bb44b"
   },
   "outputs": [],
   "source": [
    "# @title Interactive Demo\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"1020\" height=\"660\" src=\"https://playground.arashash.com/#activation=relu&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.91390&showTestData=false&discretize=false&percTrainData=90&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8fb98548-b1f2-48e9-ef4d-09c6f34b13d1"
   },
   "outputs": [],
   "source": [
    "#@markdown Do you think we can solve the discrete XOR (only 4 possibilities) with only 2 hidden units?\n",
    "w1_min_xor = 'No' #@param ['Select', 'Yes', 'No']\n",
    "if w1_min_xor == 'No':\n",
    "  print(\"Correct!\")\n",
    "else:\n",
    "  print(\"How about giving it another try?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "08083233-c74d-41e2-a1e4-02fef0d57ee3"
   },
   "outputs": [],
   "source": [
    "#@title Video 4: Ethics\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"Kt6JLi3rUFU\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETHICS: Let us watch the coded bias movie together and discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "gjsDsf1Yc5aZ",
    "outputId": "264b122f-91ab-4098-fb7b-b1ce2450e462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video available at https://youtu.be/Sfp6--d_H1A\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhsaGRodHRwfIicmIiIiJC0nLicvLic3Mi4uMy03QFBCNThLPy0tRWFFS1NWXVxbNUFlbWRYbFVZW1cBERISGRYZLxsbLVc9Nj5dX1dXV1ddV1dXV11XW1dXY1dXV1dXXVdXY1dXV1dXV1daV1dXXFdXXVdXV1dXV1dXXf/AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAQQCAwUGB//EAEQQAAEDAgMEBwcBBwQABQUAAAEAAhEDEgQhMRMiQVEFFFNhcZLRFzKBkaGx0gYVFiNCUmLBcoKT8DRDc7KzByQz4fH/xAAYAQEBAQEBAAAAAAAAAAAAAAAAAQIDBP/EACARAQACAgICAwEAAAAAAAAAAAABEQIhEjEiQWGx8HH/2gAMAwEAAhEDEQA/APn6IiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP8AwT2cY3tcN5n/AIIPIIvX+zjG9rhvM/8ABPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP8AwT2cY3tcN5n/AIIPIIvX+zjG9rhvM/8ABPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP8AwT2cY3tcN5n/AIIPIIvX+zjG9rhvM/8ABPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP8AwT2cY3tcN5n/AIIPIIvX+zjG9rhvM/8ABPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL1/s4xva4bzP8AwT2cY3tcN5n/AIIPIIvX+zjG9rhvM/8ABPZxje1w3mf+CDyCL1/s4xva4bzP/BPZxje1w3mf+CDyCL17v/p1jACdrhsv7n/gq37jYrtKHmd+KDzKL037jYrtKHmd+KfuPiu0oeZ34otPMovS/uPiu0oeZ34p+5GK7Sh5nfihTzSL0n7k4rtKHmd+Kj9y8T/XR8zvxQp5xF6I/o3E/wBdHzO/FYn9H4n+uj83fihTz6LvH9JYj+ul83fisT+lq/8AXS+bvxQpw0XaP6Zrj+el83eixP6crD+an8z6IU46Lqn9P1v6qfzPosT0FV/qp/M+iFOYi6J6Fqj+ZnzPosD0VUH8zPmfRCn3FEREEUKvXx9Cm62pWpMdyc9rT8iUWItZRQCCJGYRESihEEooRBKLF7w0FziGtAkkmAPipBQSiKEEooRBKKFiajbg24XEEhs5kDUx8QgzRYVKjWiXODRlmTAzMBZoCIoQSihEEosXPaCASASYEnU8gpQSihEEooUoCIiAiIgIiICIiAiIgIiIMKvuO8D9lxg5dmr7rvA/ZccMUlrFFyguWwMSxFa7lErbYoLFFaSVg4reWrEsQV3Fa3FWCxa3NQVXLU6Vbc1aXNQVHLS5W3NWlzURVctLgrTmrS5qCu4KjinWuHIrouCo9I05pzyzQfW0RFphQ6bxbqGErVWe81ht7joD9VUbh8Jg6LdsA4v957mF7nuiSSYK6uKw7atN9N4lr2lp8CFy6HXqDRSFOliGtybUNQ0zHC4WnPwWZdMeqam4+jQwb34IBzWVALTdALnCQAdNdNFZxGNr0msa5tN1atUtptaTa0RJuJzMAHMASqzuh63VqwJYa1as2q4CQ1sObIBOZyar/SmDfU2dSkWirRfe27R0ggtJ4SDqm1njbSzF4ijWpU8Rsntqkta+mC2HRNpaSdYOcqz0dinVdtcANnWcwRyAGvfmqow9evWpPrMZSp0XF4aH3lzrSASYEASVjQo4qjUrtZTpvZUqmo15eRbcBILYziOBz7kSYif61t6YrHDYWo1jC+tUsIMgfzcc490c1uGMxFGtSZiNk9lYlrXUwW2ugkAgkyCAc1Qq4SrRw+ApG3atxA5lsw8q8cPiMRXourMZSp0XF4DX3lz7SBwEASVNtTGP23fqH/wGJ/8ASf8AZVa2LxVCkK720TRaGl9Node1uUm+YJGsQFf6Wwzq2FrUmRc9jmichJCoYvD4utS6s5lJrHANfVDyd3jDI1Inj81ZTGq239J459NzQ2thqLHCb6xkk8g2R3ZzxWg9NVG4WrUc1m0pVNm4gmzMjf52w4Fbn4SpTxTq1Om2q19NrILrXMtJ0kaGc/BYYLB16NOvayje+qXhlxttIEiYyOR4Js8aWMBXrGXPqYerStJvpSI7olwIic5VKn0liKtPb0zh2sMllJ83uHCXTDSeUGFnhOjXHE7U0aeHbs3Ne1jpNQuIzMADKD35rRQ6LqUWbIYTDVrcmVXENkcLxaTI7tU2vitVelnVBh24YNL67S8F8wxoAkkDUyQIWmntv2jRFawkUKsOZIB32fymY+ZVjF4Go19CtQbTvpNcw0/da5rokAxlBEhRRw+IfjGV6rGMa2k9lodcQS5pEmBy+HeiRVaP1N/4Q/8AqUf/AJWrLFY+o6u6hRdSYWNBe+pJALtGhoIkxnM8lt6Zwj69AsZF19M5mMm1A4/QKrjOjHDEurso0q4qNAeypAILcg5pIPDIjuSbMarf7puwfSD3isxwpmtRAO66GPBEtM52jIg6xCqUel6gqU5q4Wux7xTcKMzTLpjO4yMuQW6p0a+rha9PZUaD6ggBmYjgHEATx05rGvha1Y4YmhSp7Koxx35IAmQ2Bp/2E2eLbTxmIqYmtSYKQZSewFzpJILQSABxzOfDkVqo4zF1m1TS2DBTq1GAuDnXWOIGQIt01z8FcwWFcyviXui2o5hbB4BgBn4hR0ZhHUmVWuiXVqrxB4OeSPum0mYjr4VOv7VmAqGkyar/AOYSWHZuJLTzyWVLF4qtUxDKWxYKVSwOeHOndBiARz1n4LHD9GVW0sC02zQfL8+Fjhlz1Ct9G4R9KpiXOiKta9sHha0Z/JNrPH1+2pt6aecLSeKbTXq1DSayd24Egmdbd0lbHYrFUquHZV2LxVqFpcwObG450QSeWs/BV/2XUZhqQuYytSruqU7jukue6Gk94dCjFVa78TghVZTpnauIY15eSBSdLiYEDOPiptaxvXy76lEW3EREQEREBERAREQEREBERBjU90+BXNDF0n+6fAqiFJahiGqbVmijTXaoLVtUEINJasHNW8hYOCCu5q1uarDgqXSFfZsJ4nSEiLSZqLaMRiqbMnPAPLiq7cdScYDszzXEqdG4l81A0/EqlXo1ac3tI+q6Vh1bnyz7p6twWlzVx+g+kCXGmTLYJE8F06tU8FiYp0ibYvC0uCh7itRcVAcFpqMkEHiFuulYuCD6YiItMIRSiCEUoghFKINdSi15aXNBLTc2RodJHfmVsREEIpRBCKUQQilEEIpRBCKUQFClEEIpRBCKUQasRh2VWFlRjXtOrXCQtWF6OoUSXU6TGuIgkDOOU8laRFuehEREEREEIpRAREQEREBERAREQYv90+BVEK9U90+BXPBUlrFnKmVhKyUaERRKAVgVJKxKDBy5fSb2scx7zDRM/RdNxXO6RwzapDXjKDBzyn/oTlx2ceWmjEdN4djYl8HQ2OA+ZC4vS3SFI5BwJPxVjHYRrngOYQ7+ouFoy1OenwXC6ToUm4gin7kAbvMZLjEQ9GUzEMuiADiZB4Fd5y4nQ7GiuNSQ12fyXacuzzNTlqctrlqcoAUOUBqytVH0pERaYEREBERAREQEUKUBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERBhU90+BXMBXTq+67wP2XJBUlrFtBWUrXKmVGmcoSsJQlBJKwJQlYlBBK01julbSVpqnIqT01E1Ll16rpMMBB1JMLy2LNtbIRPfIXoMbi2Uw5rxM6Ly2NqNLpauWDrnOnV6FowH1TxNo+GqvOqLW17W02tZEADRaH1F1cJbjUWBKr3rJsoi01CVqD0vVH01ERaYEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERBhV913gfsuOCu04SCDxVfqNPkfmVJWJpzwVMrodSp8j8ynU6fI/MpTXJz5SV0Ops5H5lOpU+R+ZSjk5xKwc+BJMBdPqVPkfmVUx3QGHxAAqteQOAqOaPkDmlHJ57pD9SUKUhp2ruTdPifRcjCfqYuquFeGsd7saNPf6r1f7ldH9k/wD5X+qfuT0f2T/+R/qpONkZVNvMdKglkiHA6EZrgYrClgDjlcvpDP0dgWiGsqAd1WoP8pU/RuBf71Oo6OdWof8AKkYU1lnEvlNStvC0nLiMltp9I1BqbvFfTf3H6O7F3/I/1T9x+juxd/yP9VqnO3zyj0iHGHC0/RW717j9x+juxd/yP9Vub+kMEBGzf/yP9Uot4MVCtgevc/ulguzd/wAj/VSP0pguzd/yP9VKW3bWIcCSARI17lkuf0jSIcxzHWOqEU3Hm08f9Qzg95WmV5rgRIII7lkuOKxZIbUtcyoGNoiItuAAjXNu9Potrcb7rdoL9u5pGU2hzoEeEIOmoLgNTCo4+s9j2taY2oLG/wBr5yPyLj/tWhmKe+CTk2pTpkQPfDt/7gfBB1A8HQg+BUrldG++z/RV/wDmWdeo+a7hUcNnUYA0REFrCQcp/mKDpqFy34p1zjtYqCraKWWYujTXNu9K3dFCBVF5cRVfIJGW8eXPVBea4ESDI7lK4eGxLxRMk0w2k809N8iZM92WXx8N9atUp3RUc6aV28Abd4AuAA4Akx3IOqi5LsQ5pfZVNRjGteTumN7eEgcWgmPVKeMeXtaXQHnagxpSAOXzt8yDqhwMwRlr3KVTZc3DudmHua5/eCZIHwyHwVSvjyWk06gJGHc6RBh27B+pQdZLhMTmOC5eJrPpOqt2rotpEudEsDnua46RECc9FpfXLH1iypeP4IL5bugl05xHxPNB21C5YrVDa0VMnVQ24Oa5wFhJBMRwCkVnbYsNUm4ua2xzTG6ci2JBEa55/JB01K4VCuRQosbVIOyLib2t0jLNpkjl81tOIqPY9+0LbcPTqANAi4hxOo0yCDrucAJJgDiUXG6Qr3MxAfVsLQA1mQkFoM55mSSPgrnSgypEvLAKrZIIH3QXQ4HQyjXAiQQR3Lk0S5sODzBxDmluUQXnun6qcM59S1u0c0bNzt0NGd5HJB1kXFbjXOYHPrbM7Bj2gWi4lsk5jPOBA/yFsGKcHsLqkg7MWtc2QXAe80iTJMyDp4IOqSAJOQCguAiSM9FWx1RrsNWLSCNnUzBnQEFU67attC99Mt2lLIMIOuWZcfsg6yNcCJBkHiFysLiajntl4BL3BzC5uQE5BsTIgFasLWhlNrq5pNFBrhm0ZyZOY7gg7ahUX4h/VG1DuuLWXGPdBIudHcCT8FXqYhwLm06xc26iL90kF9SHNmIOUH4+CDrouTWxFRl7LyQKrWlxIBaCydYgZwM+auYB7i11zg4B0NIcHGI0JGUzKC0oXFGNfBcKnvUajwC5pIgCMgBac9M1urVqlO6KjnTSDt4A270FwAHAGY7kHUQEZ56arjYqpLKrW1i9gaxxdLTabtJAiCM/gs6hc3b1GVHbrqekQ7cZrlnIQddFyes1DVdvhpFS0MLmgWz/AExJJGY+Cs4CqTJfUkufUDWmBk15GQ1OUILdwmJEjOFIcDoQeC5dak44uq+n/wDkZTpQP6gS+WnxjXmAtOExNzW/xDTpvqVzdkDIqZNz0yLj/tQdpJExOfJcnDVC+rQe6ofdqhpyAeA8Bp04iDlyyWWOrOZXdbkNmy9+Rsbe6XRx/wAa8IQdRFy6tV/8ZwquinUYGjKCC1hM5ZzcUfinBzjtYqCraKWWYugZa5jelB1EkTE58lyTjnsJLju0CRVy9647n0tPxQ1aokF8P/8AtwSAJlzyHcPgg6ylcp9ZzS5jqpDBWDS8xLQaYdExGbsp71Y6Pqlwq7+0DahDXZaWtPDLUlBdUKrh21Lt41I/uLI+glVMdii04iaxpuY3+G3d3tyZgjPOR8EHWRcnE4pwNY7W17CBTp5b+6CMjmbiSMv8KauJcC87WKjaga2llmJEZamRnPoUHULgNTClcavWu96rvDENbs8sgKojLXSDPeuygIiIChSqGOa7aUratRofUtIERFjjllzaEF6BMxnzS0TMCVzn4qpTdWyvZTskl0GLc4yzPHgsqmOLC/KYqFsvMNbuA6gZa8fmgvpC01cRbTFQiRuzBmASATPGJWlvSALi0NM7SwZ6jOXeG6/5ILkJC5Bxj7QQ45soHOJ3qsHhxCu4uq9r6QYAbi4EEwDuk5mCgtQJmM+aQqDuk4hpa1tQlwIc6Gi2J3oz95sZcVsdirsM+o3dIa/vgtnTnmEFuBySFSbjXNkVGtbFO8G/UaZ5ZH5rFvSRg7gLg9rYDst7QyQCPkgvhoGQACEDkubjMbU2dUsaBsxBddmHQCYEZgTxhdNAWIaOQXHwuIqHYOL6svcA68Cwgg6GPkrdDpMPc0Q215IbDpdxglsZAxz4hBehA0DIAKli8RUbULWxbsnumc5HGIWA6QLGzVZH8O8EOkmIBByEGSEHQDQMgBklomYE81z/ANpwHS1pcLSAx9wMuDYmBBzU1ukrCWlrJYAXi+Nc4blmY8NUF6wchrOimAqfSFV+yaaWrnMEk25OcByPNR11wzsmm11hddvTNpMRpPf8EFwtHIKSJ1zWjC4g1Ljba0Oc0GZJtcWnLgMlqbjiYdZ/Cc+wOuzmbQbY0J7+KC5CQqVPHk2FzA1j7oN0kWgnMRpAPFML0iKjmiGgPEth1xGUw4cDHig3V8KH6ueBEENIAI+WXwhbgwCIAyEDuVPG4/ZE5NIaJdvQY7hH3IlKmOcHO/hixtRrCbs962CBH9w4oLsJCp9ePvWfwr7Lrs5usm2NLstVop4usdnIbcatRsB2RDbokxwhB07RMwJ5rXsG3l8ZwB3ZEkfdU/2nk0WtDzfIc+Gix1p3ozz0yWyjjjUcwNZ7zS4knSHWnxQXViGgZACFkiCIQCMgpRBjaOQzUqUQYhoAiBHJTA5KUQRaJmBPNIUoghQWgiCBCyRBBA+SQpRBEDkkCZjPmpRBEJClQgwq0rhElveI/wA6qKFAUwQCTJkk6k/9hbUQFXr4QVCbnPtIgtBEEfKRPcVYRBFomYEjRLRMxnzUogi0TMCVKIgIiIC11KIcWE6sdcPGCPsStip4rFVGPY0U2uD3WtJfGdpdmLT/AElBtfhWOFQGf4gAdnyEKHYUS4tc9hc64lp4wBocuAU08Ww5FzbgQHAGYcTET4qX4ljZlwyNvfMTEc4MoDcMwUtkBuW2x3RCwp4Km1zHAGWNsbnw7+Z7+8qWY2m6oKYMktuBGhCyq4qmwgPe1p7z9TyQax0fTgCDADBrwY65v1Wyvhw+0kuBaSWlpiJEfFQ/GUmutc9odIBE6E6TymQpOJph9heLpiO86Dx7kGsYBgAguDgSbwd6Xe9M5GcvkOS2miDTLCSQQQSTmZ1zU1q7WAFxAnTv+C1vx1IAE1GwRcM5kcx3IFXBsfrPu268iCPjICgYJsyS5xlriSeLdNMllUxlJkXPaJEjPhz8O9aq3SLGmoNTTDSeAgmNe5BNbAMeXSXgP95oMAmIn6BWWMicyZM5nTuHctTcXTIc4PbDfeM6ckOMpBtxe0CbZJjOJjxQaqfRzG2i55awgtaXZAjTLjC2UsKGHdc+3Mhk7onXv+GizxFayk+pE2tLo0mBK0sx4cym4NO+8MIORac5B8IQbK2Fa9wcSQbXNMHUO1BUPwbHRcJhhZrwMegUjGUy4tD2yJynlr4wsaOMbUo7VuYgmPAaIJ6oC0tc97wSPeOlpkaJUwoc4uDntJADrTFwGk+ozU9bYGgucG7ocQToDpKDGUi1zr2w3JxnTkgzq0g8AHgWu+LSCPqFpOBYXTLoLriyd0u1mPHONFsp4ljotcDJIHiBJHjCxqYtgZeHNIh0ZwDbM5/AoNlGkGAhuhc53xc4k/UrS3AsDgZdAdcGTuhxzmPEzGizdjKYdaXtDpAidCdPnIR2MpB1pe0OkCJ4nQeOYyQG4VgDBGTCSPiCDPzKUMMKejnloENaTIA/z8ZWVauxkXOAnRY1MZSbFz2iRIz4c/DvQY18E15cSXAPEPAOTo0/6Fk7CsIcDO88POfERH/tCVMZSY611RoOUgnSdJ5IMXTLS68WgwT38vFBh1Fl0y626+yd26ZmPHPlOayp4NrSCC7JznAE5AumfuVDsdTBpi6doSARzGs/KFGGx7KkCQHGd2eRzQScE3ItLmuBcQ4HPeMuGeUStjKADg7MkNtkmcplah0hSDWl72tJaHRMwDxnl3rOrjKTDDntBAkydB38kG9FrqVLbdN50ZmOB+eiiliWPMNcD4ffvCDaipVOkmAvH9D2tdOQFxAme6fotwxdMtLrxAMHuPLxzCDeiwpVWvEtII7lrZi6bnFrXtJE5Ty18YQb0VR/SNOx7mOa8tYXwDqAOBW4YhlpdcIBg9x5fUINqLXUrsYQHOALtAePh81i3E0y6wPBdnl4a/JBuRV242kZio3dEnPhz8O9T1unaXXgAGDOWZ0EIN6LR1ylaHXtgmAZ4jh45HJZNxDCw1A4WAEl3ARr8oKDai1OxDBdLmi1tzs9G55nuyPyWqnj6ZcWkhrg8tAnWPXkgtItYrsIYQ4Q/wB3vynL4Aoa7AHkuEM97+3Kc/gUGxFo63TvsvbdMRPGJjx7lmK7Mt4ZuLR3kTI+h+SDYi01sSynF7g2efdqfDvU9Zp3W3tuiYnhz8MkG1Fqo4llSbHB0Z5cjofDvWoY+mHvY4hpa4NzOsgEeGsILSLScTTD7LxdMR38vHuUdcpQ43t3TDs9DMR4zwQb0WFKq14lpBCzQFXxNEvdSIjcfcZ5WObl5grC1is28suF4ElvGDxQVH4R4pkNtLtttACSARfdExlksThKhvcWtLnVLxbUc0t/htbk4DXI/NXqdQOBLTMEj4gwQsrhMSJ5IKdChVa9jnFrv4drzOczI4Z/RY4jD1LqtgYRVABLiRbuxpG8O7JX0Qc84F1lZoIN5ZaT/a1oz8pUdSde4EXMc++do5sZz7oGcHvV9zw2JMSYHipQVsXSe5zC3Nom5txZPIyOWeXf3LVhME5kSRlTLciTmXTyV5YtqtJgETJHxGoQc+lg6tNoDRTddSYx1xIgtbE6ZjPTL6qTgXi5gtLSym24kzLDyjiF0Kbw4S0yDxWSChi8E573OBH/AJZaJIksLiQSNNdVDcG4ljiACKgc6Xl8gMIGZGua6CIK2IpvqUKjCGhzmubrIzBAzhaa2AJq03sIEOaagP8ANaIBHfw8PBX0Qc6jhKg2TDZZSdIcCZdAIGUZa55/dbcNh3tw+ydbIaWggyDlkdMvBXFg+q1oJcQIEnuHNBz2dHPbTcwODg6xxLjnc0ieGYgZctNNNuIwjnPc9tszTc0HQ2zIPLXVXVKDm1MHVcHvljKpc1zcyQ20RmYzJBPDksX9FmKjWlthpubTHIuADp8o+ZXTJWkYunstre3ZxN3CEGipg3FtYSN9zSPgGjPylVK1wJottdNdr9TdnVDzuxEDPOdAuw0yARoVKCrjaLn2lrQSJzvLCJ5EAz4LQcNWF0bN5qMa1znEiCBBMQZGcxl9cugpQc/qDgx7QQZNKCeTLZnv3Sor4F5e57SJ2oeBcWyNlYRI0OpV3atvsneiY7lsQUG4V4NNwaLhULngvJ1ZbMkaxGSyp4NwbREjcc4n4hwy8wV1EHOo4B7abmEtk0GU+OrQ4H4bwVfGBzBWpttcaoGWd02BsARvDLWRC7KwfVa33iBkT8tUGvEUS404jdeHGfAj/K04LD1GOMw2nEBgeXiZ1EgWiOHorTKrXSGkGIn4iQpY8OEtMiSPkYP2QU6mFeXv921z6bwZM7tsiI/tWOIwL3Oc9pE7QPaJLZinYQSNNSugiCvhaFrXSIc4yd4u4AanuAValhKkUmOsDaWjgTLt0tGUZa55ldFEHNq4B5psaC2W0H0z4uDQPhulRsbsTAO4A19Qf3tENHxBB/2DmumiDQ+iTWY/KGteDzzLfQqphsC9pa05tYSWuvd3wbIic+a6SIOWzAVMi8NdFJ7HXVHOvLi3PTdG6dFk3CVoa4kEsfcxjnl38paQXxP806HRdJYlwBgkTBPwGv3CClTwb721HWg7Uvc0EkAbIsABjM6Fb6FC1r2ughznn4OcT/lbmPDmhzTIIBB5grJByW9GPtbc5pN0POebBEDx3B83Kz1R1pEjOsKnwDgfnkrb3hoLnEAASSeARjw4AjQ/BBz8DSmq9wM02Fwp+LjL/kch8UxNK/ENa05EA1R3MMs+ZMeC6S1iuwm24TJEd4EkfJBTOEqZ09yw1L75N3v3xbGs5TKhmEqhzAQyxlZ1S64yQbsojL3ufBdBSgp4uhUc8FpltpEXlkHnlqtVPo92zewuAuospyOBDSCfDNdFEFPC4dwdc8QQ2Ado5+pzyIEaBY1cG5za4BH8RzSPgGjPylXkQc4YFwe4EXMdUvnaOEb13uxnB71L8C7ZgAi5tV9QCSAbnOykaZO+YXQRBXwdEsDiRDnGTvF/AAZkDgArCIgLmV8O52IqPZk9jKZYToc3y09x4/Arpog4VN7yxpLXMY6pWLgS5sEv3QS3ONe76LaKJc+le98up1WhwLxEkW/GJzOsTwXYRBxdrXeA43t2sUoE7hES/u/8zPuas3udc7Opt9rDRLrbLssvdi3U8+9ddEHJcypZc251Q13QHl0ACo4Ny4CFawrS+iWuLw8yHkmCHcY5DlHcriIOLta7m3b4NT+DAndcNX92d+fc1bHN/i03PL4bXeBm6ALMvhP/AHNdZEHKwtIt6u4Xy5zw8EuiLXEbugzAWzGkbU7U1BTsFlhcN6Td7upi2AuiiDjOZVcyoahqB7cOwi1zm7+/OQyJyCnEOqGo6XFrt3ZmX8hmGtEOzmQfsuwiCn0i4hrBmA5wDnS4BogmTbnEgDXiquGY5+za41LZrD3niQHi2TrppK6yIONTcYZt3VQywwQXglwcRmW5zEROua11GOtcal+0dhiMycyJ1AymIy5ruog5WIZUp3ikXmabSZc52d28RMwYnTuWveLHWPdaX0RuueSJqC7ednpqF2UQaWkGmQ2SGy3OZyy1OZ8VxKWHfsW0rTszSFU5cQzNkf6od816FEHExD3xlc1zG07RL97SSAMu4yD8FYex2b5qXCu0DedFpe0EW6RBK6aIOdhnPNXZEuiiSSZO8He4J45Ez3tCxxh/iP2hqgWDZ2Xa5z7urtMj6q/SoNZdaDvGSSSST4lbEHOwNJwrPc+bzTpXZmJ3roGnD/sqJfttjLou2t0n3NbZ/wBeUcl0lrZRa1znAbztSSTpoM9B3IOZhnOJpwahqmdsHF0DdM5HIb0RH2WeCxBc7DiXmKTtpId727rPHVdREHMxYq7V1NhcLgKgOcC0QWzwk2ZcZctZfUey/fAqCqbTOQthojhpMcyuuiCj0c0hz5BGVP8A9irYU1A6HhzWTV2ds5uvd73w04fGF10QccMqtawsNQvdh3k3Eu3wGW5HIHNymCbhQdVIFMuNxf74cC0b2cmHAj5rrog5NKpVe9nvhtZweNRY1pmO6QGZd7lYxxG0ZtC8UrXe6XDekRJbnpMf/wAV5EHLoU31LRUNSNm7+ZzSd/dJiN6IVe+oQw1C4TRplpl7d6N7JozdMZH1XcRBTxjnCgJzJtDiLhGYk5ZwqdAOcWsLn2bZwkF4luxnU5xPeuwiDkCRY2oagpB1UTLpkO3AXDOIu+ncsaTTtKL37T3KzWkl2YubZcOZbOusZ6Lsog4tKnUp06eyvvOGdkSSLgG25HIHMoC/Z1Cx7vc0BqE3TkZcMjrku0iCj0lQHVajBcd0xvOJPx1KrYqWmqJq7QRsAC4g7ojucbpmfiuuiCnhGHaVXOLpD4AJMAWtOQ01nNVrHGo5oL2h1Z4JbIy2ORnx+q6qIOO6rWfTe+HAsDWECRJuG0cI1y0Iz1hWujpl+9LMoEudBzned8Mu5XkQEREBERAREQEREBUDWeMTUDWOeLKeQcBGbuZ/7CvrAUwHF0bxABPcJj7lBzsJiahhggPc+sZfvWhr4jI56jisX49wIeR7tOtLQci5r2j/ALylXnYOmRFsbxcCCQQTqQRmJlSMJTgCwQGlscIdqPjCDTSNTbgVC0/wyd2QPeHA/dY1sY8bV7Q2ykYcDMugAmDw1757lYo4RjDLQZiJJJMcs0qYOm51xbJynMwY0kaGO9BXdi6gLjDLG1W04zk3FomeEXLGlj3ucCGksLy2Ax0gB1t12nDT6q4aDCCLdXBx8QQQfoFDcKwPuAIMzqYnnbpKDVi8Q5pa1kXEE5tc7IRwGmv/AOiq/wC0KjmF7AwAUWVYdJ94ONuXhr9Feq4dryCQZEgEEjI6jLhloobhaYBaGgAsDI/tEwPqUFWpjXxVe0NspAFwMy7cDjB4ZHvWipWqzV3hAr0Q0ZiAbDBPLP7q/UwVNxkt5A5mDGkjQ/FZOwrC4uLcyWk5nVsQY0nIfJBUfjntljg0v2gYC1riM2XTaJPPKVIxlU2NDQHOeWy5rmggMuuAOfdH1Vp+GY66W+8QTqDIEAg8DkjMOwWwPdJIJJJkiCZOqDDF1y20NIucTq0uyGuQ+HFaKOMqVbQwMa6y5xdJHvFsAZHgfBW6tBr4LgZboQSCPiFrOBpENFsBsgQSCAdRIMwgxZWqPe4NsDWODXTJJNocYPDJ3Ja2Yx5seQ3ZvfaBncJMAzofCMlYdhKZcHW5iNCQDGkgZGO9G4OmH3huckjMwCdSBoDrmg0Nxri2iYH8S6e6GuOXyVepjK2yncBfQdUbAO6QB35+93fFXWYGk0yG5gkjM5TrAnLUrPqzIAtEBpYP9JiR9AgpYnHVKbJ3XFlO94DXZ68Z3dO9H4iow4h4tLKbpIMyQKbSQDoPqrLuj6REFpIttO87MZ5HPPU6rJ+CpucXFuZIJzMGNJGh0GqCocW5rnNGZdVcASHOtAYD7ozPhlqrmFqueyXNLTJGhEwdQDnmpfhWOmW6uukEgzESCMwYUsoNbbAO6CBmTqZPigoV2l2IqCyo8BrItqWATdwkLOri6jS60MtY9jIMybg3jwi7vlWauCpvcXOBuIAJDnN000Pes+rsz3dS0nXMtiD9AgqHGPAc023ipYCGuIO6HTbM8ear18Y51Mn3XbKvmCRmxwbMfXPMLovwrHSSMy66QSDMRMjuyUdTpxFgiHDjo8y75lAxNYtDA0Aue4NE6DIkk/AFVzjKgcKcMv2lhOcQWFwMc8tJVyrRa9trhIy+mhB4FYMwrGxDdHXTJJmIkniY5oKn7QfusgXl1QEhrnCGECbRnnI4qzSxBNIveLLbpkEDKc884MSsn4SmRFv8xdIJBBOpBGYWYotssiWxBBzmdZnVBQ/aFQB4LWkhrHCWuZ7zrYIP3+izfjKjXOYQwvuYGkSBvzqO6D45aKwMFTE7pMgDMk5AyBmeayqYZjrrmg3RPwzHhCCjXxNa4MBYHNqMBIBhwdMZTlocpU0K9RuZLSw13szm7N5Az7uSt9Sp2ltpgm4mTMjjdMysxh2RFuV13+6Zn5oKmHxz3lpt3HEiAx0tGcEu0On14rfgqz6lJr32i4AgNnIQsmYVjXXAQZJiTEnU26TmVsp0w1oa0Q0CAO5BzcA59SpTcTuigxwbLtXTOc56cVYdinita4BrZAbLXb2XB+gM5QeSsUqDGRa2IaGjwGg+qg4VhffBmZ1MTzjSUFWljXkUnkNsqmGgTLZaSJPHTPSFhSxlZwZlSF9LaDJ2URlrnM90d6tswdNrrg3POMzAnWBoJ7lm3DsFsN91to7hll9AgonpF7vcboxriLXOkuE2y3TxM+CzqY2pFR7WtDaQBcHTcd0OI/tyPerDsFTMbsQ0NyJGQ0Bg5jxU1cHTe65zZOU5kAxpI0PxQVamNqAvcAyxlRjIMyQ63OeEXIzHvc7JpLdoWQGOnJ1pddprJjlxVw4dhulvvODj3kRB+g+Sx6qy++DMzqYnnGkoNeLqua9trbnbOoQJIki2By4rLBVy8ODiC4RItcwiebXZrbUotd7wnIj4HX7BRRoNZNoMnUklxPLMoKTMXWcWQKYD31GjI5Wk5nPP3dMvFQzGPcA4Ml+zJgExIfBy48+fBXm4dgthvukkdxdM/crHqlOIt4Rqec/fNBVONfYC2DDiHEU37uUiac3TmsXY03OLbXSyhBk2m97grXUqcRDtZm50zEe9M6AfJZDCUxowDJo+DDLfkSUFY4yoDsyGF5qBgdBDc2F8kTOgPFb8JWc41Gvtljw2WznuNdOf+pMThQ8OgNlxBMzw00IIPeFjhMCKYJObi+/KQAbbeeeXPjmgtoiICIiAiIgIiICIiAiIgIiIIUoiAiIgIiIChSiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiCEUqEEqEUoCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIg1dYZzTrDOaornHpemK1SiQQaWbydA20Ou+bgIQd/rDOadYZzXC/a9CWi5wLiBBpvEEuDRdlu5kaxqEHTGHNpvIDwS0uY9oIAJmSP7Sg7vWGc06wzmuAemKYpVasODKb2tNwLTvW5wQCALvosqfS1Iht0sLwHAQTDTNpcQIbIGQJQd3rDOadYZzXna3TtFoBbc6QTmx7QAKbn5kjKQ3TWCDC3HpegJFzpBiBTeZN1sNy3jJjKUHc6wzmnWGc1xv2hTiiWh7hWMNIYcu90+6PFVcT07TpPcxzHXNvECMy1oc0f7gcvAoPR9YZzTrDOa4B6bwwBmpBaYItcTOegjMbrsxyW7DdIU6rntaZLdYzy4HLnwGpQdnrDOadYZzXFo9IB2HfXsc0NvlpidwkH7LT+2GNDts11ItDXRF+TgSDLZ/pdryQeg6wzmnWGc1yKeNpvJDSXEBxIDTO6608OenPgpwOKFak2oGlt07p1EEjOPBB1usM5p1hnNUFKC91hnNOsM5qiiC91hnNOsM5qiiC91hnNOsM5qiiC91hnNOsM5qiiC91hnNOsM5qiiC91hnNcvGfqbDUaj6bhVJZFxbTc4CRIzC3LxPSnSFRnSdbDB0UsRs2PGWRLAGuk8jHiixXt6k/rHCAAlteDodk6DGuau9H9O0MQ5zWbRrmgEh7C3I6HPwXhKVLE1KzsFUqMDMKC94BEAZXWnic+OkrofpHpSri8TiatUybGBo/pbc6G98TqlTCzx9Pc9YZz+6dYZz+6oojK91hnP7p1hnP7qiiC91hnP7p1hnP7qiiC91hnP7p1hnP7qiiC91hnP7p1hnP7qiiC91hnP7p1hnP7qgiC/wBYZz+6dYZz+6oogvdYZz+6dYZz+6oogvdYZz+6dYZz+6oogvdYZz+6dYZz+6oogvdYZz+6dYZz+6oogvdYZz+6dYZz+6oogvdYZz+6dYZz+6oqhUxjw54hm5JjM3AWwB3732Qd3rDOf3TrDOf3XGweKdUc4ECAJEf6iOeYy7vBW0GWzPJVavRVJ7nOdTkuJJMnOWWHjpAAjTIcV00QctvRFICNmTpmXOJMPDgSSZOYGvJYnoajLSaXutDRmYgAgAic/edrzXWRBzKfRdNrCwMNpcHG5znElsQZJn+UfJYfsajIOzOU5XOjMk6TBi4xynKF1VKDk1OhqLjLqZO7bFzoiws0mJtJE6wlfohj2wGlpmQRMglwcSM+YC6yhBRwmD2NJlNtxDREnU95Wur0VSe8vdSBc4sJOeZYZb8l0kQcp3Q1EgjZmC67JzhBzzbnu6nSNVupdHsY8vYy1ztSCc/Hmr6IOc3o1gvAa614Ic2TGZcSY4Elx+i0/sOhbaaZI5l7yTulvvEzEEiJ4rsKEHOwvRwpPqvAJdUcCdMg1sNA+S20cKKbQ1jYaJgeJk/UlXEQV9meSbM8lYRBX2Z5JszyVhEFfZnkmzPJWEQV9meSbM8lYRBX2Z5JszyVhEFfZnkmzPJWEQV9meS8P+pf0zjMRjKlWlSDmODYJc0aNAORK+gIg8Biv07i34KnTFB3WCQKzr2Q5jJ2YmeAI+Q5BXv0d0HicK+sa9O0PDQ2HA6Ezoe9exRBX2Z5JszyVhEFfZnkmzPJWEQV9meSbM8lZRBW2Z5JszyVlEFbZnkmzPJWUQVtmeSbM8lZRBW2Z5JszyVlEFbZnkmzPJWUQVtmeSbM8lZRBW2Z5JszyVlEFbZnkmzPJWUQVtmeSbM8lZRBW2Z5LE0JgloMGRlx5q2iCo2hEkNAnWBqstmeSsogIiICIiCFKhSgIiICIiCFKhSghEUoIRSiCEUoghFKICIiAiIgIiICIiAoUogKFKhBKIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIg09apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIg+49apdrT849U61S7Wn5x6r4ciD7j1ql2tPzj1TrVLtafnHqvhyIPuPWqXa0/OPVOtUu1p+ceq+HIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIg/9k=\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"854\"\n",
       "            height=\"480\"\n",
       "            src=\"https://www.youtube.com/embed/Sfp6--d_H1A?fs=1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fe31603f790>"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Video 5: Be a group\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"Sfp6--d_H1A\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "outputId": "5b92471b-3496-4ebf-89c4-309f74bc733d"
   },
   "outputs": [],
   "source": [
    "#@title Video 6: It's a wrap!\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"JwTn7ej2dq8\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtu.be/\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Appendix\n",
    "\n",
    "## Official PyTorch resources:\n",
    "###Tutorials\n",
    "https://pytorch.org/tutorials/\n",
    "\n",
    "### Documentation\n",
    "\n",
    " https://pytorch.org/docs/stable/tensors.html (tensor methods)\n",
    "\n",
    " https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view  (The view method in particular)\n",
    "\n",
    " https://pytorch.org/vision/stable/datasets.html (pre-loaded image datasets)\n",
    "\n",
    " ## Google Colab Resources:\n",
    " https://research.google.com/colaboratory/faq.html (FAQ including guidance on GPU usage)\n",
    "\n",
    " ## Books for reference \n",
    "\n",
    " https://www.deeplearningbook.org/ (Deep Learning by Ian Goodfellow, Yoshua Bengio and Aaron Courville)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D1_Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
