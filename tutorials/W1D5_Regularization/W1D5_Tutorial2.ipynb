{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/w1d5_fixes/tutorials/W1D5_Regularization/W1D5_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gDtezgUydhdD"
      },
      "source": [
        "# Tutorial 2: Regularization techniques part 2\n",
        "**Week 1, Day 5: Regularization**\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "\n",
        "__Content creators:__ Ravi Teja Konkimalla, Mohitrajhu Lingan Kumaraian, Kevin Machado Gamboa, Kelson Shilling-Scrivo, Lyle Ungar\n",
        "\n",
        "__Content reviewers:__ Piyush Chauhan, Siwei Bai, Kelson Shilling-Scrivo\n",
        "\n",
        "__Content editors:__ Roberto Guidotti, Spiros Chavlis\n",
        "\n",
        "__Production editors:__ Saeed Salehi, Spiros Chavlis\n",
        "\n",
        "__Post-Production team:__ Gagana B, Spiros Chavlis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "niW9coOidhdK"
      },
      "source": [
        "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
        "\n",
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "q6OEjFzxdhdL"
      },
      "source": [
        "---\n",
        "# Tutorial Objectives\n",
        "\n",
        "1. Regularization as shrinkage of overparameterized models: L1 and L2\n",
        "2. Regularization by Dropout\n",
        "3. Regularization by Data Augmentation\n",
        "4. Perils of Hyper-Parameter Tuning\n",
        "5. Rethinking generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "TK4fgSbwdhdM",
        "outputId": "52769d04-080c-4977-e4a3-e35f261c9def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/7um6p/?direct%26mode=render%26action=download%26mode=render\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f4028652a10>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# @title Tutorial slides\n",
        "\n",
        "from IPython.display import IFrame\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/7um6p/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "lFuJjUVQdhdP"
      },
      "source": [
        "These are the slides for all videos in this tutorial. If you want to locally download the slides, click [here](https://osf.io/7um6p/download)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ScsvdnZSdhdP"
      },
      "source": [
        "---\n",
        "# Setup\n",
        "Note that some of the code for today can take up to an hour to run. We have therefore \"hidden\" that code and shown the resulting outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "4HI4Qye5dhdR"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "\n",
        "# @markdown **WARNING**: There may be *errors* and *warnings* reported during the installation. However, they should be ignored.\n",
        "\n",
        "!pip install imageio --quiet\n",
        "!pip install imageio-ffmpeg --quiet\n",
        "\n",
        "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
        "from evaltools.airtable import AirtableForm\n",
        "\n",
        "atform = AirtableForm('appn7VdPRseSoMXEG','W1D5_T2', 'https://portal.neuromatchacademy.org/api/redirect/to/a76f99c1-9005-4566-8bcd-bed4e53d21f1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "execution": {},
        "id": "TNq5X61EdhdS"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import copy\n",
        "import torch\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "cyEzhpkydhdU"
      },
      "outputs": [],
      "source": [
        "# @title Figure Settings\n",
        "import ipywidgets as widgets\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "E8w_BBLadhdW",
        "outputId": "704fbac7-cbea-4dbb-9e24-97c03d1f4428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping `AnimalFaces` dataset...\n",
            "Download completed.\n"
          ]
        }
      ],
      "source": [
        "# @title Loading Animal Faces data\n",
        "import requests, os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Start downloading and unzipping `AnimalFaces` dataset...\")\n",
        "name = 'afhq'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/kgfvj/download\"\n",
        "\n",
        "if not os.path.exists(fname):\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(fname, 'wb') as fh:\n",
        "    fh.write(r.content)\n",
        "\n",
        "  if os.path.exists(fname):\n",
        "    with ZipFile(fname, 'r') as zfile:\n",
        "      zfile.extractall(f\".\")\n",
        "      os.remove(fname)\n",
        "\n",
        "print(\"Download completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "BL9z1abydhdX",
        "outputId": "048ab736-791b-4de0-a04e-a337586dccf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping `Randomized AnimalFaces` dataset...\n",
            "Download completed.\n"
          ]
        }
      ],
      "source": [
        "# @title Loading Animal Faces Randomized data\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"Start downloading and unzipping `Randomized AnimalFaces` dataset...\")\n",
        "\n",
        "names = ['afhq_random_32x32', 'afhq_10_32x32']\n",
        "urls = [\"https://osf.io/9sj7p/download\",\n",
        "        \"https://osf.io/wvgkq/download\"]\n",
        "\n",
        "\n",
        "for i, name in enumerate(names):\n",
        "  url = urls[i]\n",
        "  fname = f\"{name}.zip\"\n",
        "\n",
        "  if not os.path.exists(fname):\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    with open(fname, 'wb') as fh:\n",
        "      fh.write(r.content)\n",
        "\n",
        "    if os.path.exists(fname):\n",
        "      with ZipFile(fname, 'r') as zfile:\n",
        "        zfile.extractall(f\".\")\n",
        "        os.remove(fname)\n",
        "\n",
        "print(\"Download completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "execution": {},
        "id": "1u6vN6QadhdY"
      },
      "outputs": [],
      "source": [
        "# @title Plotting functions\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "  \"\"\"\n",
        "  Display unnormalized image\n",
        "\n",
        "  Args: \n",
        "    img: np.ndarray\n",
        "      Datapoint to visualize\n",
        "\n",
        "  Returns: \n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  img = img / 2 + 0.5  # Unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.axis(False)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_weights(norm, labels, ws, title='Weight Size Measurement'):\n",
        "  \"\"\"\n",
        "  Plot of weight size measurement [norm value vs layer]\n",
        "\n",
        "  Args: \n",
        "    norm: float\n",
        "      Norm values\n",
        "    labels: list\n",
        "      Targets\n",
        "    ws: list\n",
        "      Weights\n",
        "    title: string\n",
        "      Title of plot\n",
        "\n",
        "  Returns: \n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=[8, 6])\n",
        "  plt.title(title)\n",
        "  plt.ylabel('Frobenius Norm Value')\n",
        "  plt.xlabel('Model Layers')\n",
        "  plt.bar(labels, ws)\n",
        "  plt.axhline(y=norm,\n",
        "              linewidth=1,\n",
        "              color='r',\n",
        "              ls='--',\n",
        "              label='Total Model F-Norm')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def visualize_data(dataloader):\n",
        "  \"\"\"\n",
        "  Helper function to visualize data\n",
        "\n",
        "  Args:\n",
        "    dataloader: torch.tensor\n",
        "      Dataloader to visualize\n",
        "\n",
        "  Returns: \n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  for idx, (data,label) in enumerate(dataloader):\n",
        "    plt.figure(idx)\n",
        "    # Choose the datapoint you would like to visualize\n",
        "    index = 22\n",
        "\n",
        "    # Choose that datapoint using index and permute the dimensions\n",
        "    # and bring the pixel values between [0,1]\n",
        "    data = data[index].permute(1, 2, 0) * \\\n",
        "           torch.tensor([0.5, 0.5, 0.5]) + \\\n",
        "           torch.tensor([0.5, 0.5, 0.5])\n",
        "\n",
        "    # Convert the torch tensor into numpy\n",
        "    data = data.numpy()\n",
        "\n",
        "    plt.imshow(data)\n",
        "    plt.axis(False)\n",
        "    image_class = classes[label[index].item()]\n",
        "    print(f'The image belongs to : {image_class}')\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "execution": {},
        "id": "PXUGI_badhda"
      },
      "outputs": [],
      "source": [
        "# @title Helper functions\n",
        "\n",
        "class AnimalNet(nn.Module):\n",
        "  \"\"\"\n",
        "  Network Class - Animal Faces with following structure:\n",
        "  nn.Linear(3 * 32 * 32, 128) # Fully connected layer 1\n",
        "  nn.Linear(128, 32) # Fully connected layer 2\n",
        "  nn.Linear(32, 3) # Fully connected layer 3\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialize parameters of AnimalNet\n",
        "\n",
        "    Args:\n",
        "      None\n",
        "\n",
        "    Returns: \n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(AnimalNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(3 * 32 * 32, 128)\n",
        "    self.fc2 = nn.Linear(128, 32)\n",
        "    self.fc3 = nn.Linear(32, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward Pass of AnimalNet\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns: \n",
        "      output: torch.tensor\n",
        "        Outputs/Predictions\n",
        "    \"\"\"\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  \"\"\"\n",
        "  Network Class - 2D with following structure\n",
        "  nn.Linear(1, 300) + leaky_relu(self.fc1(x)) # First fully connected layer\n",
        "  nn.Linear(300, 500) + leaky_relu(self.fc2(x)) # Second fully connected layer\n",
        "  nn.Linear(500, 1) # Final fully connected layer\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialize parameters of Net\n",
        "\n",
        "    Args:   \n",
        "      None\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(1, 300)\n",
        "    self.fc2 = nn.Linear(300, 500)\n",
        "    self.fc3 = nn.Linear(500, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of Net\n",
        "\n",
        "    Args:   \n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "    \n",
        "    Returns: \n",
        "      x: torch.tensor\n",
        "        Output/Predictions \n",
        "    \"\"\"\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    output = self.fc3(x)\n",
        "    return output\n",
        "\n",
        "\n",
        "class BigAnimalNet(nn.Module):\n",
        "  \"\"\"\n",
        "  Network Class - Animal Faces with following structure:\n",
        "  nn.Linear(3*32*32, 124) + leaky_relu(self.fc1(x)) # First fully connected layer\n",
        "  nn.Linear(124, 64) + leaky_relu(self.fc2(x)) # Second fully connected layer\n",
        "  nn.Linear(64, 3) # Final fully connected layer\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialize parameters for BigAnimalNet\n",
        "    \n",
        "    Args: \n",
        "      None\n",
        "\n",
        "    Returns: \n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(BigAnimalNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(3*32*32, 124)\n",
        "    self.fc2 = nn.Linear(124, 64)\n",
        "    self.fc3 = nn.Linear(64, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of BigAnimalNet\n",
        "    \n",
        "    Args: \n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns: \n",
        "      x: torch.tensor\n",
        "        Output/Predictions\n",
        "    \"\"\"\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output\n",
        "\n",
        "\n",
        "def train(args, model, train_loader, optimizer, epoch,\n",
        "          reg_function1=None, reg_function2=None, criterion=F.nll_loss):\n",
        "  \"\"\"\n",
        "  Trains the current input model using the data\n",
        "  from Train_loader and Updates parameters for a single pass\n",
        "\n",
        "  Args:\n",
        "    args: dictionary\n",
        "      Dictionary with epochs: 200, lr: 5e-3, momentum: 0.9, device: DEVICE\n",
        "    model: nn.module\n",
        "      Neural network instance \n",
        "    train_loader: torch.loader\n",
        "      Input dataset\n",
        "    optimizer: function\n",
        "      Optimizer\n",
        "    reg_function1: function\n",
        "      Regularisation function [default: None]\n",
        "    reg_function2: function\n",
        "      Regularisation function [default: None]\n",
        "    criterion: function\n",
        "      Specifies loss function [default: nll_loss]\n",
        "\n",
        "  Returns:\n",
        "    model: nn.module\n",
        "      Neural network instance post training\n",
        "  \"\"\"\n",
        "  device = args['device']\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    # L1 regularization\n",
        "    if reg_function2 is None and reg_function1 is not None:\n",
        "      loss = criterion(output, target) + args['lambda1']*reg_function1(model)\n",
        "    # L2 regularization\n",
        "    elif reg_function1 is None and reg_function2 is not None:\n",
        "      loss = criterion(output, target) + args['lambda2']*reg_function2(model)\n",
        "    # No regularization\n",
        "    elif reg_function1 is None and reg_function2 is None:\n",
        "      loss = criterion(output, target)\n",
        "    # Both L1 and L2 regularizations\n",
        "    else:\n",
        "      loss = criterion(output, target) + args['lambda1']*reg_function1(model) + args['lambda2']*reg_function2(model)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def test(model, test_loader, loader='Test', criterion=F.nll_loss,\n",
        "         device='cpu'):\n",
        "  \"\"\"\n",
        "  Tests the current model\n",
        "\n",
        "  Args:\n",
        "    model: nn.module\n",
        "      Neural network instance \n",
        "    device: string\n",
        "      GPU/CUDA if available, CPU otherwise\n",
        "    test_loader: torch.loader\n",
        "      Test dataset\n",
        "    criterion: function\n",
        "      Specifies loss function [default: nll_loss]\n",
        "\n",
        "  Returns: \n",
        "    test_loss: float \n",
        "      Test loss\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += criterion(output, target, reduction='sum').item()  # sum up batch loss\n",
        "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialize parameters for BigAnimalNet\n",
        "    \n",
        "    Args: \n",
        "      None\n",
        "\n",
        "    Returns: \n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(BigAnimalNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(3*32*32, 124)\n",
        "    self.fc2 = nn.Linear(124, 64)\n",
        "    self.fc3 = nn.Linear(64, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output\n",
        "  return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "def main(args, model, train_loader, val_loader, test_data,\n",
        "         reg_function1=None, reg_function2=None, criterion=F.nll_loss):\n",
        "  \"\"\"\n",
        "  Trains the model with train_loader and \n",
        "  tests the learned model using val_loader\n",
        "\n",
        "  Args: \n",
        "    args: dictionary\n",
        "      Dictionary with epochs: 200, lr: 5e-3, momentum: 0.9, device: DEVICE\n",
        "    model: nn.module\n",
        "      Neural network instance \n",
        "    train_loader: torch.loader\n",
        "      Train dataset\n",
        "    val_loader: torch.loader\n",
        "      Validation set\n",
        "    reg_function1: function\n",
        "      Regularisation function [default: None]\n",
        "    reg_function2: function\n",
        "      Regularisation function [default: None]\n",
        "\n",
        "  Returns:\n",
        "    val_acc_list: list\n",
        "      Log of validation accuracy\n",
        "    train_acc_list: list\n",
        "      Log of training accuracy\n",
        "    param_norm_list: list\n",
        "      Log of frobenius norm\n",
        "    trained_model: nn.module\n",
        "      Trained model/model post training\n",
        "  \"\"\"\n",
        "  device = args['device']\n",
        "\n",
        "  model = model.to(device)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "  val_acc_list, train_acc_list,param_norm_list = [], [], []\n",
        "  for epoch in tqdm(range(args['epochs'])):\n",
        "    trained_model = train(args, model, train_loader, optimizer, epoch,\n",
        "                          reg_function1=reg_function1,\n",
        "                          reg_function2=reg_function2)\n",
        "    train_acc = test(trained_model, train_loader, loader='Train', device=device)\n",
        "    val_acc = test(trained_model, val_loader, loader='Val', device=device)\n",
        "    param_norm = calculate_frobenius_norm(trained_model)\n",
        "    train_acc_list.append(train_acc)\n",
        "    val_acc_list.append(val_acc)\n",
        "    param_norm_list.append(param_norm)\n",
        "\n",
        "  return val_acc_list, train_acc_list, param_norm_list, model\n",
        "\n",
        "\n",
        "def calculate_frobenius_norm(model):\n",
        "    \"\"\"\n",
        "  Function to calculate frobenius norm\n",
        "\n",
        "  Args: \n",
        "    model: nn.module\n",
        "      Neural network instance \n",
        "\n",
        "  Returns:\n",
        "    norm: float \n",
        "      Frobenius norm\n",
        "    \"\"\"\n",
        "    norm = 0.0\n",
        "    # Sum the square of all parameters\n",
        "    for name,param in model.named_parameters():\n",
        "        norm += torch.norm(param).data**2\n",
        "    # Return a square root of the sum of squares of all the parameters\n",
        "    return norm**0.5\n",
        "\n",
        "\n",
        "def early_stopping_main(args, model, train_loader, val_loader, test_data):\n",
        "  \"\"\"\n",
        "  Function to simulate early stopping\n",
        "\n",
        "  Args:\n",
        "    args: dictionary\n",
        "      Dictionary with epochs: 200, lr: 5e-3, momentum: 0.9, device: DEVICE\n",
        "    model: nn.module\n",
        "      Neural network instance \n",
        "    train_loader: torch.loader\n",
        "      Train dataset\n",
        "    val_loader: torch.loader\n",
        "      Validation set\n",
        "\n",
        "  Returns:\n",
        "    val_acc_list: list\n",
        "      Val accuracy log until early stop point\n",
        "    train_acc_list: list\n",
        "      Training accuracy log until early stop point\n",
        "    best_model: nn.module\n",
        "      Model performing best with early stopping\n",
        "    best_epoch: int\n",
        "      Epoch at which early stopping occurs\n",
        "  \"\"\"\n",
        "  device = args['device']\n",
        "\n",
        "  model = model.to(device)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "  best_acc  = 0.0\n",
        "  best_epoch = 0\n",
        "\n",
        "  # Number of successive epochs that you want to wait before stopping training process\n",
        "  patience = 20\n",
        "\n",
        "  # Keps track of number of epochs during which the val_acc was less than best_acc\n",
        "  wait = 0\n",
        "\n",
        "  val_acc_list, train_acc_list = [], []\n",
        "  for epoch in tqdm(range(args['epochs'])):\n",
        "    trained_model = train(args, model, device, train_loader, optimizer, epoch)\n",
        "    train_acc = test(trained_model, train_loader, loader='Train', device=device)\n",
        "    val_acc = test(trained_model, val_loader, loader='Val', device=device)\n",
        "    if (val_acc > best_acc):\n",
        "      best_acc = val_acc\n",
        "      best_epoch = epoch\n",
        "      best_model = copy.deepcopy(trained_model)\n",
        "      wait = 0\n",
        "    else:\n",
        "      wait += 1\n",
        "    if (wait > patience):\n",
        "      print(f'Early stopped on epoch: {epoch}')\n",
        "      break\n",
        "    train_acc_list.append(train_acc)\n",
        "    val_acc_list.append(val_acc)\n",
        "\n",
        "  return val_acc_list, train_acc_list, best_model, best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "execution": {},
        "id": "EpZ8MwsXdhdc"
      },
      "outputs": [],
      "source": [
        "# @title Set random seed\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# For DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "execution": {},
        "id": "r8NIDPHidhdd"
      },
      "outputs": [],
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# Inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "execution": {},
        "id": "cAI0bd2Udhdf",
        "outputId": "fb0add62-0f10-4e9e-9a40-224d653bb6b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"
          ]
        }
      ],
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "execution": {},
        "id": "d1k8kjfsdhdg"
      },
      "outputs": [],
      "source": [
        "# @title Dataloaders for the Dataset\n",
        "## Dataloaders for the Dataset\n",
        "batch_size = 128\n",
        "classes = ('cat', 'dog', 'wild')\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "data_path = pathlib.Path('.')/'afhq' # Using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "\n",
        "\n",
        "####################################################\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "\n",
        "## Dataloaders for the  Original Dataset\n",
        "img_train_data, img_val_data,_ = torch.utils.data.random_split(img_dataset,\n",
        "                                                               [100, 100, 14430])\n",
        "\n",
        "# Creating train_loader and Val_loader\n",
        "train_loader = torch.utils.data.DataLoader(img_train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           worker_init_fn=seed_worker,\n",
        "                                           num_workers=2,\n",
        "                                           generator=g_seed)\n",
        "val_loader = torch.utils.data.DataLoader(img_val_data,\n",
        "                                         batch_size=1000,\n",
        "                                         num_workers=2,\n",
        "                                         worker_init_fn=seed_worker,\n",
        "                                         generator=g_seed)\n",
        "\n",
        "# Creating test dataset\n",
        "test_transform = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "img_test_dataset = ImageFolder(data_path/'val', transform=test_transform)\n",
        "\n",
        "\n",
        "####################################################\n",
        "\n",
        "## Dataloaders for the  Random Dataset\n",
        "\n",
        "# Splitting randomized data into training and validation data\n",
        "data_path = pathlib.Path('.')/'afhq_random_32x32/afhq_random' # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "random_img_train_data, random_img_val_data,_ = torch.utils.data.random_split(img_dataset, [100,100,14430])\n",
        "\n",
        "# Randomized train and validation dataloader\n",
        "rand_train_loader = torch.utils.data.DataLoader(random_img_train_data,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=2,\n",
        "                                                worker_init_fn=seed_worker,\n",
        "                                                generator=g_seed)\n",
        "rand_val_loader = torch.utils.data.DataLoader(random_img_val_data,\n",
        "                                              batch_size=1000,\n",
        "                                              num_workers=2,\n",
        "                                              worker_init_fn=seed_worker,\n",
        "                                              generator=g_seed)\n",
        "\n",
        "####################################################\n",
        "\n",
        "## Dataloaders for the Partially Random Dataset\n",
        "\n",
        "# Splitting data between training and validation dataset for partially randomized data\n",
        "data_path = pathlib.Path('.')/'afhq_10_32x32/afhq_10' # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "partially_random_train_data, partially_random_val_data, _ = torch.utils.data.random_split(img_dataset, [100,100,14430])\n",
        "\n",
        "# Training and Validation loader for partially randomized data\n",
        "partial_rand_train_loader = torch.utils.data.DataLoader(partially_random_train_data,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        num_workers=2,\n",
        "                                                        worker_init_fn=seed_worker,\n",
        "                                                        generator=g_seed)\n",
        "partial_rand_val_loader = torch.utils.data.DataLoader(partially_random_val_data,\n",
        "                                                      batch_size=1000,\n",
        "                                                      num_workers=2,\n",
        "                                                      worker_init_fn=seed_worker,\n",
        "                                                      generator=g_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3seqC45Jdhdi"
      },
      "source": [
        "---\n",
        "# Section 1: L1 and L2 Regularization\n",
        "\n",
        "*Time estimate: ~30 mins*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "execution": {},
        "id": "zPMrgKaodhdi",
        "outputId": "b8e85401-b738-46c4-95ed-57c2a6123eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580,
          "referenced_widgets": [
            "935be0a6f02e4e1cb15961770d2867bc",
            "443d86adc3c84a4aacbd48dd7cec8581",
            "e24430388c2e4cf2a245ff6dfe675eb1",
            "6065e5f0f3f8458e951ee9038fa871df",
            "0b0ada48cc6f47a2a6498bde28ab7eca",
            "8865987d557f48e597e7adab64ea8814"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "935be0a6f02e4e1cb15961770d2867bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Video 1: L1 and L2 regression\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV19h41167H7\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"oQNdloKdysM\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Video 1: L1 and L2 regression')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "wO79M3M2dhdk"
      },
      "source": [
        "Some of you might have already come across L1 and L2 regularization before in other courses. L1 and L2 are the most common types of regularization. These update the general cost function by adding another term known as the regularization term.\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Cost function} = Loss(\\text{e.g., binary cross entropy}) + \\text{Regularization term}\n",
        "\\end{equation}\n",
        "\n",
        "<br>\n",
        "\n",
        "This regularization term makes the parameters smaller, giving simpler models that will overfit less.\n",
        "\n",
        "Discuss among your teammates whether the above assumption is good or bad?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "JmMqDBEjdhdk"
      },
      "source": [
        "## Section 1.1: Unregularized Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "execution": {},
        "id": "OgbGAS75dhdl"
      },
      "outputs": [],
      "source": [
        "# @markdown #### Dataloaders for Regularization\n",
        "data_path = pathlib.Path('.')/'afhq' # Using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "\n",
        "# Splitting dataset\n",
        "reg_train_data, reg_val_data,_ = torch.utils.data.random_split(img_dataset,\n",
        "                                                               [30, 100, 14500])\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "# Creating train_loader and Val_loader\n",
        "reg_train_loader = torch.utils.data.DataLoader(reg_train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               worker_init_fn=seed_worker,\n",
        "                                               num_workers=2,\n",
        "                                               generator=g_seed)\n",
        "reg_val_loader = torch.utils.data.DataLoader(reg_val_data,\n",
        "                                             batch_size=1000,\n",
        "                                             worker_init_fn=seed_worker,\n",
        "                                             num_workers=2,\n",
        "                                             generator=g_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ATWGUyKMdhdl"
      },
      "source": [
        "Now let's train a model without regularization and keep it aside as our benchmark for this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "execution": {},
        "id": "eNu3ORtVdhdl",
        "outputId": "e754bb3a-10ee-491f-adcf-e9dffb1b926e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "42b98c07dca34e9cb9dc7b3f149a24f1",
            "91ece4f75d474133aaecc24a1a1801bf",
            "5ad51d7b39c549c8a59e87c5c605b33a",
            "527420e7b3db401f9e9fade9df7475d3",
            "5f78b9d027544a11be2bc054920a761c",
            "d0026b27c8a744e497ff5e6a2ac1a452",
            "bd0e87ae1a6b46cbba625349ea3bcdf7",
            "18e135091733430caabbbdb42c81f648",
            "16146407a86f4096b1dbbfe3f41c66e2",
            "e7cbf67123a547c8981134ec7e4e491a",
            "7092fb52a1ae4aa48eee9136c20ed935"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42b98c07dca34e9cb9dc7b3f149a24f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-7781b4717f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                            \u001b[0mreg_train_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                            \u001b[0mreg_val_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                                            img_test_dataset)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Train and Test accuracy plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-3383a593c52b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, model, train_loader, val_loader, test_data, reg_function1, reg_function2, criterion)\u001b[0m\n\u001b[1;32m    276\u001b[0m                           reg_function2=reg_function2)\n\u001b[1;32m    277\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_frobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-3383a593c52b>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader, loader, criterion, device)\u001b[0m\n\u001b[1;32m    202\u001b[0m   \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set the arguments\n",
        "args = {\n",
        "    'epochs': 150,\n",
        "    'lr': 5e-3,\n",
        "    'momentum': 0.99,\n",
        "    'device': DEVICE,\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = AnimalNet()\n",
        "\n",
        "# Train the model\n",
        "val_acc_unreg, train_acc_unreg, param_norm_unreg, _ = main(args,\n",
        "                                                           model,\n",
        "                                                           reg_train_loader,\n",
        "                                                           reg_val_loader,\n",
        "                                                           img_test_dataset)\n",
        "\n",
        "# Train and Test accuracy plot\n",
        "plt.figure()\n",
        "plt.plot(val_acc_unreg, label='Val Accuracy', c='red', ls='dashed')\n",
        "plt.plot(train_acc_unreg, label='Train Accuracy', c='red', ls='solid')\n",
        "plt.axhline(y=max(val_acc_unreg), c='green', ls='dashed')\n",
        "plt.title('Unregularized Model')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(f\"Maximum Validation Accuracy reached: {max(val_acc_unreg)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Z1WIddgTdhdm"
      },
      "source": [
        "## Section 1.2: L1 Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NDkUZI4pdhdo"
      },
      "source": [
        "L1 Regularization (or LASSO$^{\\ddagger}$) uses a penalty which is the sum of the absolute value of all the weights in the Deep Learning architecture, resulting in the following loss function ($L$ is the usual Cross-Entropy loss):\n",
        "\n",
        "\\begin{equation}\n",
        "  L_R = L + \\lambda \\sum \\left| w^{(r)}_{ij} \\right|\n",
        "\\end{equation}\n",
        "\n",
        "where $r$ denotes the layer, and $ij$ the specific weight in that layer.\n",
        "\n",
        "At a high level, L1 Regularization is similar to L2 Regularization since it leads to smaller weights (you will see the analogy in the next subsection). It results in the following weight update equation when using Stochastic Gradient Descent:\n",
        "\n",
        "\\begin{equation}\n",
        "  w^{(r)}_{ij}←w^{(r)}_{ij} − \\eta \\cdot \\lambda \\cdot \\text{sgn}\\left(w^{(r)}_{ij}\\right)−\\eta \\frac{\\partial L}{\\partial w_{ij}^{(r)}} \n",
        "\\end{equation}\n",
        "\n",
        "where  $\\text{sgn}(\\cdot)$ is the sign function, such that\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{sgn}(w) = \n",
        "\\left\\{\n",
        "  \\begin{array}{ll}\n",
        "  +1 & \\mbox{if  } w > 0 \\\\\n",
        "  -1 & \\mbox{if  } w < 0 \\\\\n",
        "  0 & \\mbox{if  } w = 0\n",
        "  \\end{array}\n",
        "\\right.\n",
        "\\end{equation}\n",
        "\n",
        "<br>\n",
        "\n",
        "$^{\\ddagger}$LASSO: Least Absolute Shrinkage and Selection Operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Bmts8sXydhdo"
      },
      "source": [
        "### Coding Exercise 1.1: L1 Regularization\n",
        "\n",
        "Write a function that calculates the L1 norm of all the tensors of a PyTorch model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "8kbpYZ5gdhdp"
      },
      "outputs": [],
      "source": [
        "def l1_reg(model):\n",
        "  \"\"\"\n",
        "  This function calculates the l1 norm of the all the tensors in the model\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  l1 = 0.0\n",
        "  ####################################################################\n",
        "  # Fill in all missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Complete the l1_reg function\")\n",
        "  ####################################################################\n",
        "  for param in model.parameters():\n",
        "    l1 += ...\n",
        "\n",
        "  return l1\n",
        "\n",
        "# Add event to airtable\n",
        "atform.add_event('Coding Exercise 1.1: L1 Regularization')\n",
        "\n",
        "set_seed(seed=SEED)\n",
        "## uncomment to test\n",
        "# net = nn.Linear(20, 20)\n",
        "# print(f\"L1 norm of the model: {l1_reg(net)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "R_njSF5_dhdp"
      },
      "outputs": [],
      "source": [
        "# to_remove solution\n",
        "def l1_reg(model):\n",
        "  \"\"\"\n",
        "    Inputs: Pytorch model\n",
        "    This function calculates the l1 norm of the all the tensors in the model\n",
        "  \"\"\"\n",
        "  l1 = 0.0\n",
        "\n",
        "  for param in model.parameters():\n",
        "    l1 += torch.sum(torch.abs(param))\n",
        "\n",
        "  return l1\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 1.1: L1 Regularization')\n",
        "\n",
        "set_seed(seed=SEED)\n",
        "## uncomment to test\n",
        "net = nn.Linear(20, 20)\n",
        "print(f\"L1 norm of the model: {l1_reg(net)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "w56leNTrdhdp"
      },
      "source": [
        "```\n",
        "Random seed 2021 has been set.\n",
        "L1 norm of the model: 48.445133209228516\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "MOGFMhFwdhdq"
      },
      "source": [
        "Now, let's train a classifier that uses L1 regularization. Tune the hyperparameter `lambda1` such that the validation accuracy is higher than that of the unregularized model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "bls2yV2sdhdq"
      },
      "outputs": [],
      "source": [
        "# Set the arguments\n",
        "args1 = {\n",
        "    'test_batch_size': 1000,\n",
        "    'epochs': 150,\n",
        "    'lr': 5e-3,\n",
        "    'momentum': 0.99,\n",
        "    'device': DEVICE,\n",
        "    'lambda1': 0.001  # <<<<<<<< Tune the hyperparameter lambda1\n",
        "}\n",
        "\n",
        "# intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = AnimalNet()\n",
        "\n",
        "# Train the model\n",
        "val_acc_l1reg, train_acc_l1reg, param_norm_l1reg, _ = main(args1,\n",
        "                                                           model,\n",
        "                                                           reg_train_loader,\n",
        "                                                           reg_val_loader,\n",
        "                                                           img_test_dataset,\n",
        "                                                           reg_function1=l1_reg)\n",
        "\n",
        "# Train and Test accuracy plot\n",
        "plt.figure()\n",
        "plt.plot(val_acc_l1reg, label='Val Accuracy L1 Regularized',\n",
        "         c='red', ls='dashed')\n",
        "plt.plot(train_acc_l1reg, label='Train Accuracy L1 regularized',\n",
        "         c='red', ls='solid')\n",
        "plt.axhline(y=max(val_acc_l1reg), c='green', ls='dashed')\n",
        "plt.title('L1 regularized model')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(f\"maximum Validation Accuracy reached: {max(val_acc_l1reg)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ES4--WkOdhdr"
      },
      "source": [
        "What value of `lambda1` hyperparameter worked for L1 Regularization?\n",
        "\n",
        "**Note:** that the $\\lambda$ in the equations is the `lambda1` in the code for clarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "dUxslECndhdr"
      },
      "source": [
        "## Section 1.3: L2 / Ridge Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "jL7R--x0dhds"
      },
      "source": [
        "L2 Regularization (or Ridge), also referred to as “Weight Decay”, is widely used. It works by adding a quadratic penalty term to the Cross-Entropy Loss Function $L$, which results in a new Loss Function $L_R$ given by:\n",
        "\n",
        "\\begin{equation}\n",
        "L_R = L + \\lambda \\sum \\left( w^{(r)}_{ij} \\right)^2\n",
        "\\end{equation}\n",
        "\n",
        "where, again, $r$ superscript denotes the layer, and $ij$ the specific weight in that layer.\n",
        "\n",
        "To get further insight into L2 Regularization, we investigate its effect on the Gradient Descent based update equations for the weight and bias parameters. Taking the derivative on both sides of the above equation, we obtain\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial L_R}{\\partial w^{(r)}_{ij}}=\\frac{\\partial L}{\\partial w^{(r)}_{ij}} + 2\\lambda w^{(r)}_{ij}\n",
        "\\end{equation}\n",
        "\n",
        "Thus the weight update rule becomes:\n",
        "\n",
        "\\begin{equation}\n",
        "w^{(r)}_{ij}←w^{(r)}_{ij}−η\\frac{\\partial L}{\\partial w^{(r)}_{ij}}−2 \\eta \\lambda w^{(r)}_{ij}=(1−2 \\eta \\lambda)w^{(r)}_{ij} − \\eta \\frac{\\partial L}{\\partial w^{(r)}_{ij}}\n",
        "\\end{equation}\n",
        "\n",
        "where $\\eta$ is the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HSnkf1x2dhds"
      },
      "source": [
        "### Coding Exercise 1.2: L2 Regularization\n",
        "\n",
        "Write a function that calculates the L2 norm of all the tensors of a PyTorch model. (What did we call this before?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "gtK3FCoQdhdt"
      },
      "outputs": [],
      "source": [
        "def l2_reg(model):\n",
        "\n",
        "  \"\"\"\n",
        "    Inputs: Pytorch model\n",
        "    This function calculates the l2 norm of the all the tensors in the model\n",
        "  \"\"\"\n",
        "\n",
        "  l2 = 0.0\n",
        "  ####################################################################\n",
        "  # Fill in all missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Complete the l2_reg function\")\n",
        "  ####################################################################\n",
        "  for param in model.parameters():\n",
        "    l2 += ...\n",
        "\n",
        "  return l2\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 1.2: L2 Regularization')\n",
        "\n",
        "set_seed(SEED)\n",
        "## uncomment to test\n",
        "# net = nn.Linear(20, 20)\n",
        "# print(f\"L2 norm of the model: {l2_reg(net)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "rAVvSMM7dhdu"
      },
      "outputs": [],
      "source": [
        "# to_remove solution\n",
        "def l2_reg(model):\n",
        "\n",
        "  \"\"\"\n",
        "    Inputs: Pytorch model\n",
        "    This function calculates the l2 norm of the all the tensors in the model\n",
        "  \"\"\"\n",
        "\n",
        "  l2 = 0.0\n",
        "  for param in model.parameters():\n",
        "    l2 += torch.sum(torch.abs(param)**2)\n",
        "\n",
        "  return l2\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 1.2: L2 Regularization')\n",
        "\n",
        "set_seed(SEED)\n",
        "## uncomment to test\n",
        "net = nn.Linear(20, 20)\n",
        "print(f\"L2 norm of the model: {l2_reg(net)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "XeJ3k0Kmdhdu"
      },
      "source": [
        "```\n",
        "Random seed 2021 has been set.\n",
        "L2 norm of the model: 7.328375816345215\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NEMg1xeQdhdv"
      },
      "source": [
        "Now we'll train a classifier that uses L2 regularization. Tune the hyperparameter `lambda2` such that the validation accuracy is higher than that of the unregularized model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "_ObJrUPpdhdv"
      },
      "outputs": [],
      "source": [
        "# Set the arguments\n",
        "args2 = {\n",
        "    'test_batch_size': 1000,\n",
        "    'epochs': 150,\n",
        "    'lr': 5e-3,\n",
        "    'momentum': 0.99,\n",
        "    'device': DEVICE,\n",
        "    'lambda2': 0.001  # <<<<<<<< Tune the hyperparameter lambda2\n",
        "}\n",
        "\n",
        "# intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = AnimalNet()\n",
        "\n",
        "# Train the model\n",
        "val_acc_l2reg, train_acc_l2reg, param_norm_l2reg, model = main(args2,\n",
        "                                                               model,\n",
        "                                                               train_loader,\n",
        "                                                               val_loader,\n",
        "                                                               img_test_dataset,\n",
        "                                                               reg_function2=l2_reg)\n",
        "\n",
        "## Train and Test accuracy plot\n",
        "plt.figure()\n",
        "plt.plot(val_acc_l2reg, label='Val Accuracy L2 regularized',\n",
        "         c='red', ls='dashed')\n",
        "plt.plot(train_acc_l2reg, label='Train Accuracy L2 regularized',\n",
        "         c='red', ls='solid')\n",
        "plt.axhline(y=max(val_acc_l2reg), c='green', ls='dashed')\n",
        "plt.title('L2 Regularized Model')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(f\"maximum Validation Accuracy reached: {max(val_acc_l2reg)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1PRKmkobdhdw"
      },
      "source": [
        "What value `lambda2` worked for L2 Regularization?\n",
        "\n",
        "**Note:** that the $\\lambda$ in the equations is the `lambda2` in the code for clarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "U0nI4BK7dhdw"
      },
      "source": [
        "Now, let's run a model with both L1 and L2 regularization terms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "6gItDOT6dhdx"
      },
      "outputs": [],
      "source": [
        "# @markdown Visualize all of them together (Run Me!)\n",
        "\n",
        "# @markdown `lambda1=0.001` and `lambda2=0.001`\n",
        "\n",
        "args3 = {\n",
        "    'test_batch_size': 1000,\n",
        "    'epochs': 150,\n",
        "    'lr': 5e-3,\n",
        "    'momentum': 0.99,\n",
        "    'device': DEVICE,\n",
        "    'lambda1': 0.001,\n",
        "    'lambda2': 0.001\n",
        "}\n",
        "\n",
        "# Intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = AnimalNet()\n",
        "val_acc_l1l2reg, train_acc_l1l2reg, param_norm_l1l2reg, _ = main(args3,\n",
        "                                                                 model,\n",
        "                                                                 train_loader,\n",
        "                                                                 val_loader,\n",
        "                                                                 img_test_dataset,\n",
        "                                                                 reg_function1=l1_reg,\n",
        "                                                                 reg_function2=l2_reg)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(val_acc_l2reg, c='red', ls='dashed')\n",
        "plt.plot(train_acc_l2reg,\n",
        "         label=f\"L2 regularized, $\\lambda_2$={args2['lambda2']}\",\n",
        "         c='red', ls='solid')\n",
        "plt.axhline(y=max(val_acc_l2reg), c='red', ls='dashed')\n",
        "\n",
        "plt.plot(val_acc_l1reg, c='green', ls = 'dashed')\n",
        "plt.plot(train_acc_l1reg,\n",
        "         label=f\"L1 regularized, $\\lambda_1$={args1['lambda1']}\",\n",
        "         c='green', ls='solid')\n",
        "plt.axhline(y=max(val_acc_l1reg), c='green', ls='dashed')\n",
        "\n",
        "plt.plot(val_acc_unreg, c='blue', ls = 'dashed')\n",
        "plt.plot(train_acc_unreg,\n",
        "         label='Unregularized', c='blue', ls='solid')\n",
        "plt.axhline(y=max(val_acc_unreg), c='blue', ls='dashed')\n",
        "\n",
        "plt.plot(val_acc_l1l2reg, c='orange', ls='dashed')\n",
        "plt.plot(train_acc_l1l2reg,\n",
        "         label=f\"L1+L2 regularized, $\\lambda_1$={args3['lambda1']}, $\\lambda_2$={args3['lambda2']}\",\n",
        "         c='orange', ls='solid')\n",
        "plt.axhline(y=max(val_acc_l1l2reg), c='orange', ls = 'dashed')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "eVzDQff1dhdy"
      },
      "source": [
        "Now, let's visualize what these different regularizations do to the model's parameters. We observe the effect by computing the size (technically, the Frobenius norm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "bzuQjNdadhdy"
      },
      "outputs": [],
      "source": [
        "# @markdown #### Visualize Norm of the Models (Train Me!)\n",
        "plt.figure()\n",
        "plt.plot(param_norm_unreg, label='Unregularized', c='blue')\n",
        "plt.plot(param_norm_l1reg, label='L1 Regularized', c='green')\n",
        "plt.plot(param_norm_l2reg, label='L2 Regularized', c='red')\n",
        "plt.plot(param_norm_l1l2reg, label='L1+L2 Regularized', c='orange')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Parameter Norms')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "b0-soKB1dhdy"
      },
      "source": [
        "In the above plots, you should have seen that the validation accuracies fluctuate even after the model achieves 100% train accuracy. Thus, the model is still trying to learn something. Why would this be the case?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "QGYsB2F1dhdz"
      },
      "source": [
        "---\n",
        "# Section 2: Dropout\n",
        "\n",
        "*Time estimate: ~25 mins*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "mEuKrFJydhdz"
      },
      "outputs": [],
      "source": [
        "# @title Video 2: Dropout\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1gU4y1G7V2\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"UZfUzawej3A\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 2: Dropout')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "OaKrniuZdhd0"
      },
      "source": [
        "With Dropout, we literally drop out (zero out) some neurons during training. Throughout the training, the standard dropout zeros out some fraction (usually 50%) of the nodes in each layer, and on each iteration, before calculating the subsequent layer. Randomly selecting different subsets to drop out introduces noise into the process and reduces overfitting.\n",
        "\n",
        "<br>\n",
        "\n",
        "<center><img src=\"https://d2l.ai/_images/dropout2.svg\" alt=\"Dropout\" width=\"600\"/></center>\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BPJU1IUldhd1"
      },
      "source": [
        "Now let's revisit the toy dataset we generated above to visualize how the Dropout stabilizes training on a noisy dataset. We will slightly modify the architecture we used above to add dropout layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "zK7Rl2RWdhd1"
      },
      "outputs": [],
      "source": [
        "# Network Class - 2D\n",
        "class NetDropout(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetDropout, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(1, 300)\n",
        "    self.fc2 = nn.Linear(300, 500)\n",
        "    self.fc3 = nn.Linear(500, 1)\n",
        "    # We add two dropout layers\n",
        "    self.dropout1 = nn.Dropout(0.4)\n",
        "    self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.dropout1(self.fc1(x)))\n",
        "    x = F.leaky_relu(self.dropout2(self.fc2(x)))\n",
        "    output = self.fc3(x)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "FljmtZJLdhd2"
      },
      "outputs": [],
      "source": [
        "# @markdown #### Run to train the default network\n",
        "set_seed(seed=SEED)\n",
        "# creating train data\n",
        "X = torch.rand((10, 1))\n",
        "X.sort(dim = 0)\n",
        "Y = 2*X + 2*torch.empty((X.shape[0], 1)).normal_(mean=0, std=1)  # adding small error in the data\n",
        "\n",
        "X = X.unsqueeze_(1)\n",
        "Y = Y.unsqueeze_(1)\n",
        "\n",
        "# creating test dataset\n",
        "X_test = torch.linspace(0, 1, 40)\n",
        "X_test = X_test.reshape((40, 1, 1))\n",
        "\n",
        "# train the network on toy dataset\n",
        "model = Net()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "max_epochs = 10000\n",
        "iters = 0\n",
        "\n",
        "running_predictions = np.empty((40, (int)(max_epochs/500 + 1)))\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "model_norm = []\n",
        "\n",
        "for epoch in tqdm(range(max_epochs)):\n",
        "\n",
        "  #training\n",
        "  model_norm.append(calculate_frobenius_norm(model))\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  predictions = model(X)\n",
        "  loss = criterion(predictions,Y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  train_loss.append(loss.data)\n",
        "  model.eval()\n",
        "  Y_test = model(X_test)\n",
        "  loss = criterion(Y_test, 2*X_test)\n",
        "  test_loss.append(loss.data)\n",
        "\n",
        "  if (epoch % 500 == 0 or epoch == max_epochs - 1):\n",
        "    running_predictions[:, iters] = Y_test[:, 0, 0].detach().numpy()\n",
        "    iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "wRgfuxNodhd2"
      },
      "outputs": [],
      "source": [
        "# train the network on toy dataset\n",
        "\n",
        "# Intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = NetDropout()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "max_epochs = 10000\n",
        "iters = 0\n",
        "\n",
        "running_predictions_dp = np.empty((40, (int)(max_epochs / 500)))\n",
        "\n",
        "train_loss_dp = []\n",
        "test_loss_dp = []\n",
        "model_norm_dp = []\n",
        "\n",
        "for epoch in tqdm(range(max_epochs)):\n",
        "\n",
        "  # training\n",
        "  model_norm_dp.append(calculate_frobenius_norm(model))\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  predictions = model(X)\n",
        "  loss = criterion(predictions, Y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  train_loss_dp.append(loss.data)\n",
        "  model.eval()\n",
        "  Y_test = model(X_test)\n",
        "  loss = criterion(Y_test, 2*X_test)\n",
        "  test_loss_dp.append(loss.data)\n",
        "\n",
        "  if (epoch % 500 == 0 or epoch == max_epochs):\n",
        "    running_predictions_dp[:, iters] = Y_test[:, 0, 0].detach().numpy()\n",
        "    iters += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TcuxdhSGdhd3"
      },
      "source": [
        "Now that we have finished the training, let's see how the model has evolved over the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "XGM7IOp6dhd4"
      },
      "outputs": [],
      "source": [
        "# @markdown Animation! (Run Me!)\n",
        "set_seed(seed=SEED)\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = plt.axes()\n",
        "def frame(i):\n",
        "  ax.clear()\n",
        "  ax.scatter(X[:, 0, :].numpy(), Y[:, 0, :].numpy())\n",
        "  plot = ax.plot(X_test[:, 0, :].detach().numpy(),\n",
        "                 running_predictions_dp[:, i])\n",
        "  title = f\"Epoch: {i*500}\"\n",
        "  plt.title(title)\n",
        "  ax.set_xlabel(\"X axis\")\n",
        "  ax.set_ylabel(\"Y axis\")\n",
        "  return plot\n",
        "\n",
        "\n",
        "anim = animation.FuncAnimation(fig, frame, frames=range(20),\n",
        "                               blit=False, repeat=False,\n",
        "                               repeat_delay=10000)\n",
        "html_anim = HTML(anim.to_html5_video());\n",
        "plt.close()\n",
        "display(html_anim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "9NZFG6jzdhd4"
      },
      "outputs": [],
      "source": [
        "# @markdown Plot the train and test losses with epoch\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(test_loss_dp, label='test loss dropout', c='blue', ls='dashed')\n",
        "plt.plot(test_loss, label='test loss', c='red', ls='dashed')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('dropout vs without dropout')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Zn8Ey32bdhd5"
      },
      "outputs": [],
      "source": [
        "# @markdown Plot the train and test losses with epoch\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_loss_dp, label='train loss dropout', c='blue', ls='dashed')\n",
        "plt.plot(train_loss, label='train loss', c='red', ls='dashed')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('dropout vs without dropout')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "USirYxrIdhd6"
      },
      "outputs": [],
      "source": [
        "# @markdown Plot model weights with epoch\n",
        "plt.figure()\n",
        "plt.plot(model_norm_dp, label='dropout')\n",
        "plt.plot(model_norm, label='no dropout')\n",
        "plt.ylabel('norm of the model')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.title('Size of the model vs Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "7zYCUEr3dhd6"
      },
      "source": [
        "Do you think this performed better than the initial model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "hqZgBZ6Udhd7"
      },
      "source": [
        "## Section 2.1: Dropout Implementation Caveats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "_CpxVDvudhd7"
      },
      "source": [
        "* Dropout is used only during training. However, the complete model weights are used during testing, so it is vital to use the `model.eval()` method before testing the model. \n",
        "\n",
        "* Dropout reduces the capacity of the model during training, and hence as a general practice, wider networks are used when using dropout. If you are using a dropout with a random probability of 0.5, you might want to double the number of hidden neurons in that layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tq4PFDxSdhd7"
      },
      "source": [
        "Now, let's see how dropout fares on the “Animal Faces” dataset. We first modify the existing model to include dropout and then train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "kWoecVb3dhd8"
      },
      "outputs": [],
      "source": [
        "# Network Class - Animal Faces\n",
        "class AnimalNetDropout(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AnimalNetDropout, self).__init__()\n",
        "    self.fc1 = nn.Linear(3*32*32, 248)\n",
        "    self.fc2 = nn.Linear(248, 210)\n",
        "    self.fc3 = nn.Linear(210, 3)\n",
        "    self.dropout1 = nn.Dropout(p=0.5)\n",
        "    self.dropout2 = nn.Dropout(p=0.3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = F.leaky_relu(self.dropout1(self.fc1(x)))\n",
        "    x = F.leaky_relu(self.dropout2(self.fc2(x)))\n",
        "    x = self.fc3(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "ibGwPfMOdhd8"
      },
      "outputs": [],
      "source": [
        "# Set the arguments\n",
        "args = {\n",
        "    'test_batch_size': 1000,\n",
        "    'epochs': 200,\n",
        "    'lr': 5e-3,\n",
        "    'batch_size': 32,\n",
        "    'momentum': 0.9,\n",
        "    'device': DEVICE,\n",
        "    'log_interval': 100\n",
        "}\n",
        "\n",
        "# intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = AnimalNetDropout()\n",
        "\n",
        "# Train the model with Dropout\n",
        "val_acc_dropout, train_acc_dropout, _, model_dp = main(args,\n",
        "                                                       model,\n",
        "                                                       train_loader,\n",
        "                                                       val_loader,\n",
        "                                                       img_test_dataset)\n",
        "\n",
        "# intialize the BigAnimalNet model\n",
        "set_seed(seed=SEED)\n",
        "model = BigAnimalNet()\n",
        "\n",
        "# Train the model\n",
        "val_acc_big, train_acc_big, _, model_big = main(args,\n",
        "                                                model,\n",
        "                                                train_loader,\n",
        "                                                val_loader,\n",
        "                                                img_test_dataset)\n",
        "\n",
        "\n",
        "# Train and Test accuracy plot\n",
        "plt.figure()\n",
        "plt.plot(val_acc_big, label='Val - Big', c='blue', ls='dashed')\n",
        "plt.plot(train_acc_big, label='Train - Big', c='blue', ls='solid')\n",
        "plt.plot(val_acc_dropout, label='Val - DP', c='magenta', ls='dashed')\n",
        "plt.plot(train_acc_dropout, label='Train - DP', c='magenta', ls='solid')\n",
        "plt.title('Dropout')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "q3bUWFtcdhd-"
      },
      "source": [
        "When do you think dropouts can perform bad and do you think their placement within a model matters?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HBgSOVEvdhd-"
      },
      "source": [
        "---\n",
        "# Section 3: Data Augmentation\n",
        "\n",
        "*Time estimate: ~15 mins*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "4L1nahaRdhd-"
      },
      "outputs": [],
      "source": [
        "# @title Video 3: Data Augmentation\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1Xw411d7Pz\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"nm44FhjL3xc\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 3: Data Augmentation')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "L2O9AITZdheA"
      },
      "source": [
        "Data augmentation is often used to increase the number of training samples. Now we will explore the effects of data augmentation on regularization. Here regularization is achieved by adding noise into training data after every epoch.\n",
        "\n",
        "PyTorch's torchvision module provides a few built-in data augmentation techniques, which we can use on image datasets. Some of the techniques we most frequently use are:\n",
        "\n",
        "* Random Crop\n",
        "* Random Rotate\n",
        "* Vertical Flip\n",
        "* Horizontal Flip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "QDRLn6NudheB"
      },
      "outputs": [],
      "source": [
        "# @markdown ####  Data Loader without Data Augmentation\n",
        "\n",
        "# For reproducibility\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "data_path = pathlib.Path('.')/'afhq' # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "\n",
        "# Splitting dataset\n",
        "img_train_data, img_val_data,_ = torch.utils.data.random_split(img_dataset, [250,100,14280])\n",
        "\n",
        "# Creating train_loader and Val_loader\n",
        "train_loader = torch.utils.data.DataLoader(img_train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           num_workers=2,\n",
        "                                           worker_init_fn=seed_worker,\n",
        "                                           generator=g_seed)\n",
        "val_loader = torch.utils.data.DataLoader(img_val_data,\n",
        "                                         batch_size=1000,\n",
        "                                         num_workers=2,\n",
        "                                         worker_init_fn=seed_worker,\n",
        "                                         generator=g_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rpgAbckcdheD"
      },
      "source": [
        "Define a DataLoader using `torchvision.transforms`, which randomly augments the data for us. For more info, see [here](https://pytorch.org/vision/stable/transforms.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "2YoKtICndheE"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation using transforms\n",
        "new_transforms = transforms.Compose([\n",
        "                                     transforms.RandomHorizontalFlip(p=0.1),\n",
        "                                     transforms.RandomVerticalFlip(p=0.1),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                                          (0.5, 0.5, 0.5))\n",
        "                                     ])\n",
        "\n",
        "data_path = pathlib.Path('.')/'afhq'  # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=new_transforms)\n",
        "# Splitting dataset\n",
        "new_train_data, _,_ = torch.utils.data.random_split(img_dataset,\n",
        "                                                    [250, 100, 14280])\n",
        "\n",
        "# For reproducibility\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "# Creating train_loader and Val_loader\n",
        "new_train_loader = torch.utils.data.DataLoader(new_train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               worker_init_fn=seed_worker,\n",
        "                                               generator=g_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "vnGLJ_SEdheG"
      },
      "outputs": [],
      "source": [
        "# Set the arguments\n",
        "args = {\n",
        "    'epochs': 250,\n",
        "    'lr': 1e-3,\n",
        "    'momentum': 0.99,\n",
        "    'device': DEVICE,\n",
        "}\n",
        "\n",
        "# Intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model_aug = AnimalNet()\n",
        "\n",
        "# train the model\n",
        "val_acc_dataaug, train_acc_dataaug, param_norm_dataaug, _ = main(args,\n",
        "                                                                 model_aug,\n",
        "                                                                 new_train_loader,\n",
        "                                                                 val_loader,\n",
        "                                                                 img_test_dataset)\n",
        "# Intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model_pure = AnimalNet()\n",
        "\n",
        "val_acc_pure, train_acc_pure, param_norm_pure, _, = main(args,\n",
        "                                                         model_pure,\n",
        "                                                         train_loader,\n",
        "                                                         val_loader,\n",
        "                                                         img_test_dataset)\n",
        "\n",
        "\n",
        "# Train and Test accuracy plot\n",
        "plt.figure()\n",
        "plt.plot(val_acc_pure, label='Val Accuracy Pure',\n",
        "         c='red', ls='dashed')\n",
        "plt.plot(train_acc_pure, label='Train Accuracy Pure',\n",
        "         c='red', ls='solid')\n",
        "plt.plot(val_acc_dataaug, label='Val Accuracy data augment',\n",
        "         c='blue', ls='dashed')\n",
        "plt.plot(train_acc_dataaug, label='Train Accuracy data augment',\n",
        "         c='blue', ls='solid')\n",
        "plt.axhline(y=max(val_acc_pure), c='red', ls='dashed')\n",
        "plt.axhline(y=max(val_acc_dataaug), c='blue', ls='dashed')\n",
        "plt.title('Data Augmentation')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "7beSRNE2dheG"
      },
      "outputs": [],
      "source": [
        "# Plot together: without and with augmenetation\n",
        "plt.figure()\n",
        "plt.plot(param_norm_pure, c='red', label='Without Augmentation')\n",
        "plt.plot(param_norm_dataaug, c='blue', label='With Augmentation')\n",
        "plt.title('Norm of parameters as a function of training epoch')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Norm of model parameters')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mCslLUm5dheH"
      },
      "source": [
        "Can you think of more ways of augmenting the training data? (Think of other problems beyond object recogition.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "h6tHFrBhdheJ"
      },
      "source": [
        "### Think! 3.1: Thought Question\n",
        "\n",
        "Why is it better to regularize an overparameterized ANN than to start with a smaller one? Think about the regularization methods you know.\n",
        "Each group should have a 10 min discussion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "65YLb1LPdheK"
      },
      "outputs": [],
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q1', text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "NvvZExz7dheK"
      },
      "outputs": [],
      "source": [
        "# to_remove explanation\n",
        "\n",
        "\"\"\"\n",
        "Regularization works by penalizing model complexity. If the initial model is not\n",
        "complex enough to correctly describe the data then no amount of regularization\n",
        "will help as the model needs to get more complex to improve, not less.\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TzAq-io2dheL"
      },
      "source": [
        "---\n",
        "# Section 4: Stochastic Gradient Descent\n",
        "\n",
        "*Time estimate: ~20 mins*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "e87IqPtXdheL"
      },
      "outputs": [],
      "source": [
        "# @title Video 4: SGD\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1nM4y1K7wP\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"rjzlFvJhNqE\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 4: SGD')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "KPimSLCodheL"
      },
      "source": [
        "## Section 4.1: Learning Rate\n",
        "\n",
        "In this section, we will see how the learning rate can act as a regularizer while training a neural network. In summary:\n",
        "\n",
        "* Smaller learning rates regularize less and slowly converge to deep minima. \n",
        "* Larger learning rates regularize more by missing local minima and converging to broader, flatter minima, which often generalize better.\n",
        "\n",
        "But beware, a very large learning rate may result in overshooting or finding a bad local minimum.\n",
        "\n",
        "In the block below, we will train the `AnimalNet` model with different learning rates and see how that affects the regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "xS-8Yv00dheM"
      },
      "outputs": [],
      "source": [
        "# @markdown #### Generating Data Loaders\n",
        "\n",
        "# For reproducibility\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "batch_size = 128\n",
        "train_transform = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "data_path = pathlib.Path('.')/'afhq' # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "img_train_data, img_val_data, = torch.utils.data.random_split(img_dataset, [11700,2930])\n",
        "\n",
        "full_train_loader = torch.utils.data.DataLoader(img_train_data,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=2,\n",
        "                                                worker_init_fn=seed_worker,\n",
        "                                                generator=g_seed)\n",
        "full_val_loader = torch.utils.data.DataLoader(img_val_data,\n",
        "                                              batch_size=1000,\n",
        "                                              num_workers=2,\n",
        "                                              worker_init_fn=seed_worker,\n",
        "                                              generator=g_seed)\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    # [TO-DO]\n",
        "     ])\n",
        "img_test_dataset = ImageFolder(data_path/'val', transform=test_transform)\n",
        "# img_test_loader = DataLoader(img_test_dataset, batch_size=batch_size,shuffle=False, num_workers=1)\n",
        "classes = ('cat', 'dog', 'wild')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "KpWWb10odheN"
      },
      "outputs": [],
      "source": [
        "# Set the arguments\n",
        "args = {\n",
        "    'test_batch_size': 1000,\n",
        "    'epochs': 350,\n",
        "    'batch_size': 32,\n",
        "    'momentum': 0.99,\n",
        "    'device': DEVICE\n",
        "}\n",
        "\n",
        "learning_rates = [5e-4, 1e-3, 5e-3]\n",
        "acc_dict = {}\n",
        "\n",
        "for i, lr in enumerate(learning_rates):\n",
        "  # Initialize the model\n",
        "  set_seed(seed=SEED)\n",
        "  model = AnimalNet()\n",
        "  # Learning rate\n",
        "  args['lr'] = lr\n",
        "  # Train the model\n",
        "  val_acc, train_acc, param_norm, _ = main(args,\n",
        "                                           model,\n",
        "                                           train_loader,\n",
        "                                           val_loader,\n",
        "                                           img_test_dataset)\n",
        "  # store the outputs\n",
        "  acc_dict[f'val_{i}'] = val_acc\n",
        "  acc_dict[f'train_{i}'] = train_acc\n",
        "  acc_dict[f'param_norm_{i}'] = param_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "pZFkKbYkdheN"
      },
      "outputs": [],
      "source": [
        "# @markdown Plot Train and Validation accuracy (Run me)\n",
        "\n",
        "plt.figure()\n",
        "for i, lr in enumerate(learning_rates):\n",
        "  plt.plot(acc_dict[f'val_{i}'], linestyle='dashed',\n",
        "          label=f'lr={lr:0.1e} - validation')\n",
        "  plt.plot(acc_dict[f'train_{i}'], label=f'{lr:0.1e} - train')\n",
        "\n",
        "  print(f\"Maximum Test Accuracy obtained with lr={lr:0.1e}: {max(acc_dict[f'val_{i}'])}\")\n",
        "\n",
        "plt.title('Optimal Learning Rate')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "tE5pEcNmdheO"
      },
      "outputs": [],
      "source": [
        "# @markdown Plot parametric norms (Run me)\n",
        "plt.figure()\n",
        "\n",
        "for i, lr in enumerate(learning_rates):\n",
        "  plt.plot(acc_dict[f'param_norm_{i}'],label=f'lr={lr:0.2e}')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('parameter norms')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "93oWpfAwdheP"
      },
      "source": [
        "In the model above, we observe something different from what we expected. Why do you think this is happening?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "f_E9ODvsdheP"
      },
      "source": [
        "---\n",
        "# Section 5: Hyperparameter Tuning\n",
        "\n",
        "*Time estimate: ~5 mins*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "yLeuoEzEdheQ"
      },
      "outputs": [],
      "source": [
        "# @title Video 5: Hyperparameter tuning\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1E44y127Sn\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"HgkiKRYc-3A\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 5: Hyperparameter tuning')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "6GDMbwvddheQ"
      },
      "source": [
        "Hyperparameter tuning is often tricky and time-consuming, and it is a vital part of training any Deep Learning model to give good generalization. There are a few techniques that we can use to guide us during the search. \n",
        "\n",
        "* **Grid Search**: Try all possible combinations of hyperparameters\n",
        "* **Random Search**: Randomly try different combinations of hyperparameters\n",
        "* **Coordinate-wise Gradient Descent**: Start at one set of hyperparameters and try changing one at a time, accept any changes that reduce your validation error\n",
        "* **Bayesian Optimization / Auto ML**:  Start from a set of hyperparameters that have worked well on a similar problem, and then do some sort of local exploration (e.g., gradient descent) from there.\n",
        "\n",
        "There are many choices, like what range to explore over, which parameter to optimize first, etc. Some hyperparameters don’t matter much (people use a dropout of either 0.5 or 0.2, but not much else). Others can matter a lot more (e.g., size and depth of the neural net). The key is to see what worked on similar problems.\n",
        "\n",
        "One can automate the process of tuning the network architecture using the so called *Neural Architecture Search (NAS)*. NAS designs new architectures using a few building blocks (Linear, Convolutional, Convolution Layers, etc.) and optimizes the design based on performance using a wide range of techniques such as Grid Search, Reinforcement Learning, Gradient Descent, Evolutionary Algorithms, etc. This obviously requires very high computing power. Read this [article](https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html) to learn more about NAS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "iOoM5UP3dheU"
      },
      "source": [
        "## Think! 5: Overview of regularization techniques\n",
        "\n",
        "Which regularization technique today do you think had the most significant effect on the network? Why might do you think so? Can you apply all of the regularization methods on the same network?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "ByucjuigdheV"
      },
      "outputs": [],
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q2', text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "tTKtmPmudheW"
      },
      "outputs": [],
      "source": [
        "# to_remove explanation\n",
        "\n",
        "\"\"\"\n",
        "Theoretically yes, we can apply all of the regularization methods on the same network.\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "JR3rEZPTdheW"
      },
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "Congratulations! You have finished the first week of NMA-DL! \n",
        "\n",
        "In this tutorial, you learned more regularization techniques, i.e., L1 and L2 regularization, Dropout, and Data Augmentation. Finally, you have seen that the learning rate of SGD can act as a regularizer. An interesting paper can be found [here](https://arxiv.org/abs/1611.03530). \n",
        "\n",
        "Continue to the Bonus material on *Adversarial Attacks*if you have time left!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "zkW4691RdheW"
      },
      "outputs": [],
      "source": [
        "# @title Airtable Submission Link\n",
        "from IPython import display as IPydisplay\n",
        "IPydisplay.HTML(\n",
        "   f\"\"\"\n",
        " <div>\n",
        "   <a href= \"{atform.url()}\" target=\"_blank\">\n",
        "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\"\n",
        " alt=\"button link end of day Survey\" style=\"width:410px\"></a>\n",
        "   </div>\"\"\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "7KKu_rHxdheX"
      },
      "source": [
        "---\n",
        "# Bonus: Adversarial  Attacks\n",
        "\n",
        "*Time estimate: ~15 mins*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Tw6iZJ1pdheX"
      },
      "outputs": [],
      "source": [
        "# @title Video 6: Adversarial Attacks\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV19o4y1X74u\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"LzPPoiKi5jE\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 6: Adversarial Attacks')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "dNpeEpcjdheY"
      },
      "source": [
        "Designing perturbations to the input data to trick a machine learning model is called an \"adversarial attack\". These attacks are an inevitable consequence of learning in high dimensional space using complex decision boundaries. Depending on the application, these attacks can be very dangerous.\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/static/AdversarialAttacks_w1d5t2.png\">\n",
        "\n",
        "<br>\n",
        "\n",
        "Hence, we need to build models which can defend against such attacks. One possible way to do it is by regularizing the networks, which smooths the decision boundaries. A few ways of building models robust to such attacks are:\n",
        "* [Defensive Distillation](https://deepai.org/machine-learning-glossary-and-terms/defensive-distillation): Models trained via distillation are less prone to such attacks as they are trained on soft labels as there is an element of randomness in the training process.\n",
        "* [Feature Squeezing](https://evademl.org/squeezing/): Identifies adversarial attacks for online classifiers whose model is being used by comparing the model's prediction before and after squeezing the input. \n",
        "* [SGD](https://arxiv.org/abs/1706.06083): You can also pick weight to minimize what the adversary is trying to maximize via SGD.\n",
        "\n",
        "<br>\n",
        "\n",
        "Read more about adversarial attacks [here](https://openai.com/blog/adversarial-example-research/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "W1D5_Tutorial2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "935be0a6f02e4e1cb15961770d2867bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_443d86adc3c84a4aacbd48dd7cec8581",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e24430388c2e4cf2a245ff6dfe675eb1",
              "IPY_MODEL_6065e5f0f3f8458e951ee9038fa871df"
            ]
          }
        },
        "443d86adc3c84a4aacbd48dd7cec8581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e24430388c2e4cf2a245ff6dfe675eb1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://youtube.com/watch?v=oQNdloKdysM\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/oQNdloKdysM?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                  "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f402a415290>",
                  "image/jpeg": "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\n"
                },
                "metadata": {}
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_0b0ada48cc6f47a2a6498bde28ab7eca",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "6065e5f0f3f8458e951ee9038fa871df": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://www.bilibili.com/video/BV19h41167H7\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV19h41167H7&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                  "text/plain": "<__main__.BiliVideo at 0x7f40286ea490>"
                },
                "metadata": {}
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_8865987d557f48e597e7adab64ea8814",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "0b0ada48cc6f47a2a6498bde28ab7eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8865987d557f48e597e7adab64ea8814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42b98c07dca34e9cb9dc7b3f149a24f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_91ece4f75d474133aaecc24a1a1801bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ad51d7b39c549c8a59e87c5c605b33a",
              "IPY_MODEL_527420e7b3db401f9e9fade9df7475d3",
              "IPY_MODEL_5f78b9d027544a11be2bc054920a761c"
            ]
          }
        },
        "91ece4f75d474133aaecc24a1a1801bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ad51d7b39c549c8a59e87c5c605b33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0026b27c8a744e497ff5e6a2ac1a452",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 41%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd0e87ae1a6b46cbba625349ea3bcdf7"
          }
        },
        "527420e7b3db401f9e9fade9df7475d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_18e135091733430caabbbdb42c81f648",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 61,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16146407a86f4096b1dbbfe3f41c66e2"
          }
        },
        "5f78b9d027544a11be2bc054920a761c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e7cbf67123a547c8981134ec7e4e491a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 61/150 [00:37&lt;00:52,  1.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7092fb52a1ae4aa48eee9136c20ed935"
          }
        },
        "d0026b27c8a744e497ff5e6a2ac1a452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd0e87ae1a6b46cbba625349ea3bcdf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18e135091733430caabbbdb42c81f648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16146407a86f4096b1dbbfe3f41c66e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7cbf67123a547c8981134ec7e4e491a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7092fb52a1ae4aa48eee9136c20ed935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}